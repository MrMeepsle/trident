{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c9c550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import learn2learn as l2l\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from PIL.Image import LANCZOS\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0570df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c796324e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/src',\n",
       " '/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.11.1001550889/pythonFiles',\n",
       " '/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.11.1001550889/pythonFiles/lib/python',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python39.zip',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.9',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.9/site-packages',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.9/site-packages/IPython/extensions',\n",
       " '/home/anuj/.ipython',\n",
       " '/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append('/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05f3b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = l2l.vision.models.get_pretrained_backbone(model='resnet12', dataset='mini-imagenet', root='../../dataset/backbones/', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87115fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 3, 84, 84])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = train_tasks.sample()[0]\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bb247f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 16000])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = model(a)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1ddceef",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNet12Backbone' object has no attribute 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24925/2375489130.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ResNet12Backbone' object has no attribute 'features'"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efda1c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet12Backbone(\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.1)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (DropBlock): DropBlock()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.1)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (DropBlock): DropBlock()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.1)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (DropBlock): DropBlock()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.1)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (DropBlock): DropBlock()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): Lambda()\n",
       "  (flatten): Flatten()\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5864db42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for p1, p2 in zip(model.parameters(), backbone.parameters()):\n",
    "    if p1.data.ne(p2.data).sum() > 0:\n",
    "        print('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b03ebf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet12Backbone(\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.1)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (DropBlock): DropBlock()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.1)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (DropBlock): DropBlock()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.1)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (DropBlock): DropBlock()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.1)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (DropBlock): DropBlock()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=5, stride=1, padding=0)\n",
       "  (flatten): Flatten()\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "337d93de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.taskers import gen_tasks\n",
    "from src.zoo.archs import CCVAE, CEncoder, Classifier_VAE, ConvBase, ResNet12Backbone, WRN28Backbone, CDecoder\n",
    "from src.zoo.delpo_utils import setup, inner_adapt_delpo, loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5eb15a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tasks = gen_tasks(dataname='miniimagenet', root='../../dataset/mini_imagenet', mode='train', n_ways=5, k_shots=1, q_shots=5, image_transforms=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b1b9846",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "n_ways = 5\n",
    "k_shots = 1\n",
    "q_shots = 5\n",
    "dataset = 'mini_imagenet'\n",
    "root = '../../dataset/mini_imagenet'\n",
    "order = False\n",
    "inner_lr = 0.001\n",
    "meta_lr = 0.0001\n",
    "reconst_loss = nn.MSELoss(reduction='none')\n",
    "adapt_steps = 2\n",
    "meta_batch_size = 10\n",
    "download = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b432fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, wt_ce, klwt, rec_wt, beta_l, beta_s):\n",
    "        #args.wt_ce, args.klwt, args.rec_wt, args.beta_l, args.beta_s\n",
    "        self.wt_ce = wt_ce\n",
    "        self.klwt = klwt\n",
    "        self.rec_wt = rec_wt\n",
    "        self.beta_l = beta_l\n",
    "        self.beta_s = beta_s\n",
    "        self.dataset = 'miniimagenet'\n",
    "        self.task_adapt = True\n",
    "        self.task_adapt_fn = 'tafe'\n",
    "        self.n_ways = 5\n",
    "        self.k_shots = 1\n",
    "        self.q_shots = 5\n",
    "        self.pretrained = [True, '../../dataset/backbones/mini/25u1gtp5.pth', 'nofreeze']\n",
    "        self.device = 'cpu'\n",
    "args = Args(100, False, 0.01, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7794ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = setup(args.dataset, root, n_ways, k_shots, q_shots, order, inner_lr, device, download, args.task_adapt, args.task_adapt_fn, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d951e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for p in a[-1].parameters():\n",
    "    print(p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b39e5897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[-1].allow_nograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07554f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(adapt_steps):\n",
    "        if args.task_adapt:\n",
    "            reconst_image, logits, mu_l, log_var_l, mu_s, log_var_s = learner(\n",
    "                torch.cat([support, queries], dim=0), 'inner')\n",
    "        else:\n",
    "            reconst_image, logits, mu_l, log_var_l, mu_s, log_var_s = learner(\n",
    "                support, 'inner')\n",
    "        adapt_loss = loss(reconst_loss, reconst_image, support,\n",
    "                            logits, support_labels, mu_s, log_var_s, mu_l, log_var_l, args.wt_ce, args.klwt, args.rec_wt, args.beta_l, args.beta_s)\n",
    "        learner.adapt(adapt_loss['elbo'])\n",
    "\n",
    "    if args.task_adapt:\n",
    "        reconst_image, logits, mu_l, log_var_l, mu_s, log_var_s = learner(\n",
    "            torch.cat([support, queries], dim=0), 'outer')\n",
    "    else:\n",
    "        reconst_image, logits, mu_l, log_var_l, mu_s, log_var_s = learner(\n",
    "            queries, 'outer')\n",
    "\n",
    "    eval_loss = loss(reconst_loss, reconst_image, queries,\n",
    "                     logits, queries_labels, mu_s, log_var_s, mu_l, log_var_l, args.wt_ce, args.klwt, args.rec_wt, args.beta_l, args.beta_s)\n",
    "    eval_acc = accuracy(F.softmax(logits, dim=1), queries_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b9c3833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet12Backbone(\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.1)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (DropBlock): DropBlock()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.1)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (DropBlock): DropBlock()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.1)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (DropBlock): DropBlock()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.1)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (DropBlock): DropBlock()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): Lambda()\n",
       "  (flatten): Flatten()\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone = ResNet12Backbone(args=args, avg_pool=False)\n",
    "weights = torch.load('../../dataset/backbones/mini/25u1gtp5.pth', map_location='cpu')\n",
    "backbone.load_state_dict(weights)\n",
    "backbone.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d1f49ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 640, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = backbone(train_tasks.sample()[0].to('cpu'))\n",
    "x = x.reshape(x.shape[-1], x.shape[0], x.shape[1], -1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35c8386a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 640])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.squeeze(dim=0).squeeze(dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2af24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CEncoder(num_input_channels=3, base_channel_size=32, latent_dim=64, dataset=dataset, args=args, flag=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d2bd5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoder = CDecoder(num_input_channels=3, base_channel_size=32, latent_dim=(64 + 64), dataset=dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c1d5046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier_vae = Classifier_VAE(3, 32, 64, 5, dataset, task_adapt=True, task_adapt_fn='eaen', args=args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd929faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "b = 1\n",
    "c = 2\n",
    "\n",
    "if a == 1010:\n",
    "    print('yes')\n",
    "elif a == 0:\n",
    "    if b == 1:\n",
    "        print(c)\n",
    "    elif b == 2:\n",
    "        print('nonlocal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cab0c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TADCEncoder(nn.Module):\n",
    "    \"\"\" Convolutional Encoder to transform an input image into a latent-space gaussian distribution parametrized by its mean and log-variance, \n",
    "    with the added functionality of the distributions being task/episode aware. \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_input_channels: int,\n",
    "                 base_channel_size: int,\n",
    "                 latent_dim: int,\n",
    "                 dataset: str,\n",
    "                 task_adapt_fn: str,\n",
    "                 args,\n",
    "                 act_fn: object = nn.ReLU):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            - num_input_channels : Number of input channels of the image\n",
    "            - base_channel_size : Number of channels we use in the first convolutional layers. Deeper layers use 2x of it.\n",
    "            - latent_dim : Dimensionality of latent representation z\n",
    "            - dataset: name of the dataset\n",
    "            - task_adapt_fn: EAEN (eaen) or Kernel Smoothing (gks)\n",
    "            - args: dict of arguments\n",
    "            - act_fn : Activation function used throughout the encoder network\n",
    "        \"\"\"\n",
    "\n",
    "        super(TADCEncoder, self).__init__()\n",
    "        c_hid = base_channel_size\n",
    "        self.args = args\n",
    "        self.task_adapt_fn = task_adapt_fn\n",
    "\n",
    "        if dataset == 'omniglot':\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Conv2d(num_input_channels, c_hid,\n",
    "                          kernel_size=3, padding=1, stride=(2, 2)),\n",
    "                nn.BatchNorm2d(c_hid),\n",
    "                act_fn(),  # 14\n",
    "\n",
    "                nn.Conv2d(c_hid, c_hid, kernel_size=3,\n",
    "                          padding=1, stride=(2, 2)),\n",
    "                nn.BatchNorm2d(c_hid),\n",
    "                act_fn(),  # 7\n",
    "\n",
    "                nn.Conv2d(c_hid, c_hid, kernel_size=3,\n",
    "                          padding=1, stride=(2, 2)),\n",
    "                nn.BatchNorm2d(c_hid),\n",
    "                act_fn(),  # 4\n",
    "\n",
    "                nn.Conv2d(c_hid, c_hid, kernel_size=3,\n",
    "                          padding=1, stride=(2, 2)),\n",
    "                nn.BatchNorm2d(c_hid),\n",
    "                act_fn()  # 2\n",
    "            )\n",
    "            self.h1 = nn.Linear(4*c_hid, latent_dim)\n",
    "            self.h2 = nn.Linear(4*c_hid, latent_dim)\n",
    "\n",
    "        elif (dataset == 'mini_imagenet') or (dataset == 'cifarfs') or (dataset == 'tiered'):\n",
    "            if args.pretrained[0] == True:\n",
    "                self.h1 = nn.Sequential(nn.Linear(\n",
    "                    640*25, 8000), nn.Linear(8000, 1000), nn.Linear(1000, latent_dim))\n",
    "                self.h2 = nn.Sequential(nn.Linear(\n",
    "                    640*25, 8000), nn.Linear(8000, 1000), nn.Linear(1000, latent_dim))\n",
    "\n",
    "            elif args.pre_trained[0] == False:\n",
    "                self.net = nn.Sequential(\n",
    "                    nn.Conv2d(num_input_channels, c_hid,\n",
    "                              kernel_size=3, padding=1),\n",
    "                    nn.BatchNorm2d(c_hid),\n",
    "                    act_fn(),\n",
    "                    nn.MaxPool2d(2),  # 28 x 28, # 42 x 42\n",
    "\n",
    "                    # nn.ZeroPad2d(conv_padding),\n",
    "                    nn.Conv2d(c_hid, c_hid, kernel_size=3, padding=1),\n",
    "                    nn.BatchNorm2d(c_hid),\n",
    "                    act_fn(),\n",
    "                    nn.MaxPool2d(2),  # 9x9 # 21 x 21\n",
    "\n",
    "                    # nn.ZeroPad2d(conv_padding),\n",
    "                    nn.Conv2d(c_hid, c_hid, kernel_size=3, padding=1),\n",
    "                    nn.BatchNorm2d(c_hid),\n",
    "                    act_fn(),\n",
    "                    nn.MaxPool2d(2),  # 3x3 # 10 x 10\n",
    "\n",
    "                    # nn.ZeroPad2d(conv_padding),\n",
    "                    nn.Conv2d(c_hid, c_hid, kernel_size=3, padding=1),\n",
    "                    nn.BatchNorm2d(c_hid),\n",
    "                    act_fn(),\n",
    "                    nn.MaxPool2d(2)  # 1x1 # 5 x 5\n",
    "                )\n",
    "\n",
    "                if (dataset == 'mini_imagenet') or (dataset == 'tiered'):\n",
    "                    self.h1 = nn.Linear(c_hid*25, latent_dim)\n",
    "                    self.h2 = nn.Linear(c_hid*25, latent_dim)\n",
    "                elif dataset == 'cifarfs':\n",
    "                    self.h1 = nn.Linear(c_hid*4, latent_dim)\n",
    "                    self.h2 = nn.Linear(c_hid*4, latent_dim)\n",
    "\n",
    "        self.n = args.n_ways * (args.k_shots + args.q_shots)\n",
    "        self.eaen = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(\n",
    "                self.n, 1), stride=(1, 1), padding='valid', bias=False),\n",
    "            # P\n",
    "            act_fn(),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=(\n",
    "                1, 1), stride=(1, 1), padding='valid', bias=False),\n",
    "            # Z\n",
    "            act_fn(),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=1, kernel_size=(\n",
    "                1, 1), stride=(1, 1), padding='valid', bias=False),\n",
    "            # F\n",
    "            act_fn(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, update: str):\n",
    "        if self.args.pretrained[0] == False:\n",
    "            x = self.net(x)\n",
    "        elif self.args.pretrained[0] == True:\n",
    "            x = x\n",
    "\n",
    "        # Task aware embeddings\n",
    "\n",
    "        if self.task_adapt_fn == 'eaen':\n",
    "            G = x.permute(2, 3, 0, 1)\n",
    "            G = G.reshape(G.shape[0] * G.shape[1],\n",
    "                          G.shape[2], G.shape[3]).unsqueeze(dim=1)\n",
    "            G = self.eaen(G)\n",
    "            G = G.squeeze().transpose(0, 1).reshape(-1, x.shape[2], x.shape[3])\n",
    "            if update == 'inner':\n",
    "                x = x[:self.args.n_ways*self.args.k_shots] * G\n",
    "            elif update == 'outer':\n",
    "                x = x[self.args.n_ways*self.args.k_shots:] * G\n",
    "            x = nn.Flatten()(x)\n",
    "\n",
    "        elif self.task_adapt_fn == 'gks':\n",
    "            G = x.reshape(self.n, -1)\n",
    "            A = torch.cdist(G, G, p=2) ** 2\n",
    "            A = A / A.var()  # Normalized adjacency matrix\n",
    "            D = torch.diag(A.sum(dim=1).pow(-0.5))\n",
    "            L = torch.matmul(torch.matmul(D, A), D)  # Laplacian Matrix\n",
    "            I = torch.eye(self.n, self.n).to(self.args.device)\n",
    "            P = torch.linalg.inv(I - self.args.alpha * L)  # Propagator Matrix\n",
    "            x = torch.matmul(P, G)\n",
    "            if update == 'inner':\n",
    "                x = x[:self.args.n_ways*self.args.k_shots]\n",
    "            elif update == 'outer':\n",
    "                x = x[self.args.n_ways*self.args.k_shots:]\n",
    "\n",
    "        mu = self.h1(x)\n",
    "        log_var = self.h2(x)\n",
    "        return mu, log_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "622eec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tadcen = TADCEncoder(3, 32, 64, 'mini_imagenet', 'eaen', args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7634d236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier_VAE(\n",
       "  (encoder): TADCEncoder(\n",
       "    (eaen): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(30, 1), stride=(1, 1), padding=valid, bias=False)\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), padding=valid, bias=False)\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1), padding=valid, bias=False)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c6fb414",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13967/3190204934.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCCVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_ways\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_ways\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mini_imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_adapt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_adapt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_adapt_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_adapt_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/src/zoo/archs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, base_channels, n_ways, dataset, task_adapt, task_adapt_fn, args, latent_dim_l, latent_dim_s)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         self.classifier_vae = Classifier_VAE(\n\u001b[0;32m--> 862\u001b[0;31m             self.in_channels, self.base_channels, self.latent_dim_l, self.classes, dataset, task_adapt=task_adapt, task_adapt_fn=task_adapt_fn, args=self.args)\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/src/zoo/archs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, base_channels, latent_dim, n_ways, dataset, task_adapt, task_adapt_fn, args, act_fn)\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_adapt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             self.encoder = TADCEncoder(num_input_channels=self.in_channels,\n\u001b[0;32m--> 811\u001b[0;31m                                 base_channel_size=self.base_channels, latent_dim=self.latent_dim, dataset=dataset, task_adapt_fn=self.task_adapt_fn, args=args)\n\u001b[0m\u001b[1;32m    812\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m             self.encoder = CEncoder(num_input_channels=self.in_channels,\n",
      "\u001b[0;32m~/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/src/zoo/archs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_input_channels, base_channel_size, latent_dim, dataset, task_adapt_fn, args, act_fn)\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_trained\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[0;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner = CCVAE(in_channels=3, base_channels=32, n_ways=n_ways, dataset='mini_imagenet', task_adapt=args.task_adapt, task_adapt_fn=args.task_adapt_fn, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49302011",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = learner.to(device)\n",
    "learner = l2l.algorithms.MAML(learner, first_order=order, lr=inner_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e84d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Init the Backbone\n",
    "if args.pretrained[0] == True:\n",
    "    backbone = ResNet12Backbone(\n",
    "        args, avg_pool=True if args.pretrained[2] == 640 else False)  # F => 16000; T => 640\n",
    "    weights = torch.load(args.pretrained[1], map_location='cpu')\n",
    "    backbone.load_state_dict(weights)\n",
    "    backbone.to(device)\n",
    "    # Freeze the backbone\n",
    "    for p in backbone.parameters():\n",
    "        p.requires_grad = False\n",
    "else:\n",
    "    backbone = 'None'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2ccd49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def accuracy(predictions, targets):\n",
    "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
    "    return (predictions == targets).sum().float() / targets.size(0)\n",
    "\n",
    "\n",
    "def kl_div(mus, log_vars):\n",
    "    return - 0.5 * (1 + log_vars - mus**2 - torch.exp(log_vars)).sum(dim=1)\n",
    "\n",
    "\n",
    "def loss(reconst_loss: object, reconst_image, image, logits, labels, mu_s, log_var_s, mu_l, log_var_l, wt_ce=1e2, klwt=False, rec_wt=1e-2, beta_l=1, beta_s=1):\n",
    "    kl_div_s = kl_div(mu_s, log_var_s).mean()\n",
    "    kl_div_l = kl_div(mu_l, log_var_l).mean()\n",
    "    if klwt:\n",
    "        kl_wt = mu_s.shape[-1] / (image.shape[-1] *\n",
    "                                  image.shape[-2] * image.shape[-3])\n",
    "    else:\n",
    "        kl_wt = 1\n",
    "\n",
    "    ce_loss = torch.nn.CrossEntropyLoss()\n",
    "    classification_loss = ce_loss(logits, labels)\n",
    "    rec_loss = reconst_loss(reconst_image, image)\n",
    "    rec_loss = rec_loss.view(rec_loss.shape[0], -1).sum(dim=-1).mean()\n",
    "\n",
    "    L = wt_ce*classification_loss + beta_l*kl_wt*kl_div_l + \\\n",
    "        rec_wt*rec_loss + beta_s*kl_wt*kl_div_s  # -log p(x,y)\n",
    "\n",
    "    losses = {'elbo': L, 'label_kl': kl_div_l, 'style_kl': kl_div_s,\n",
    "              'reconstruction_loss': rec_loss, 'classification_loss': classification_loss}\n",
    "\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "596ba2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = train_tasks.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e880ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = task\n",
    "if args.dataset == 'miniimagenet':\n",
    "    data, labels = data.to(device) / 255.0, labels.to(device)\n",
    "elif (args.dataset == 'omniglot') or (args.dataset == 'cifarfs') or (args.dataset == 'tiered'):\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "total = n_ways * (k_shots + q_shots)\n",
    "queries_index = np.zeros(total)\n",
    "\n",
    "# Extracting the evaluation datums from the entire task set, for the meta gradient calculation\n",
    "for offset in range(n_ways):\n",
    "    queries_index[np.random.choice(\n",
    "        k_shots+q_shots, q_shots, replace=False) + ((k_shots + q_shots)*offset)] = True\n",
    "support = data[np.where(queries_index == 0)]\n",
    "support_labels = labels[np.where(queries_index == 0)]\n",
    "queries = data[np.where(queries_index == 1)]\n",
    "queries_labels = labels[np.where(queries_index == 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebf4eb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 3, 84, 84])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dccabbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if args.pretrained[0] == True:\n",
    "    support_ext = backbone(support)\n",
    "    queries_ext = backbone(queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03bac9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 640, 5, 5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_ext.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55b22777",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TADCEncoder' object has no attribute 'h1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13967/2006488311.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapt_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_adapt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             reconst_image, logits, mu_l, log_var_l, mu_s, log_var_s = learner([torch.cat(\n\u001b[0m\u001b[1;32m      6\u001b[0m                 [support_ext, queries_ext], dim=0), torch.cat([support, queries], dim=0)], 'inner')\n\u001b[1;32m      7\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/learn2learn/algorithms/maml.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     def adapt(self,\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/src/zoo/archs.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, update)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_adapt\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mupdate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_ways\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_shots\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/src/zoo/archs.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, update)\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_adapt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m             \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/src/zoo/archs.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, update)\u001b[0m\n\u001b[1;32m    653\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_ways\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_shots\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m         \u001b[0mlog_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1131\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TADCEncoder' object has no attribute 'h1'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Inner adapt step\n",
    "if args.pretrained[0] == True:\n",
    "    for _ in range(adapt_steps):\n",
    "        if args.task_adapt:\n",
    "            reconst_image, logits, mu_l, log_var_l, mu_s, log_var_s = learner([torch.cat(\n",
    "                [support_ext, queries_ext], dim=0), torch.cat([support, queries], dim=0)], 'inner')\n",
    "        else:\n",
    "            reconst_image, logits, mu_l, log_var_l, mu_s, log_var_s = learner(\n",
    "                [support_ext, support], 'inner')\n",
    "        adapt_loss = loss(reconst_loss, reconst_image, support,\n",
    "                            logits, support_labels, mu_s, log_var_s, mu_l, log_var_l, args.wt_ce, args.klwt, args.rec_wt, args.beta_l, args.beta_s)\n",
    "        learner.adapt(adapt_loss['elbo'])\n",
    "\n",
    "    if args.task_adapt:\n",
    "        reconst_image, logits, mu_l, log_var_l, mu_s, log_var_s = learner([torch.cat(\n",
    "            [support_ext, queries_ext], dim=0), torch.cat([support, queries], dim=0)], 'outer')\n",
    "    else:\n",
    "        reconst_image, logits, mu_l, log_var_l, mu_s, log_var_s = learner(\n",
    "            [queries_ext, queries], 'outer')\n",
    "\n",
    "if args.pretrained[0] == False:\n",
    "    for _ in range(adapt_steps):\n",
    "        if args.task_adapt:\n",
    "            reconst_image, logits, mu_l, log_var_l, mu_s, log_var_s = learner(\n",
    "                torch.cat([support, queries], dim=0), 'inner')\n",
    "        else:\n",
    "            reconst_image, logits, mu_l, log_var_l, mu_s, log_var_s = learner(\n",
    "                support, 'inner')\n",
    "        adapt_loss = loss(reconst_loss, reconst_image, support,\n",
    "                            logits, support_labels, mu_s, log_var_s, mu_l, log_var_l, args.wt_ce, args.klwt, args.rec_wt, args.beta_l, args.beta_s)\n",
    "        learner.adapt(adapt_loss['elbo'])\n",
    "\n",
    "    if args.task_adapt:\n",
    "        reconst_image, logits, mu_l, log_var_l, mu_s, log_var_s = learner(\n",
    "            torch.cat([support, queries], dim=0), 'outer')\n",
    "    else:\n",
    "        reconst_image, logits, mu_l, log_var_l, mu_s, log_var_s = learner(\n",
    "            queries, 'outer')\n",
    "\n",
    "eval_loss = loss(reconst_loss, reconst_image, queries,\n",
    "                    logits, queries_labels, mu_s, log_var_s, mu_l, log_var_l, args.wt_ce, args.klwt, args.rec_wt, args.beta_l, args.beta_s)\n",
    "eval_acc = accuracy(F.softmax(logits, dim=1), queries_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "196d755f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet12Backbone(\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.1)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (DropBlock): DropBlock()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.1)\n",
       "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (DropBlock): DropBlock()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.1)\n",
       "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (DropBlock): DropBlock()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): LeakyReLU(negative_slope=0.1)\n",
       "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (DropBlock): DropBlock()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=5, stride=1, padding=0)\n",
       "  (flatten): Flatten()\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone = ResNet12Backbone(args=args, avg_pool=True)\n",
    "weights = torch.load('../../dataset/backbones/mini/25u1gtp5.pth', map_location='cpu')\n",
    "backbone.load_state_dict(weights)\n",
    "backbone.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5445336",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in backbone.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26568ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 640])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = backbone(train_tasks.sample()[0].to('cuda'))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f56cfbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x.detach()\n",
    "x.requires_grad"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m71"
  },
  "interpreter": {
   "hash": "7e3af266dcb7df8b026f0780dbb396b062ee5ca2767a18f50e60e26ee6084121"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('torch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
