{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import learn2learn as l2l\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from PIL.Image import LANCZOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/src',\n",
       " '/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/pythonFiles',\n",
       " '/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/pythonFiles/lib/python',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python38.zip',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/datasets-1.2.1-py3.8.egg',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/locket-0.2.1-py3.8.egg',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/home/anuj/.ipython',\n",
       " '/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append('/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.taskers import gen_tasks\n",
    "from src.zoo.archs import CCVAE, CEncoder, Classifier_VAE, ConvBase, TADCEncoder\n",
    "from src.zoo.delpo_utils import setup, inner_adapt_delpo, loss, accuracy\n",
    "from src.utils2 import Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "n_ways = 5\n",
    "k_shots = 5\n",
    "q_shots = 15\n",
    "dataset = 'cifarfs'\n",
    "root = '../../dataset/cifarfs'\n",
    "order = False\n",
    "inner_lr = 0.001\n",
    "meta_lr = 0.001\n",
    "reconst_loss = nn.MSELoss(reduction='none')\n",
    "inner_adapt_steps_train = 5\n",
    "meta_batch_size = 10\n",
    "download = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, wt_ce, klwt, rec_wt, beta_l, beta_s):\n",
    "        #args.wt_ce, args.klwt, args.rec_wt, args.beta_l, args.beta_s\n",
    "        self.wt_ce = wt_ce\n",
    "        self.klwt = klwt\n",
    "        self.rec_wt = rec_wt\n",
    "        self.beta_l = beta_l\n",
    "        self.beta_s = beta_s\n",
    "        self.dataset = 'cifarfs'\n",
    "\n",
    "args = Args(100, False, 0.1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_trans = transforms.Compose([transforms.ToTensor()])\n",
    "train_tasks = gen_tasks(dataset, root, image_transforms=image_trans, download=download, mode='train',\n",
    "                        n_ways=n_ways, k_shots=k_shots, q_shots=q_shots)\n",
    "valid_tasks = gen_tasks(dataset, root, image_transforms=image_trans, download=download, mode='validation',\n",
    "                        n_ways=n_ways, k_shots=k_shots, q_shots=q_shots)\n",
    "test_tasks = gen_tasks(dataset, root, image_transforms=image_trans, download=download, mode='test',\n",
    "                        n_ways=n_ways, k_shots=k_shots, q_shots=q_shots, num_tasks=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 32, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = train_tasks.sample()[0]\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 64, 16, 16])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nn.Conv2d(3, 64, kernel_size=3, padding=1)(input)\n",
    "x = nn.BatchNorm2d(64)(x)\n",
    "x = nn.MaxPool2d(2)(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 64, 8, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nn.Conv2d(64, 64, kernel_size=3, padding=1)(x)\n",
    "x = nn.BatchNorm2d(64)(x)\n",
    "x = nn.MaxPool2d(2)(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 64, 4, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nn.Conv2d(64, 64, kernel_size=3, padding=1)(x)\n",
    "x = nn.BatchNorm2d(64)(x)\n",
    "x = nn.MaxPool2d(2)(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 64, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nn.Conv2d(64, 64, kernel_size=3, padding=1)(x)\n",
    "x = nn.BatchNorm2d(64)(x)\n",
    "x = nn.MaxPool2d(2)(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Args' object has no attribute 'n_ways'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_66038/137489212.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCCVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_ways\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_ways\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cifarfs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_adapt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_adapt_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eaen'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/src/zoo/archs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, base_channels, n_ways, dataset, task_adapt, task_adapt_fn, args, latent_dim_l, latent_dim_s)\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_dim_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatent_dim_l\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_dim_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatent_dim_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/src/zoo/archs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, base_channels, latent_dim, n_ways, dataset, task_adapt, task_adapt_fn, args, act_fn)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mClassifier_VAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m     \"\"\" Module for a Convolutional-VAE: Convolutional Encoder + Linear Classifier that \n\u001b[0m\u001b[1;32m    743\u001b[0m     \u001b[0mtransforms\u001b[0m \u001b[0man\u001b[0m \u001b[0minput\u001b[0m \u001b[0mimage\u001b[0m \u001b[0minto\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mspace\u001b[0m \u001b[0mgaussian\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muses\u001b[0m \u001b[0mz_c\u001b[0m \u001b[0mdrawn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     from this distribution to produce logits for classification. \"\"\"\n",
      "\u001b[0;32m~/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/src/zoo/archs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_input_channels, base_channel_size, latent_dim, dataset, task_adapt_fn, args, act_fn)\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_hid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_hid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_hid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                 \u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m                 \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 1x1 # 5 x 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Args' object has no attribute 'n_ways'"
     ]
    }
   ],
   "source": [
    "learner = CCVAE(in_channels=3, base_channels=64, n_ways=n_ways, dataset='cifarfs', task_adapt=True, task_adapt_fn='eaen', args=args)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m71"
  },
  "interpreter": {
   "hash": "7e3af266dcb7df8b026f0780dbb396b062ee5ca2767a18f50e60e26ee6084121"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('torch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
