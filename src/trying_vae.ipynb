{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifiers: nn.crossentropyloss = -log-likelihood --- use for logp(y) and -logq(y/x) for support <br>\n",
    "kl-div: <br>\n",
    "reconstr-loss: set reduction to none and then take mean of losses per image in the total batch. This gives reconstr-loss per image for further computation<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import learn2learn as l2l\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from PIL.Image import LANCZOS\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/src',\n",
       " '/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.9.1001312534/pythonFiles',\n",
       " '/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.9.1001312534/pythonFiles/lib/python',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python38.zip',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/datasets-1.2.1-py3.8.egg',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/locket-0.2.1-py3.8.egg',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/home/anuj/.ipython',\n",
       " '/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append('/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from data.loaders import Omniglotmix, MiniImageNet\n",
    "from data.taskers import gen_tasks\n",
    "from src.zoo.archs import CCVAE, CEncoder, Classifier_VAE\n",
    "from src.zoo.delpo_utils import setup, inner_adapt_delpo, loss, accuracy\n",
    "\n",
    "#from src.utils import Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_34479/766937723.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_tasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'miniimagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../../dataset/mini_imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_ways\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_shots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_shots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_transforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/data/taskers.py\u001b[0m in \u001b[0;36mgen_tasks\u001b[0;34m(dataname, root, image_transforms, target_transforms, download, **task_transforms)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'miniimagenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         mini = MiniImageNet(root, mode, transform=image_transforms,\n\u001b[0m\u001b[1;32m     43\u001b[0m                             target_transform=target_transforms, download=download)\n\u001b[1;32m     44\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetaDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/data/loaders.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, mode, transform, target_transform, download)\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mdownload_pkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoogle_drive_file_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_tasks = gen_tasks(dataname='miniimagenet', root='../../dataset/mini_imagenet', mode='train', n_ways=5, k_shots=1, q_shots=1, image_transforms=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "classes = list(range(1623))\n",
    "random.shuffle(classes)\n",
    "image_transforms = transforms.Compose([transforms.Resize(28, interpolation=LANCZOS),\n",
    "                                                    transforms.ToTensor(),\n",
    "                                                    lambda x: 1.0 - x,\n",
    "                                                ])\n",
    "train_tasks = gen_tasks('omniglot', '/home/anuj/Desktop/Work/TU_Delft/research/implement/omniglot', image_transforms=image_transforms, n_ways=5, k_shots=5, q_shots=5, classes=classes[:1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = train_tasks.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "n_ways = 5\n",
    "k_shots = 5\n",
    "q_shots = 15\n",
    "dataset = 'miniimagenet'\n",
    "root = '../../dataset/mini_imagenet'\n",
    "order = False\n",
    "inner_lr = 0.0001\n",
    "meta_lr = 0.0001\n",
    "reconst_loss = nn.MSELoss(reduction='none')\n",
    "inner_adapt_steps_train = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tasks, valid_tasks, test_tasks, learner = setup(\n",
    "    dataset, root, n_ways, k_shots, q_shots, order, inner_lr, device, download='False')\n",
    "opt = optim.Adam(learner.parameters(), meta_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.zero_grad()\n",
    "meta_train_loss = []\n",
    "meta_valid_loss = []\n",
    "meta_train_acc = []\n",
    "meta_valid_acc = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = train_tasks.sample()\n",
    "model = learner.clone()\n",
    "data, labels = task\n",
    "data, labels = data.to(device) / 256, labels.to(device)\n",
    "total = n_ways * (k_shots + q_shots)\n",
    "queries_index = np.zeros(total)\n",
    "\n",
    "# Extracting the evaluation datums from the entire task set, for the meta gradient calculation\n",
    "for offset in range(n_ways):\n",
    "    queries_index[np.random.choice(\n",
    "        k_shots+q_shots, q_shots, replace=False) + ((k_shots + q_shots)*offset)] = True\n",
    "support = data[np.where(queries_index == 0)]\n",
    "support_labels = labels[np.where(queries_index == 0)]\n",
    "queries = data[np.where(queries_index == 1)]\n",
    "queries_labels = labels[np.where(queries_index == 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learner.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1137.4082, grad_fn=<AddBackward0>),\n",
       " tensor(56.8141, grad_fn=<MeanBackward0>),\n",
       " tensor(25.3008, grad_fn=<MeanBackward0>),\n",
       " tensor(2422.6084, grad_fn=<MeanBackward0>),\n",
       " tensor(1.0311, grad_fn=<NllLossBackward>))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconst_image, logits, mu_l, log_var_l, mu_s, log_var_s = model(support)\n",
    "adapt_loss = loss(reconst_loss, reconst_image, support, logits, support_labels, mu_s, log_var_s, mu_l, log_var_l)\n",
    "adapt_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.adapt(adapt_loss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0671, 0.1224, 0.1134, 0.1977, 0.4994],\n",
       "        [0.0495, 0.0567, 0.0615, 0.0856, 0.7466],\n",
       "        [0.0616, 0.1182, 0.0882, 0.0639, 0.6681],\n",
       "        [0.1082, 0.1271, 0.1970, 0.1099, 0.4578],\n",
       "        [0.1577, 0.2765, 0.2085, 0.1579, 0.1994],\n",
       "        [0.2518, 0.1493, 0.2866, 0.1699, 0.1425],\n",
       "        [0.1147, 0.1307, 0.3507, 0.2322, 0.1718],\n",
       "        [0.1675, 0.1424, 0.3328, 0.1532, 0.2042],\n",
       "        [0.1277, 0.1921, 0.2469, 0.1764, 0.2570],\n",
       "        [0.1496, 0.2345, 0.2737, 0.1282, 0.2140],\n",
       "        [0.2273, 0.2629, 0.1814, 0.1745, 0.1539],\n",
       "        [0.2630, 0.2246, 0.0819, 0.1546, 0.2759],\n",
       "        [0.3271, 0.1557, 0.1397, 0.2652, 0.1123],\n",
       "        [0.3151, 0.2511, 0.1084, 0.1540, 0.1715],\n",
       "        [0.2765, 0.1391, 0.1244, 0.3009, 0.1591],\n",
       "        [0.2782, 0.2093, 0.2391, 0.1639, 0.1095],\n",
       "        [0.2384, 0.2250, 0.1913, 0.1731, 0.1722],\n",
       "        [0.1471, 0.3402, 0.1831, 0.1211, 0.2085],\n",
       "        [0.2134, 0.2904, 0.2023, 0.1475, 0.1463],\n",
       "        [0.1804, 0.2893, 0.1912, 0.1854, 0.1536],\n",
       "        [0.1903, 0.1011, 0.0828, 0.5309, 0.0950],\n",
       "        [0.1580, 0.1425, 0.1449, 0.3783, 0.1763],\n",
       "        [0.1235, 0.1248, 0.1716, 0.4096, 0.1705],\n",
       "        [0.1667, 0.2059, 0.1632, 0.2681, 0.1961],\n",
       "        [0.1170, 0.0990, 0.1260, 0.5177, 0.1403]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = train_tasks.sample()\n",
    "model = learner.clone()\n",
    "evaluation_loss, evaluation_accuracy = inner_adapt_delpo(\n",
    "            task, reconst_loss, model, n_ways, k_shots, q_shots, inner_adapt_steps_train, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Kernel is dead",
     "output_type": "error",
     "traceback": [
      "Error: Kernel is dead",
      "at g._sendKernelShellControl (/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:1006195)",
      "at g.sendShellMessage (/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:1005964)",
      "at g.requestExecute (/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:1008506)",
      "at d.requestExecute (/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:37:325680)",
      "at w.requestExecute (/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:32:18027)",
      "at w.executeCodeCell (/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:301076)",
      "at w.execute (/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:300703)",
      "at w.start (/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:296367)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:311160)",
      "at async t.CellExecutionQueue.start (/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/out/client/extension.js:52:310700)"
     ]
    }
   ],
   "source": [
    "evaluation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_loss[0].backward()\n",
    "meta_train_loss.append(evaluation_loss[0])\n",
    "meta_train_acc.append(evaluation_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.9887, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_loss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in learner.parameters():\n",
    "    p.grad.data.mul_(1.0 / 3)\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "for iter in range(10):\n",
    "    opt.zero_grad()\n",
    "    meta_train_losses = []\n",
    "    meta_valid_losses = []\n",
    "    meta_train_acc = []\n",
    "    meta_valid_acc = []\n",
    "\n",
    "    for batch in range(5):\n",
    "        ttask = train_tasks.sample()\n",
    "        model = learner.clone()\n",
    "        evaluation_loss, evaluation_accuracy = inner_adapt_delpo(\n",
    "            ttask, reconst_loss, model, n_ways, k_shots, q_shots, inner_adapt_steps_train, device)\n",
    "        evaluation_loss[0].backward()\n",
    "        meta_train_losses.append([l.item() for l in evaluation_loss])\n",
    "        meta_train_acc.append(evaluation_accuracy.item())\n",
    "\n",
    "    vtask = valid_tasks.sample()\n",
    "    model = learner.clone()\n",
    "    validation_loss, validation_accuracy = inner_adapt_delpo(\n",
    "        vtask, reconst_loss, model, n_ways, k_shots, q_shots, inner_adapt_steps_train, device)\n",
    "    meta_valid_losses.append([l.item() for l in validation_loss])\n",
    "    meta_valid_acc.append(validation_accuracy.item())\n",
    "\n",
    "    for p in learner.parameters():\n",
    "        p.grad.data.mul_(1.0 / 5)\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[207.71360778808594,\n",
       "  21.771520614624023,\n",
       "  6.7143144607543945,\n",
       "  2425.524658203125,\n",
       "  1.5497252941131592],\n",
       " [194.03419494628906,\n",
       "  21.9337100982666,\n",
       "  5.416471481323242,\n",
       "  2459.828857421875,\n",
       "  1.4208571910858154],\n",
       " [199.2206268310547,\n",
       "  30.40707015991211,\n",
       "  5.68020486831665,\n",
       "  2262.280517578125,\n",
       "  1.405105471611023],\n",
       " [203.253662109375,\n",
       "  22.707983016967773,\n",
       "  5.878161430358887,\n",
       "  2504.766357421875,\n",
       "  1.4961985349655151],\n",
       " [195.3379364013672,\n",
       "  20.966901779174805,\n",
       "  7.109440326690674,\n",
       "  2023.20703125,\n",
       "  1.4702953100204468]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.07713608e+02, 2.17715206e+01, 6.71431446e+00, 2.42552466e+03,\n",
       "       1.54972529e+00, 1.94034195e+02, 2.19337101e+01, 5.41647148e+00,\n",
       "       2.45982886e+03, 1.42085719e+00, 1.99220627e+02, 3.04070702e+01,\n",
       "       5.68020487e+00, 2.26228052e+03, 1.40510547e+00, 2.03253662e+02,\n",
       "       2.27079830e+01, 5.87816143e+00, 2.50476636e+03, 1.49619853e+00,\n",
       "       1.95337936e+02, 2.09669018e+01, 7.10944033e+00, 2.02320703e+03,\n",
       "       1.47029531e+00])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.hstack(meta_train_losses)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199.91200561523436"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[::5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29333332, 0.37333333, 0.42666668, 0.40000001, 0.34666666])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = np.array(meta_train_acc)\n",
    "y1"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m71"
  },
  "interpreter": {
   "hash": "7e3af266dcb7df8b026f0780dbb396b062ee5ca2767a18f50e60e26ee6084121"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('torch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
