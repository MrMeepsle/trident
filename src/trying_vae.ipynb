{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifiers: nn.crossentropyloss = -log-likelihood --- use for logp(y) and -logq(y/x) for support <br>\n",
    "kl-div: <br>\n",
    "reconstr-loss: set reduction to none and then take mean of losses per image in the total batch. This gives reconstr-loss per image for further computation<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import learn2learn as l2l\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from PIL.Image import LANCZOS\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/src',\n",
       " '/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.9.1001312534/pythonFiles',\n",
       " '/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.9.1001312534/pythonFiles/lib/python',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python38.zip',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/datasets-1.2.1-py3.8.egg',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/locket-0.2.1-py3.8.egg',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/home/anuj/.ipython',\n",
       " '/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append('/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from data.loaders import Omniglotmix, MiniImageNet\n",
    "from data.taskers import gen_tasks\n",
    "from src.zoo.archs import CCVAE, CEncoder, Classifier_VAE\n",
    "from src.zoo.delpo_utils import setup, inner_adapt_delpo, loss, accuracy\n",
    "from src.utils2 import Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tasks = gen_tasks(dataname='miniimagenet', root='../../dataset/mini_imagenet', mode='train', n_ways=5, k_shots=5, q_shots=15, image_transforms=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "classes = list(range(1623))\n",
    "random.shuffle(classes)\n",
    "image_transforms = transforms.Compose([transforms.Resize(28, interpolation=LANCZOS),\n",
    "                                                    transforms.ToTensor(),\n",
    "                                                    lambda x: 1.0 - x,\n",
    "                                                ])\n",
    "train_tasks = gen_tasks('omniglot', '/home/anuj/Desktop/Work/TU_Delft/research/implement/omniglot', image_transforms=image_transforms, n_ways=5, k_shots=5, q_shots=5, classes=classes[:1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = train_tasks.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2684,  0.5101,  0.3525, -0.2756,  0.0364,  0.2518,  0.0488, -0.1867,\n",
       "          0.3903, -0.1682,  0.4346, -0.3466, -0.4787, -0.0811, -0.0494,  0.0600,\n",
       "          0.4937,  1.0365, -0.9835,  0.5833,  0.5752,  0.7435, -0.2313, -0.0507,\n",
       "          0.4669, -0.4916, -0.5960, -0.0464, -0.7211, -0.6048,  0.3278,  0.2911,\n",
       "         -0.5268, -0.0178, -0.6828,  0.0753,  0.6817,  0.1579,  0.3840, -0.2426,\n",
       "         -0.0159,  0.1036, -0.1665, -0.3253,  0.5705, -0.3869,  0.2745, -0.5063,\n",
       "          0.1639,  0.4242,  0.5326,  0.0982,  0.7161,  0.7510,  0.0719, -0.1910,\n",
       "          0.2985,  0.4226,  0.2843,  0.0187,  0.2833, -0.6101,  0.5434,  0.2796],\n",
       "        [ 0.9444, -0.0394,  0.7175, -0.2272, -0.7262,  0.8960, -0.7549,  0.3189,\n",
       "         -0.4788,  0.2551,  0.3806,  1.1372, -0.3198, -0.3861, -0.3925,  0.6683,\n",
       "          0.1526,  1.2116, -1.0847,  0.7135, -0.0278,  0.6548,  0.2452,  1.0444,\n",
       "         -0.4580,  0.0427, -0.0952, -0.0762, -0.2499, -0.5090, -0.5563, -0.0489,\n",
       "         -0.1487,  0.4910,  0.0515,  0.3634,  0.3556,  0.1886,  0.4254,  0.1479,\n",
       "         -0.4502, -0.0550, -0.4000, -0.5456,  0.6392,  0.7774,  0.1181,  0.4654,\n",
       "          0.6830, -0.6312, -0.2214,  0.5474,  0.2066,  0.1626, -0.3057, -0.3409,\n",
       "          0.2951,  0.1692,  0.0258,  0.0777,  0.4196, -0.6885,  0.3339, -0.8172]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = torch.load('/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/logs/DELPO_miniimagenet_5-way_1-shot_1-queries/experiment/latents_epoch-0_train.pt')\n",
    "abc['style_latents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "n_ways = 2\n",
    "k_shots = 1\n",
    "q_shots = 1\n",
    "dataset = 'miniimagenet'\n",
    "root = '../../dataset/mini_imagenet'\n",
    "order = False\n",
    "inner_lr = 0.001\n",
    "meta_lr = 0.0001\n",
    "reconst_loss = nn.MSELoss(reduction='none')\n",
    "inner_adapt_steps_train = 5\n",
    "meta_batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler = Profiler('DELPO_{}_{}-way_{}-shot_{}-queries'.format('miniimagenet',\n",
    "                        5, 1, 1), 'experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tasks, valid_tasks, test_tasks, learner = setup(\n",
    "    dataset, root, n_ways, k_shots, q_shots, order, inner_lr, device, download='False')\n",
    "opt = optim.Adam(learner.parameters(), meta_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, wt_ce, klwt, rec_wt, beta_l, beta_s):\n",
    "        #args.wt_ce, args.klwt, args.rec_wt, args.beta_l, args.beta_s\n",
    "        self.wt_ce = wt_ce\n",
    "        self.klwt = klwt\n",
    "        self.rec_wt = rec_wt\n",
    "        self.beta_l = beta_l\n",
    "        self.beta_s = beta_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args(100, False, 0.01, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "ttask = train_tasks.sample()\n",
    "model = learner.clone()\n",
    "evaluation_loss, evaluation_accuracy, reconst_img, query_imgs, mu_l, log_var_l, mu_s, log_var_s = inner_adapt_delpo(\n",
    "                ttask, reconst_loss, model, n_ways, k_shots, q_shots, inner_adapt_steps_train, device, True, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_loss['elbo'].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x7f63240334a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a.item() for a in evaluation_loss.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [1, evaluation_accuracy.item()]\n",
    "tmp = tmp + [a.item() for a in evaluation_loss.values()]\n",
    "batch_losses.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  0.20000000298023224,\n",
       "  213.8948516845703,\n",
       "  15.829955101013184,\n",
       "  14.429597854614258,\n",
       "  2242.850830078125,\n",
       "  1.6120678186416626]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training ##\n",
    "for iter in range(2):\n",
    "    opt.zero_grad()\n",
    "    batch_losses = []\n",
    "\n",
    "    for batch in range(meta_batch_size):\n",
    "        ttask = train_tasks.sample()\n",
    "        model = learner.clone()\n",
    "        if (batch == 0):\n",
    "            evaluation_loss, evaluation_accuracy, reconst_img, query_imgs, mu_l, log_var_l, mu_s, log_var_s = inner_adapt_delpo(\n",
    "                ttask, reconst_loss, model, n_ways, k_shots, q_shots, inner_adapt_steps_train, device, True, args)\n",
    "            \n",
    "            # Logging train-task images and latents\n",
    "            di = {\"reconst_examples\": reconst_img.detach().to('cpu'), \"gt_examples\": query_imgs.detach().to('cpu')}\n",
    "            dl = {\"label_latents\": [mu_l.detach().to('cpu'), log_var_l.detach().to('cpu')],\n",
    "                  \"style_latents\": [mu_s.detach().to('cpu'), log_var_s.detach().to('cpu')]}\n",
    "            profiler.log_data(di, iter, 'images', 'train')\n",
    "            profiler.log_data(dl, iter, 'latents', 'train')\n",
    "\n",
    "        else:\n",
    "            evaluation_loss, evaluation_accuracy = inner_adapt_delpo(\n",
    "                ttask, reconst_loss, model, n_ways, k_shots, q_shots, inner_adapt_steps_train, device, False, args)\n",
    "\n",
    "        evaluation_loss['elbo'].backward()\n",
    "\n",
    "        # Logging per train-task losses and accuracies\n",
    "        tmp = [(iter*meta_batch_size)+batch, evaluation_accuracy.item()]\n",
    "        tmp = tmp + [a.item() for a in evaluation_loss.values()]\n",
    "        batch_losses.append(tmp)\n",
    "\n",
    "    #     wandb.log(dict({f\"train/{key}\": loss.item() for _, (key, loss) in enumerate(evaluation_loss.items())},\n",
    "    #               **{'train/accuracies': evaluation_accuracy.item(), 'train/task': (iter*args.meta_batch_size)+batch}))\n",
    "\n",
    "    # rimages = wandb.Image(reconst_img, caption=\"Reconstructed Query Images\")\n",
    "    # qimages = wandb.Image(query_imgs, caption=\"Query Images\")\n",
    "    # wandb.log({\"reconst_examples\": rimages, \"gt_examples\": qimages})\n",
    "\n",
    "    vtask = valid_tasks.sample()\n",
    "    model = learner.clone()\n",
    "    if iter % 2 == 0:\n",
    "        validation_loss, validation_accuracy, reconst_img, query_imgs, mu_l, log_var_l, mu_s, log_var_s = inner_adapt_delpo(\n",
    "            vtask, reconst_loss, model, n_ways, k_shots, q_shots, inner_adapt_steps_train, device, True, args)\n",
    "        # Logging valid-task images and latents\n",
    "        di = {\"reconst_examples\": reconst_img.to('cpu'), \"gt_examples\": query_imgs.to('cpu')}\n",
    "        dl = {\"label_latents\": [mu_l.to('cpu'), log_var_l.to('cpu')],\n",
    "            \"style_latents\": [mu_s.to('cpu'), log_var_s.to('cpu')]}\n",
    "        profiler.log_data(di, iter, 'images', 'valid')\n",
    "        profiler.log_data(dl, iter, 'latents', 'valid')\n",
    "\n",
    "    else:\n",
    "        validation_loss, validation_accuracy = inner_adapt_delpo(\n",
    "            vtask, reconst_loss, model, n_ways, k_shots, q_shots, inner_adapt_steps_train, device, False, args)\n",
    "\n",
    "    # Logging per validation-task losses and accuracies\n",
    "    tmp = [iter, validation_accuracy.item()]\n",
    "    tmp = tmp + [a.item() for a in validation_loss.values()]\n",
    "\n",
    "    # wandb.log(dict({f\"valid/{key}\": loss.item() for _, (key, loss) in enumerate(validation_loss.items())},\n",
    "    #           **{'valid/accuracies': validation_accuracy.item(), 'valid/task': iter}))\n",
    "\n",
    "    # Meta backpropagation of gradients\n",
    "    for p in learner.parameters():\n",
    "        p.grad.data.mul_(1.0 / meta_batch_size)\n",
    "    opt.step()\n",
    "\n",
    "    # Saving the Logs\n",
    "    profiler.log_csv(batch_losses, 'train')\n",
    "    profiler.log_csv(tmp, 'valid')\n",
    "\n",
    "#torch.save(learner, f='../repro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_var_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Testing ##\n",
    "print('Testing on held out classes')\n",
    "\n",
    "for i, tetask in enumerate(test_tasks):\n",
    "    # wandb.define_metric(\"accuracies\", summary=\"max\")\n",
    "    # wandb.define_metric(\"accuracies\", summary=\"mean\")\n",
    "\n",
    "    model = learner.clone()\n",
    "    #tetask = test_tasks.sample()\n",
    "    evaluation_loss, evaluation_accuracy = inner_adapt_delpo(\n",
    "        tetask, reconst_loss, model, args.n_ways, args.k_shots, args.q_shots, args.inner_adapt_steps_test, args.device, False, args)\n",
    "\n",
    "    # Logging per test-task losses and accuracies\n",
    "    tmp = [iter, evaluation_accuracy.item()]\n",
    "    tmp.append(a.item() for a in evaluation_loss.values())\n",
    "    profiler.log_csv(tmp, 'test')\n",
    "    # wandb.log(dict({f\"test/{key}\": loss.item() for _, (key, loss) in enumerate(evaluation_loss.items())},\n",
    "    #             **{'test/accuracies': evaluation_accuracy.item(), 'test/task': i}))\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m71"
  },
  "interpreter": {
   "hash": "7e3af266dcb7df8b026f0780dbb396b062ee5ca2767a18f50e60e26ee6084121"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('torch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
