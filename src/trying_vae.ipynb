{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "classifiers: nn.crossentropyloss = -log-likelihood --- use for logp(y) and -logq(y/x) for support <br>\n",
    "kl-div: <br>\n",
    "reconstr-loss: set reduction to none and then take mean of losses per image in the total batch. This gives reconstr-loss per image for further computation<br> "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import learn2learn as l2l\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from PIL.Image import LANCZOS\n",
    "from config import *\n",
    "\n",
    "import json\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "torch.cuda.is_available()\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "sys.path.append('/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn')\n",
    "sys.path"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/src',\n",
       " '/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/pythonFiles',\n",
       " '/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/pythonFiles/lib/python',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python38.zip',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/datasets-1.2.1-py3.8.egg',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/locket-0.2.1-py3.8.egg',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/home/anuj/.ipython',\n",
       " '/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#from data.loaders import Omniglotmix, MiniImageNet\n",
    "from data.taskers import gen_tasks\n",
    "from src.zoo.archs import CVAE, LVAE\n",
    "from src.zoo.lpo_utils import proto_distr, classify, set_sets, accuracy, inner_adapt_lpo, setup, kl_div\n",
    "\n",
    "#from src.utils import Profiler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_tasks = gen_tasks(dataname='miniimagenet', root='../../mini_imagenet', mode='train', n_ways=5, k_shots=1, q_shots=1, image_transforms=None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "classes = list(range(1623))\n",
    "random.shuffle(classes)\n",
    "image_transforms = transforms.Compose([transforms.Resize(28, interpolation=LANCZOS),\n",
    "                                                    transforms.ToTensor(),\n",
    "                                                    lambda x: 1.0 - x,\n",
    "                                                ])\n",
    "train_tasks = gen_tasks('omniglot', '/home/anuj/Desktop/Work/TU_Delft/research/implement/omniglot', image_transforms=image_transforms, n_ways=5, k_shots=5, q_shots=5, classes=classes[:1100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_tasks, valid_tasks, test_tasks, learner, learner_temp, embedder = setup('miniimagenet', '../../mini_imagenet', 5, 3, 7, 5, 3, 7, 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "task = train_tasks.sample()\n",
    "device = 'cpu'\n",
    "n_ways = 5\n",
    "k_shots = 3\n",
    "q_shots = 7"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "data, labels = task\n",
    "data, labels = data.to(device), labels.to(device)\n",
    "#data, labels = data.squeeze(0), labels.squeeze(0)\n",
    "sort = torch.sort(labels)\n",
    "data = data.squeeze(0)[sort.indices].squeeze(0)\n",
    "labels = labels.squeeze(0)[sort.indices].squeeze(0)\n",
    "total = n_ways * (k_shots + q_shots)\n",
    "queries_index = np.zeros(total)\n",
    "\n",
    "# Extracting the query datums from the entire task set\n",
    "for offset in range(n_ways):\n",
    "    queries_index[np.random.choice(\n",
    "        k_shots+q_shots, q_shots, replace=False) + ((k_shots + q_shots)*offset)] = True\n",
    "support = data[np.where(queries_index == 0)]\n",
    "support_labels = labels[np.where(queries_index == 0)]\n",
    "queries = data[np.where(queries_index == 1)]\n",
    "queries_labels = labels[np.where(queries_index == 1)]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "queries_labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n",
       "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "\n",
    "y_support = F.one_hot(support_labels, num_classes=n_ways)\n",
    "y_queries = torch.tensor(range(n_ways))\n",
    "y_queries = y_queries.repeat(n_ways*q_shots)\n",
    "y_queries = F.one_hot(y_queries, num_classes=n_ways)\n",
    "qs = queries.repeat_interleave(n_ways, dim=0)\n",
    "\n",
    "support, qs = embedder(support), embedder(qs)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "y_support.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([15, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "support_cap, support_mu, support_log_var = learner(support, y_support)\n",
    "support_mu"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 1.3663e-01,  2.4987e-02,  5.5654e-03, -9.8920e-03, -7.6280e-02,\n",
       "         -7.1484e-02, -1.0899e-01,  1.5873e-01, -1.1427e-01, -6.6355e-02,\n",
       "         -1.4163e-01,  1.7571e-02,  6.9741e-02,  1.1391e-01,  9.5002e-02,\n",
       "          2.6588e-02, -7.3195e-02,  2.3054e-01, -2.5127e-02, -3.4086e-02,\n",
       "         -4.2776e-02, -9.1617e-02,  7.0079e-03,  4.8824e-02, -9.7244e-02,\n",
       "          6.5436e-02, -4.2479e-02,  1.9061e-01,  7.1781e-02,  2.2788e-01,\n",
       "          7.2408e-02,  2.1769e-02, -2.3030e-02,  2.0740e-01,  1.3754e-01,\n",
       "          8.9016e-02, -2.4195e-01, -2.6483e-02, -2.6474e-01,  1.8368e-02,\n",
       "         -6.4890e-02, -5.7888e-02,  9.3043e-02,  8.5093e-02,  4.8365e-02,\n",
       "         -5.6663e-02,  4.0189e-02, -2.8450e-02, -1.3092e-01,  1.8675e-01,\n",
       "         -1.3265e-01, -7.3903e-03, -1.6466e-01,  3.8370e-02, -2.8796e-01,\n",
       "         -5.6105e-02, -4.8747e-02,  1.3053e-01, -3.3306e-02, -5.2846e-02,\n",
       "         -2.6578e-02,  6.0663e-02, -4.4995e-02,  5.4612e-02],\n",
       "        [ 1.6521e-01,  2.6701e-02, -1.0535e-02, -3.7108e-02, -1.0576e-01,\n",
       "         -9.3357e-02, -9.0165e-02,  1.1237e-01, -1.2253e-01, -6.4975e-02,\n",
       "         -1.4389e-01, -4.9910e-03,  5.3389e-02,  1.2103e-01,  1.0221e-01,\n",
       "          5.4722e-02, -8.4778e-02,  2.4290e-01, -3.4266e-02, -5.0682e-02,\n",
       "         -6.8620e-02, -7.5596e-02,  2.8096e-02,  4.9107e-02, -9.3843e-02,\n",
       "          5.2103e-02, -3.6805e-02,  2.2961e-01,  5.3987e-02,  2.2314e-01,\n",
       "          6.4221e-02,  4.7536e-02, -1.6037e-02,  2.4067e-01,  1.6465e-01,\n",
       "          8.3020e-02, -2.4111e-01, -2.4812e-02, -2.8159e-01,  3.0698e-02,\n",
       "         -2.2136e-02, -4.1879e-02,  6.3594e-02,  7.6622e-02,  6.9812e-02,\n",
       "         -4.4232e-02,  4.5749e-02, -2.5817e-02, -1.1848e-01,  1.9127e-01,\n",
       "         -1.6806e-01, -2.5027e-02, -1.7703e-01,  3.9216e-02, -2.9516e-01,\n",
       "         -7.0278e-02, -1.8192e-02,  1.3151e-01, -3.2949e-02, -6.6274e-02,\n",
       "         -6.0514e-02,  7.4205e-02, -5.0354e-02,  5.4819e-02],\n",
       "        [ 1.4100e-01, -4.3444e-02, -2.5826e-02,  1.0066e-02, -3.8487e-02,\n",
       "         -2.1441e-02, -9.9746e-02,  1.1156e-01, -9.2353e-02, -2.2916e-02,\n",
       "         -1.4282e-01,  4.3273e-02,  6.0082e-02,  7.5290e-02,  2.9439e-02,\n",
       "          4.7626e-02, -9.3119e-02,  1.7583e-01, -5.0386e-02, -4.4226e-02,\n",
       "         -5.0985e-02, -9.5975e-02, -3.3765e-03,  3.1370e-02, -1.0853e-01,\n",
       "          3.8573e-02, -4.7426e-02,  1.5840e-01,  3.9207e-02,  1.8749e-01,\n",
       "          6.1508e-02,  8.8510e-03, -5.6324e-02,  1.2523e-01,  9.4044e-02,\n",
       "          4.9703e-02, -2.2242e-01, -1.0762e-02, -2.2780e-01,  2.3292e-02,\n",
       "         -8.7135e-03, -8.4481e-02,  6.0936e-02,  7.2029e-02,  5.7326e-02,\n",
       "         -2.7621e-02,  7.5998e-03,  1.2941e-02, -9.8162e-02,  1.6415e-01,\n",
       "         -1.1181e-01, -3.6816e-02, -1.4642e-01,  2.2383e-03, -2.0189e-01,\n",
       "         -7.5403e-02, -4.6692e-02,  1.1225e-01, -5.1992e-02, -6.4997e-02,\n",
       "         -3.8714e-02,  3.0859e-02, -4.4034e-02,  6.6124e-02],\n",
       "        [ 1.5522e-01, -2.1414e-02, -4.5835e-02, -9.6340e-03, -3.9878e-02,\n",
       "         -5.5716e-02, -1.1120e-01,  1.2830e-01, -1.0049e-01, -5.1508e-02,\n",
       "         -1.4235e-01,  3.6624e-02,  6.8631e-02,  1.0257e-01,  8.4532e-02,\n",
       "          5.4354e-02, -6.2282e-02,  2.1183e-01, -3.6339e-02, -3.2508e-02,\n",
       "         -6.1826e-02, -7.1533e-02,  1.7478e-03,  1.4600e-02, -1.0991e-01,\n",
       "          3.3279e-02, -4.9961e-02,  1.8099e-01,  5.5901e-02,  2.0694e-01,\n",
       "          5.1765e-02,  2.6854e-02, -3.3870e-02,  1.8071e-01,  1.1041e-01,\n",
       "          6.1242e-02, -2.3724e-01, -1.6701e-02, -2.5958e-01,  1.9588e-02,\n",
       "         -2.6711e-02, -6.6191e-02,  7.5550e-02,  8.0082e-02,  8.9208e-02,\n",
       "         -2.2949e-02,  4.1297e-03,  1.1833e-02, -1.2446e-01,  1.9803e-01,\n",
       "         -1.3231e-01, -2.0972e-02, -1.3468e-01,  2.5191e-02, -2.3474e-01,\n",
       "         -7.2624e-02, -5.0189e-02,  9.5185e-02, -6.9437e-02, -6.6539e-02,\n",
       "         -4.3299e-02,  3.6470e-02, -4.3383e-02,  5.2994e-02],\n",
       "        [ 1.3759e-01, -7.0420e-02, -3.5448e-02,  2.5122e-03,  1.3071e-02,\n",
       "         -2.8176e-02, -9.5105e-02,  1.1961e-01, -8.5097e-02, -5.7092e-02,\n",
       "         -1.1976e-01,  6.0566e-02,  6.4183e-02,  1.2006e-01,  3.1021e-02,\n",
       "          2.9853e-02, -8.9373e-02,  1.5358e-01, -8.3965e-02, -5.2000e-02,\n",
       "         -9.0714e-02, -8.6507e-02,  1.0970e-02,  1.5945e-02, -1.0587e-01,\n",
       "         -8.7109e-03, -3.4144e-02,  1.3177e-01,  6.7927e-02,  2.0246e-01,\n",
       "          7.1955e-02,  4.3037e-02, -5.7671e-02,  1.3456e-01,  7.5924e-02,\n",
       "          5.5142e-02, -2.3697e-01, -1.7570e-02, -2.1599e-01,  2.8958e-02,\n",
       "          3.0974e-02, -5.8577e-02,  7.3064e-02,  7.4911e-02,  6.0158e-02,\n",
       "         -4.2122e-02, -2.4658e-02,  1.3125e-02, -9.9910e-02,  1.6614e-01,\n",
       "         -1.2368e-01, -3.3137e-03, -1.5018e-01,  4.1624e-03, -1.5098e-01,\n",
       "         -5.9783e-02, -6.3655e-02,  7.3864e-02, -7.1348e-02, -8.1473e-02,\n",
       "         -1.0294e-02,  3.5653e-02, -4.7098e-02,  5.4574e-02],\n",
       "        [ 1.6013e-01, -8.3555e-02, -2.2252e-03, -1.7177e-02,  1.3212e-02,\n",
       "         -3.1266e-02, -1.2105e-01,  1.2247e-01, -9.5398e-02, -7.0273e-03,\n",
       "         -1.1599e-01,  5.9608e-02,  8.6298e-02,  8.7754e-02,  4.5038e-02,\n",
       "          5.1492e-02, -6.6231e-02,  1.8388e-01, -2.1137e-02, -8.8385e-02,\n",
       "         -5.4267e-02, -9.0494e-02, -6.1038e-03,  2.1343e-02, -1.3471e-01,\n",
       "          4.4958e-02, -5.2967e-02,  1.3038e-01,  2.9848e-02,  1.9341e-01,\n",
       "          4.8976e-02,  3.0472e-02, -4.3554e-02,  1.2382e-01,  9.0939e-02,\n",
       "          6.7164e-02, -2.2145e-01, -2.4603e-02, -2.0348e-01,  7.1585e-02,\n",
       "         -2.1648e-02, -5.2612e-02,  1.1743e-01,  8.8101e-02,  4.7880e-02,\n",
       "         -1.3586e-02, -2.3058e-02,  2.6075e-02, -9.1980e-02,  1.5273e-01,\n",
       "         -6.4939e-02, -3.7850e-02, -1.7071e-01,  2.4091e-02, -1.6794e-01,\n",
       "         -6.1897e-02, -6.1079e-02,  1.0340e-01, -1.0767e-01, -7.3455e-02,\n",
       "         -1.1065e-02,  5.4726e-02, -3.5915e-02,  5.5671e-02],\n",
       "        [ 1.6940e-01, -5.4910e-02, -2.0581e-02, -3.0312e-02, -1.4351e-02,\n",
       "         -2.1199e-02, -5.3638e-02,  1.2907e-01, -1.0934e-01, -5.2339e-02,\n",
       "         -1.1993e-01,  1.9812e-02,  5.4667e-02,  1.2322e-01,  9.2304e-03,\n",
       "          1.0319e-02, -1.1860e-01,  1.2677e-01, -8.1588e-02, -8.3352e-02,\n",
       "         -8.0301e-02, -7.1065e-02,  2.5925e-02,  3.9956e-02, -5.9301e-02,\n",
       "          1.0963e-02, -2.3214e-02,  1.5686e-01,  4.3370e-02,  2.3978e-01,\n",
       "          6.7107e-02,  3.9076e-02, -5.4505e-02,  1.4838e-01,  9.1811e-02,\n",
       "          5.6499e-02, -2.4431e-01, -2.9515e-02, -2.3333e-01,  1.0765e-02,\n",
       "          3.8754e-02, -7.5528e-02,  6.3463e-02,  7.8988e-02,  3.2762e-02,\n",
       "         -4.4202e-02, -1.1022e-02,  1.4962e-02, -6.8171e-02,  1.6867e-01,\n",
       "         -9.9363e-02, -4.6716e-02, -1.6677e-01, -9.4468e-03, -1.2959e-01,\n",
       "         -9.5858e-02, -6.8639e-02,  9.3338e-02, -7.5348e-02, -9.0456e-02,\n",
       "         -1.3850e-02,  1.1948e-02, -5.0095e-02,  4.3715e-02],\n",
       "        [ 1.3098e-01, -1.5090e-02, -4.0618e-02, -3.4300e-03, -5.1500e-02,\n",
       "         -2.5528e-02, -1.2862e-01,  1.4184e-01, -9.4637e-02, -3.3834e-02,\n",
       "         -1.4406e-01,  4.8494e-02,  6.1359e-02,  9.9036e-02,  8.2379e-02,\n",
       "          6.9732e-02, -8.3241e-02,  1.8881e-01, -4.6509e-02, -4.7700e-02,\n",
       "         -4.3699e-02, -6.2093e-02, -2.0260e-03,  2.6102e-02, -1.1672e-01,\n",
       "          3.3476e-02, -5.6912e-02,  1.7539e-01,  4.9148e-02,  1.8539e-01,\n",
       "          6.2856e-02,  2.3682e-02, -2.8015e-02,  1.6784e-01,  1.1766e-01,\n",
       "          6.2857e-02, -2.3642e-01, -1.4312e-02, -2.3608e-01,  3.2639e-02,\n",
       "         -3.3357e-02, -6.7444e-02,  7.1563e-02,  7.9127e-02,  5.6039e-02,\n",
       "         -4.9892e-02, -1.0097e-02,  1.3178e-02, -9.6606e-02,  1.6825e-01,\n",
       "         -1.2637e-01, -1.3511e-02, -1.4372e-01,  7.2211e-03, -2.1482e-01,\n",
       "         -6.1727e-02, -5.8337e-02,  1.1322e-01, -5.9482e-02, -7.6934e-02,\n",
       "         -3.2476e-02,  2.2869e-02, -2.8749e-02,  5.3243e-02],\n",
       "        [ 1.3718e-01, -4.6922e-02, -3.4399e-02, -5.9427e-03, -3.1411e-02,\n",
       "         -2.3292e-02, -1.0260e-01,  1.2861e-01, -1.1446e-01, -5.3220e-02,\n",
       "         -1.3384e-01,  2.9818e-02,  6.6215e-02,  9.7018e-02,  6.8421e-02,\n",
       "          3.8560e-02, -8.1745e-02,  2.0559e-01, -6.3233e-02, -4.8675e-02,\n",
       "         -6.1714e-02, -9.4315e-02,  1.3120e-02,  1.8785e-02, -9.7702e-02,\n",
       "          3.3706e-02, -5.4926e-02,  1.6441e-01,  6.5235e-02,  2.0331e-01,\n",
       "          6.9252e-02,  2.9910e-02, -4.2594e-02,  1.6957e-01,  9.9406e-02,\n",
       "          5.4077e-02, -2.3944e-01, -1.9509e-02, -2.4183e-01,  1.8090e-02,\n",
       "         -1.8826e-02, -8.0456e-02,  7.8010e-02,  7.5268e-02,  6.8762e-02,\n",
       "         -3.6103e-02, -1.2916e-02,  1.5825e-02, -9.9635e-02,  1.8056e-01,\n",
       "         -1.2451e-01, -3.2033e-02, -1.4338e-01,  5.2715e-04, -2.0825e-01,\n",
       "         -9.0869e-02, -5.4239e-02,  1.2325e-01, -5.6831e-02, -8.7361e-02,\n",
       "         -3.1479e-02,  2.8980e-02, -3.8465e-02,  4.4768e-02],\n",
       "        [ 1.3557e-01, -4.9887e-02, -2.6259e-02,  1.6890e-03, -3.1251e-02,\n",
       "         -4.2932e-02, -1.1216e-01,  1.2601e-01, -9.5368e-02, -2.1731e-02,\n",
       "         -1.4185e-01,  4.6890e-02,  6.5123e-02,  1.0436e-01,  7.1680e-02,\n",
       "          4.7685e-02, -7.3490e-02,  1.6671e-01, -4.7409e-02, -4.9356e-02,\n",
       "         -4.9225e-02, -6.2732e-02,  1.1680e-02,  7.5103e-03, -1.0630e-01,\n",
       "          3.7938e-02, -4.4502e-02,  1.4564e-01,  2.8123e-02,  1.8894e-01,\n",
       "          5.4807e-02,  5.4796e-02, -4.3621e-02,  1.6929e-01,  8.9843e-02,\n",
       "          4.9368e-02, -2.3234e-01, -1.6046e-02, -2.1013e-01,  2.8455e-02,\n",
       "         -3.2451e-02, -6.6082e-02,  9.4173e-02,  7.5056e-02,  4.9158e-02,\n",
       "         -5.4766e-02, -1.4443e-02,  2.9082e-02, -9.2837e-02,  1.7188e-01,\n",
       "         -1.1757e-01, -2.1362e-02, -1.3324e-01,  1.0302e-02, -2.1101e-01,\n",
       "         -7.3125e-02, -6.3070e-02,  1.2975e-01, -6.7791e-02, -8.1553e-02,\n",
       "         -2.0642e-02,  1.0390e-02, -3.5617e-02,  4.7385e-02],\n",
       "        [ 1.4448e-01,  2.5693e-02, -7.0466e-02, -1.3675e-02, -7.3452e-02,\n",
       "         -4.2979e-02, -1.1245e-01,  1.1220e-01, -1.0633e-01, -5.2869e-02,\n",
       "         -1.3994e-01, -1.7300e-02,  5.3861e-02,  1.0833e-01,  3.5468e-02,\n",
       "          7.1528e-02, -7.4713e-02,  2.1234e-01, -5.6166e-02, -5.6518e-02,\n",
       "         -2.8683e-02, -8.9083e-02,  4.5160e-03,  5.4563e-02, -1.2545e-01,\n",
       "          2.0458e-02, -6.4751e-02,  1.9087e-01,  3.8848e-02,  1.8975e-01,\n",
       "          6.0669e-02,  2.7954e-02, -3.2822e-02,  1.8776e-01,  1.3168e-01,\n",
       "          4.1724e-02, -2.3383e-01,  1.9664e-03, -2.5022e-01,  3.1137e-02,\n",
       "         -2.9625e-03, -8.5545e-02,  4.1931e-02,  6.9178e-02,  7.6658e-02,\n",
       "         -4.2162e-02,  5.3110e-02, -9.4626e-03, -1.3283e-01,  1.6815e-01,\n",
       "         -1.3937e-01, -3.0955e-02, -1.6006e-01,  5.3992e-03, -2.3891e-01,\n",
       "         -4.9650e-02, -5.4248e-02,  5.5558e-02, -4.7579e-02, -3.1854e-02,\n",
       "         -4.6123e-02,  2.3735e-02, -3.8427e-02,  6.7300e-02],\n",
       "        [ 1.4730e-01, -5.2498e-02, -2.5230e-02, -5.2910e-03, -1.5555e-02,\n",
       "         -3.5228e-02, -1.0678e-01,  1.2427e-01, -9.8386e-02, -5.4013e-02,\n",
       "         -1.3440e-01,  5.0173e-02,  4.7021e-02,  9.8607e-02,  3.7067e-02,\n",
       "          3.9768e-02, -1.0623e-01,  1.8445e-01, -5.3714e-02, -4.7857e-02,\n",
       "         -6.1447e-02, -9.1731e-02,  1.2960e-02,  2.7691e-02, -1.0655e-01,\n",
       "          8.1680e-03, -3.1586e-02,  1.4370e-01,  3.8930e-02,  2.0358e-01,\n",
       "          3.2940e-02,  4.3647e-02, -4.6122e-02,  1.4504e-01,  9.7107e-02,\n",
       "          6.1332e-02, -2.3433e-01, -1.0541e-02, -2.3920e-01,  2.1623e-02,\n",
       "          6.1881e-03, -7.9503e-02,  6.4306e-02,  9.9358e-02,  6.0527e-02,\n",
       "         -3.5806e-02,  9.1189e-04,  2.4114e-02, -8.9525e-02,  1.7358e-01,\n",
       "         -1.1382e-01, -2.2196e-02, -1.6028e-01,  1.5334e-03, -1.8233e-01,\n",
       "         -7.2915e-02, -4.5512e-02,  1.1831e-01, -5.4494e-02, -7.0701e-02,\n",
       "         -3.0573e-02,  2.6100e-02, -5.1852e-02,  4.4040e-02],\n",
       "        [ 1.3570e-01, -6.5563e-02, -5.6614e-02,  3.3749e-03, -7.2088e-03,\n",
       "         -2.7219e-02, -1.0399e-01,  1.2056e-01, -8.2504e-02, -5.9947e-02,\n",
       "         -1.3733e-01,  5.4059e-02,  5.6111e-02,  8.4622e-02,  4.9329e-02,\n",
       "          2.8830e-02, -8.0403e-02,  1.7519e-01, -4.0087e-02, -3.8249e-02,\n",
       "         -7.4019e-02, -8.2769e-02,  1.1167e-02,  1.4255e-03, -1.2476e-01,\n",
       "         -1.4712e-02, -3.9826e-02,  1.2656e-01,  4.1023e-02,  1.8541e-01,\n",
       "          3.6601e-02,  4.3782e-02, -4.4070e-02,  1.4058e-01,  6.0671e-02,\n",
       "          7.1958e-02, -2.3120e-01, -4.8668e-03, -2.1100e-01,  1.7839e-02,\n",
       "          8.3373e-03, -5.4609e-02,  5.9697e-02,  8.5521e-02,  7.1796e-02,\n",
       "         -1.2436e-02, -8.4592e-03,  2.0499e-02, -1.1979e-01,  1.8173e-01,\n",
       "         -1.1552e-01, -1.2333e-02, -1.4522e-01, -8.6421e-03, -1.6672e-01,\n",
       "         -4.7658e-02, -4.3573e-02,  7.4059e-02, -5.7374e-02, -7.5212e-02,\n",
       "         -4.3673e-02,  1.6319e-02, -5.2160e-02,  4.4250e-02],\n",
       "        [ 1.4944e-01,  7.2369e-02, -1.7431e-02, -2.6759e-02, -1.0636e-01,\n",
       "         -8.2888e-02, -1.0787e-01,  1.6329e-01, -1.3727e-01, -8.5934e-02,\n",
       "         -1.4756e-01, -1.5050e-02,  5.1190e-02,  1.2041e-01,  9.8668e-02,\n",
       "          5.8354e-02, -9.3249e-02,  2.4861e-01, -4.4901e-02, -2.6585e-02,\n",
       "         -3.9447e-02, -8.0045e-02,  4.6438e-03,  6.1890e-02, -1.0597e-01,\n",
       "          7.0439e-02, -5.6558e-02,  2.4431e-01,  8.9463e-02,  2.4882e-01,\n",
       "          8.5965e-02,  3.2360e-02,  4.2407e-03,  2.6066e-01,  1.6611e-01,\n",
       "          8.0851e-02, -2.5629e-01, -1.7404e-03, -3.0175e-01,  2.7157e-02,\n",
       "         -6.6211e-02, -4.0781e-02,  6.0286e-02,  6.9890e-02,  5.8174e-02,\n",
       "         -5.9359e-02,  7.2858e-02, -6.3587e-02, -1.6003e-01,  1.7955e-01,\n",
       "         -1.9303e-01,  1.4890e-03, -1.5688e-01,  2.0418e-02, -3.2443e-01,\n",
       "         -5.0582e-02, -3.8451e-02,  1.0726e-01, -2.5557e-02, -5.6368e-02,\n",
       "         -6.2697e-02,  7.8184e-02, -4.5194e-02,  7.1005e-02],\n",
       "        [ 1.2225e-01, -1.0245e-02, -5.2965e-02,  2.1731e-02, -5.2741e-02,\n",
       "         -1.9684e-02, -1.5075e-01,  1.1069e-01, -1.0441e-01, -3.2861e-02,\n",
       "         -1.6711e-01,  4.1293e-02,  1.0055e-01,  8.5731e-02,  4.2365e-02,\n",
       "          9.0645e-02, -1.0912e-01,  1.4134e-01, -6.4400e-02, -8.7918e-02,\n",
       "         -9.2038e-03, -4.7598e-02, -2.8776e-02,  5.1360e-02, -8.3271e-02,\n",
       "          4.1131e-02, -7.4764e-02,  1.8864e-01, -7.2175e-03,  2.1556e-01,\n",
       "          5.4895e-02,  1.5941e-02, -2.2215e-02,  1.5749e-01,  1.2804e-01,\n",
       "          3.5271e-02, -2.0402e-01, -3.7222e-02, -2.1239e-01, -2.2997e-02,\n",
       "         -2.8252e-02, -6.6802e-02,  7.6954e-02,  1.0793e-01,  1.7438e-02,\n",
       "         -4.3562e-02,  2.5117e-02, -2.8154e-04, -1.0127e-01,  1.3531e-01,\n",
       "         -1.1665e-01, -2.0423e-02, -1.4906e-01, -8.2510e-03, -1.9701e-01,\n",
       "         -1.0359e-01, -6.1777e-02,  1.2618e-01, -1.7531e-02, -9.0058e-02,\n",
       "         -3.3293e-02, -1.3701e-02, -6.4986e-03,  9.9875e-02]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Building Prototypical distributions\n",
    "proto_mu, proto_var = proto_distr(\n",
    "    support_mu, support_log_var, n_ways, k_shots, 'precision_weighted')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "proto_var.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 64])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "proto_mu.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 64])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "\n",
    "# Forward pass on the Query datums\n",
    "queries_cap, queries_mu, queries_log_var = learner(qs, y_queries)\n",
    "queries_cap"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.0181,  0.1320,  0.1416,  ...,  0.1404,  0.1503, -0.0212],\n",
       "        [ 0.0554,  0.1279,  0.0390,  ...,  0.0312,  0.1333,  0.0928],\n",
       "        [ 0.1802,  0.1755,  0.0260,  ...,  0.0782,  0.0141, -0.0260],\n",
       "        ...,\n",
       "        [ 0.1379,  0.2035,  0.0282,  ...,  0.1016,  0.0877,  0.0401],\n",
       "        [-0.0352,  0.1227,  0.0220,  ...,  0.0677,  0.1188, -0.0588],\n",
       "        [ 0.1649,  0.1123,  0.1100,  ...,  0.0597,  0.1080, -0.0852]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "support_mu.unsqueeze(1).expand(a,b,-1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 0.1366,  0.0250,  0.0056,  ...,  0.0607, -0.0450,  0.0546],\n",
       "         [ 0.1366,  0.0250,  0.0056,  ...,  0.0607, -0.0450,  0.0546],\n",
       "         [ 0.1366,  0.0250,  0.0056,  ...,  0.0607, -0.0450,  0.0546],\n",
       "         [ 0.1366,  0.0250,  0.0056,  ...,  0.0607, -0.0450,  0.0546],\n",
       "         [ 0.1366,  0.0250,  0.0056,  ...,  0.0607, -0.0450,  0.0546]],\n",
       "\n",
       "        [[ 0.1652,  0.0267, -0.0105,  ...,  0.0742, -0.0504,  0.0548],\n",
       "         [ 0.1652,  0.0267, -0.0105,  ...,  0.0742, -0.0504,  0.0548],\n",
       "         [ 0.1652,  0.0267, -0.0105,  ...,  0.0742, -0.0504,  0.0548],\n",
       "         [ 0.1652,  0.0267, -0.0105,  ...,  0.0742, -0.0504,  0.0548],\n",
       "         [ 0.1652,  0.0267, -0.0105,  ...,  0.0742, -0.0504,  0.0548]],\n",
       "\n",
       "        [[ 0.1410, -0.0434, -0.0258,  ...,  0.0309, -0.0440,  0.0661],\n",
       "         [ 0.1410, -0.0434, -0.0258,  ...,  0.0309, -0.0440,  0.0661],\n",
       "         [ 0.1410, -0.0434, -0.0258,  ...,  0.0309, -0.0440,  0.0661],\n",
       "         [ 0.1410, -0.0434, -0.0258,  ...,  0.0309, -0.0440,  0.0661],\n",
       "         [ 0.1410, -0.0434, -0.0258,  ...,  0.0309, -0.0440,  0.0661]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.1357, -0.0656, -0.0566,  ...,  0.0163, -0.0522,  0.0442],\n",
       "         [ 0.1357, -0.0656, -0.0566,  ...,  0.0163, -0.0522,  0.0442],\n",
       "         [ 0.1357, -0.0656, -0.0566,  ...,  0.0163, -0.0522,  0.0442],\n",
       "         [ 0.1357, -0.0656, -0.0566,  ...,  0.0163, -0.0522,  0.0442],\n",
       "         [ 0.1357, -0.0656, -0.0566,  ...,  0.0163, -0.0522,  0.0442]],\n",
       "\n",
       "        [[ 0.1494,  0.0724, -0.0174,  ...,  0.0782, -0.0452,  0.0710],\n",
       "         [ 0.1494,  0.0724, -0.0174,  ...,  0.0782, -0.0452,  0.0710],\n",
       "         [ 0.1494,  0.0724, -0.0174,  ...,  0.0782, -0.0452,  0.0710],\n",
       "         [ 0.1494,  0.0724, -0.0174,  ...,  0.0782, -0.0452,  0.0710],\n",
       "         [ 0.1494,  0.0724, -0.0174,  ...,  0.0782, -0.0452,  0.0710]],\n",
       "\n",
       "        [[ 0.1223, -0.0102, -0.0530,  ..., -0.0137, -0.0065,  0.0999],\n",
       "         [ 0.1223, -0.0102, -0.0530,  ..., -0.0137, -0.0065,  0.0999],\n",
       "         [ 0.1223, -0.0102, -0.0530,  ..., -0.0137, -0.0065,  0.0999],\n",
       "         [ 0.1223, -0.0102, -0.0530,  ..., -0.0137, -0.0065,  0.0999],\n",
       "         [ 0.1223, -0.0102, -0.0530,  ..., -0.0137, -0.0065,  0.0999]]],\n",
       "       grad_fn=<ExpandBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "a = queries_mu.shape[0]\n",
    "b = proto_mu.shape[0]\n",
    "\n",
    "# delta.t * Q**-1 * delta\n",
    "\n",
    "delta = queries_mu.unsqueeze(1).expand(a,b,-1) - proto_mu.unsqueeze(0).expand(a,b,-1)\n",
    "logits = -0.5 * torch.mul(torch.mul(delta, proto_var.unsqueeze(0).expand(a,b,-1)**(-1)), delta).sum(dim=-1)\n",
    "logits.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([175, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "\n",
    "support_logits = classify(\n",
    "    mu_p=proto_mu, var_p=proto_var, mu_datums=support_mu)\n",
    "queries_logits = classify(\n",
    "    mu_p=proto_mu, var_p=proto_var, mu_datums=queries_mu)\n",
    "support_logits"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-23.6021, -23.6018, -23.6142, -23.5726, -23.5880],\n",
       "        [-23.5873, -23.5628, -23.4816, -23.4948, -23.4916],\n",
       "        [-23.5813, -23.5522, -23.5197, -23.5076, -23.5279],\n",
       "        [-23.5949, -23.5359, -23.5181, -23.5067, -23.5110],\n",
       "        [-23.5810, -23.5382, -23.5119, -23.5014, -23.5085],\n",
       "        [-23.6005, -23.5409, -23.5303, -23.5203, -23.5227],\n",
       "        [-23.6427, -23.6106, -23.4794, -23.5159, -23.4984],\n",
       "        [-23.6293, -23.5917, -23.4693, -23.5036, -23.4954],\n",
       "        [-23.6215, -23.5772, -23.4727, -23.4979, -23.4884],\n",
       "        [-23.6039, -23.5669, -23.5206, -23.5002, -23.5154],\n",
       "        [-23.5838, -23.5446, -23.4925, -23.4868, -23.4953],\n",
       "        [-23.6467, -23.6168, -23.4848, -23.5051, -23.4993],\n",
       "        [-23.6246, -23.5816, -23.5140, -23.5177, -23.4837],\n",
       "        [-23.6001, -23.5622, -23.4982, -23.4963, -23.4792],\n",
       "        [-23.6877, -23.6445, -23.4968, -23.5423, -23.5072]],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "\n",
    "# adding up the losses\n",
    "ce_loss = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "reconstruction_loss = nn.MSELoss(reduction='none')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "\n",
    "L_support = -reconstruction_loss(support_cap, support).view(support.shape[0], -1).mean(dim=1) - ce_loss(\n",
    "    F.softmax(torch.ones_like(y_support).float(), dim=1), torch.argmax(y_support, dim=1)) - kl_div(support_mu, support_log_var)  # = -L(x_s, y_s)\n",
    "L_support"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-2.5833, -3.0038, -2.8290, -2.5975, -2.6868, -2.6668, -3.2976, -3.0719,\n",
       "        -2.9612, -2.6229, -2.8146, -3.3088, -2.8344, -2.8077, -3.4454],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "\n",
    "L_queries = -reconstruction_loss(queries_cap, qs).view(qs.shape[0], -1).mean(dim=1) - ce_loss(\n",
    "    F.softmax(torch.ones_like(y_queries).float(), dim=1), torch.argmax(y_queries, dim=1)) - kl_div(queries_mu, queries_log_var)  # = -L(x_q, y_q)\n",
    "L_queries"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-2.7519, -2.7516, -2.7609, -2.7493, -2.7607, -2.6219, -2.6133, -2.6251,\n",
       "        -2.6283, -2.6194, -2.7640, -2.7708, -2.7782, -2.7780, -2.7817, -2.7049,\n",
       "        -2.6945, -2.7047, -2.7047, -2.7028, -2.6130, -2.6090, -2.6101, -2.6148,\n",
       "        -2.6060, -2.7029, -2.7020, -2.7052, -2.7152, -2.7026, -2.6540, -2.6356,\n",
       "        -2.6403, -2.6457, -2.6380, -2.5660, -2.5774, -2.5702, -2.5704, -2.5642,\n",
       "        -2.8104, -2.8126, -2.8134, -2.8128, -2.8140, -2.8794, -2.8642, -2.8698,\n",
       "        -2.8728, -2.8693, -2.9672, -2.9540, -2.9480, -2.9431, -2.9446, -2.9832,\n",
       "        -2.9816, -2.9821, -2.9812, -2.9750, -2.5828, -2.5861, -2.5875, -2.5781,\n",
       "        -2.5856, -2.8765, -2.8712, -2.8730, -2.8725, -2.8709, -2.7327, -2.7147,\n",
       "        -2.7157, -2.7129, -2.7193, -3.5113, -3.4952, -3.4876, -3.4819, -3.4779,\n",
       "        -2.5509, -2.5536, -2.5512, -2.5452, -2.5477, -2.7118, -2.7136, -2.7242,\n",
       "        -2.7072, -2.7143, -3.3958, -3.3839, -3.3937, -3.3829, -3.3937, -2.7552,\n",
       "        -2.7553, -2.7500, -2.7622, -2.7625, -3.6034, -3.5930, -3.5946, -3.6086,\n",
       "        -3.6056, -2.9572, -2.9554, -2.9530, -2.9648, -2.9650, -3.3585, -3.3411,\n",
       "        -3.3566, -3.3504, -3.3559, -2.6287, -2.6234, -2.6217, -2.6261, -2.6187,\n",
       "        -3.3443, -3.3340, -3.3453, -3.3456, -3.3366, -2.9700, -2.9656, -2.9668,\n",
       "        -2.9682, -2.9700, -2.9267, -2.9321, -2.9386, -2.9281, -2.9303, -2.7379,\n",
       "        -2.7326, -2.7403, -2.7353, -2.7363, -2.7281, -2.7239, -2.7386, -2.7275,\n",
       "        -2.7288, -2.8979, -2.8854, -2.8927, -2.8873, -2.8823, -2.6569, -2.6576,\n",
       "        -2.6539, -2.6719, -2.6602, -3.2795, -3.2551, -3.2695, -3.2739, -3.2655,\n",
       "        -3.3101, -3.3312, -3.3227, -3.3098, -3.3249, -2.6668, -2.6968, -2.6893,\n",
       "        -2.6744, -2.6790, -3.2009, -3.2041, -3.1976, -3.1984, -3.1929],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "yq = torch.argmax(y_queries, dim=1)\n",
    "yq.view(n_ways*q_shots, n_ways).t()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "        [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "         4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]])"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "L_queries.view(n_ways*q_shots, n_ways).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([35, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "U_queries = torch.mul(F.softmax(queries_logits, dim=1)[\n",
    "                        ::5, ], L_queries.view(n_ways*q_shots, n_ways)).sum(dim=1) - 0.1*torch.sum(torch.mul(F.softmax(queries_logits, dim=1)[\n",
    "                            ::5, ], torch.log(F.softmax(queries_logits, dim=1)[\n",
    "                                ::5, ])), dim=1)\n",
    "U_queries"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-2.5940, -2.4607, -2.6137, -2.5415, -2.4497, -2.5448, -2.4817, -2.4088,\n",
       "        -2.6518, -2.7102, -2.7902, -2.8197, -2.4231, -2.7119, -2.5580, -3.3294,\n",
       "        -2.3888, -2.5534, -3.2292, -2.5962, -3.4405, -2.7984, -3.1919, -2.4627,\n",
       "        -3.1805, -2.8073, -2.7704, -2.5756, -2.5687, -2.7281, -2.4993, -3.1080,\n",
       "        -3.1591, -2.5205, -3.0378], grad_fn=<SubBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "alpha = 0.1*(q_shots/k_shots)\n",
    "J_alpha = -L_support.mean() - U_queries.mean() + alpha * \\\n",
    "    ce_loss(support_logits, torch.argmax(y_support, dim=1)).mean()\n",
    "J_alpha"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(6.0066, grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_tasks, valid_tasks, test_tasks, learner, learner_temp, embedder = setup('miniimagenet', '../../mini_imagenet', 5, 3, 7, 5, 3, 7, 'cpu')\n",
    "\n",
    "device = 'cpu'\n",
    "n_ways = 5\n",
    "k_shots = 3\n",
    "q_shots = 7"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "loss = nn.MSELoss(reduction='none')\n",
    "## Training ##\n",
    "meta_train_loss = []\n",
    "meta_valid_loss = []\n",
    "meta_train_acc = []\n",
    "meta_valid_acc = []\n",
    "learner.train()\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LVAE(\n",
       "  (encoder): LEncoder(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (h1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (h2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  )\n",
       "  (decoder): LDecoder(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "learner_temp_state = copy.deepcopy(learner.state_dict())\n",
    "learner_temp.load_state_dict(learner_temp_state)\n",
    "opt = optim.Adam(learner_temp.parameters(), 0.001)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "[p for p in learner_temp.parameters()]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0108,  0.0243,  0.0185,  ..., -0.0164,  0.0236,  0.0374],\n",
       "         [ 0.0068,  0.0064, -0.0116,  ...,  0.0058,  0.0020,  0.0191],\n",
       "         [-0.0327,  0.0254, -0.0249,  ..., -0.0022,  0.0181,  0.0160],\n",
       "         ...,\n",
       "         [ 0.0349, -0.0221,  0.0433,  ...,  0.0178,  0.0242,  0.0199],\n",
       "         [ 0.0255,  0.0358, -0.0036,  ..., -0.0374,  0.0353, -0.0067],\n",
       "         [-0.0255,  0.0315,  0.0118,  ..., -0.0030,  0.0020,  0.0005]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 1.3028e-02, -3.7853e-02, -4.3363e-02,  2.5034e-02,  2.1001e-02,\n",
       "          3.0429e-02, -1.9690e-02, -4.4064e-02,  7.8055e-03,  1.2786e-02,\n",
       "         -4.1244e-02, -4.0994e-02,  1.8539e-02, -3.3859e-03, -5.5976e-03,\n",
       "         -2.7980e-02, -2.4508e-02, -1.3778e-02, -3.1488e-02,  2.7404e-02,\n",
       "          4.2747e-02, -1.2746e-02,  2.0945e-02,  1.1789e-02,  1.0178e-02,\n",
       "          5.0657e-03, -3.2606e-02,  7.6419e-03,  1.0938e-02,  4.3282e-02,\n",
       "         -4.0774e-03, -3.9221e-02,  2.7995e-02,  2.9974e-02, -2.0080e-02,\n",
       "          5.1581e-03,  1.0977e-02, -2.2941e-02, -1.6359e-02,  1.3408e-02,\n",
       "         -3.7971e-02,  4.0835e-03, -3.4791e-02, -1.8681e-02, -1.4372e-02,\n",
       "          4.0276e-02,  3.3049e-03, -3.5235e-02, -4.0212e-02, -3.4582e-02,\n",
       "          6.3961e-03, -2.7739e-02, -1.1579e-02,  1.7510e-02,  5.7920e-03,\n",
       "          1.2337e-02, -2.2277e-02,  1.8925e-02,  1.5877e-02,  2.3946e-02,\n",
       "         -4.2756e-02,  3.6554e-04, -1.6239e-02, -2.6552e-02,  1.2995e-02,\n",
       "          6.6763e-03, -8.7062e-03, -1.4466e-02, -2.4865e-02,  4.3006e-02,\n",
       "         -2.3823e-02,  1.1178e-02, -1.0703e-02,  4.3419e-03, -3.0426e-02,\n",
       "          2.2427e-02,  4.3299e-02, -1.9327e-02,  4.0963e-03,  2.5181e-02,\n",
       "          2.7926e-02,  9.0398e-03, -3.3982e-02, -2.2509e-02, -3.1507e-02,\n",
       "          5.0530e-03,  3.0388e-02,  1.3121e-02,  1.3249e-02, -1.7692e-02,\n",
       "         -7.7672e-03, -1.5035e-02,  3.0769e-02, -2.2105e-02,  2.2630e-02,\n",
       "         -3.5706e-02,  2.8463e-02,  3.5626e-02,  1.2047e-02,  8.2586e-03,\n",
       "         -3.4525e-02, -3.0932e-02,  2.5752e-02,  1.5484e-02, -4.3709e-02,\n",
       "          4.6641e-03, -7.7673e-03,  3.4862e-02, -1.9531e-02,  2.6847e-02,\n",
       "          3.2331e-02,  3.7418e-02, -9.9484e-03,  6.3375e-03, -1.8478e-02,\n",
       "         -3.4241e-02, -3.1248e-02,  3.4759e-02, -4.2040e-02, -1.3658e-02,\n",
       "         -2.1999e-02, -2.4598e-02, -1.2080e-02,  6.6850e-03, -2.9987e-02,\n",
       "          2.1093e-02,  2.5504e-02,  4.2729e-02, -2.2505e-03, -2.1353e-02,\n",
       "          2.5532e-03, -1.5947e-02, -2.5986e-02,  2.8922e-02, -2.2898e-02,\n",
       "         -3.2195e-05, -1.3493e-02, -2.8615e-02,  9.7745e-03, -2.0192e-02,\n",
       "         -2.4184e-02,  2.1117e-02, -1.4131e-02, -1.9057e-02, -1.2340e-02,\n",
       "         -4.0023e-02, -2.3222e-02,  3.1158e-02, -3.0530e-02,  1.4592e-02,\n",
       "         -1.8497e-02, -4.2080e-02, -7.0586e-03, -4.2848e-02, -1.5647e-02,\n",
       "         -5.0136e-03, -2.7459e-02, -1.8861e-02,  3.4418e-02,  1.3902e-02,\n",
       "         -2.8180e-02,  1.3258e-02,  2.6909e-02,  1.3396e-02, -1.7369e-02,\n",
       "         -4.4175e-02,  3.9270e-02,  3.0798e-03,  1.5471e-02, -2.4522e-02,\n",
       "         -1.1816e-04, -2.5890e-02, -3.9448e-02, -1.9325e-02, -8.7388e-03,\n",
       "         -2.0697e-02,  2.1341e-04,  4.0725e-02, -2.6892e-02,  4.2834e-02,\n",
       "         -4.3864e-02, -2.4500e-02, -3.9817e-02, -2.7600e-02, -4.0332e-02,\n",
       "          3.9035e-02, -1.6696e-02,  4.9515e-04,  3.0613e-02,  2.6923e-02,\n",
       "          3.0785e-02,  3.6288e-02,  5.3088e-03, -1.9846e-02,  2.1574e-02,\n",
       "          1.4037e-02, -3.0347e-02,  4.1062e-02, -2.5302e-02, -1.0305e-02,\n",
       "          2.2718e-02,  7.0306e-03, -3.1658e-02,  3.2341e-02, -3.1876e-02,\n",
       "         -1.7374e-02,  2.1883e-02,  4.0304e-02, -2.5916e-02, -3.8560e-03,\n",
       "         -6.9956e-03, -1.9174e-03,  2.9442e-02, -3.7217e-02,  4.3933e-02,\n",
       "          7.3553e-03, -4.6301e-03,  3.7275e-02, -5.7614e-03,  2.2223e-02,\n",
       "          1.0228e-02, -1.2247e-02, -2.6669e-02, -1.4257e-02,  9.1100e-04,\n",
       "         -1.4006e-02,  4.3237e-02, -3.0569e-02, -2.4042e-02,  3.2274e-02,\n",
       "          3.9654e-03, -2.2135e-02,  2.4147e-02,  3.7447e-02, -3.7084e-02,\n",
       "          3.6548e-02, -1.1539e-02, -2.8612e-02, -4.3721e-03,  2.4667e-02,\n",
       "         -1.9582e-02,  2.2585e-04,  2.3154e-02, -5.2551e-04,  9.6619e-03,\n",
       "         -1.6652e-02,  3.8063e-02, -2.1764e-02, -2.7924e-02, -1.2937e-03,\n",
       "          2.5935e-02, -2.6045e-02, -2.2423e-02, -3.4540e-02,  2.1154e-02,\n",
       "          1.9374e-02], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0551, -0.0455,  0.0335,  ...,  0.0199,  0.0176, -0.0604],\n",
       "         [-0.0465,  0.0284,  0.0171,  ...,  0.0206,  0.0069,  0.0217],\n",
       "         [ 0.0117, -0.0424, -0.0460,  ...,  0.0064, -0.0018, -0.0424],\n",
       "         ...,\n",
       "         [-0.0250,  0.0540,  0.0535,  ..., -0.0404, -0.0175,  0.0151],\n",
       "         [-0.0336,  0.0156,  0.0054,  ..., -0.0431,  0.0482, -0.0047],\n",
       "         [ 0.0396,  0.0019,  0.0352,  ..., -0.0598,  0.0129, -0.0013]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0299, -0.0587, -0.0499,  0.0562,  0.0366, -0.0354,  0.0155, -0.0503,\n",
       "         -0.0384,  0.0023,  0.0550, -0.0485,  0.0439, -0.0275,  0.0590, -0.0428,\n",
       "         -0.0342, -0.0289, -0.0498, -0.0295,  0.0114,  0.0237, -0.0513, -0.0613,\n",
       "         -0.0163,  0.0200, -0.0514,  0.0218,  0.0341,  0.0428,  0.0299,  0.0352,\n",
       "          0.0329,  0.0556, -0.0524,  0.0288, -0.0166, -0.0382,  0.0210, -0.0041,\n",
       "          0.0180, -0.0192,  0.0006, -0.0076,  0.0383, -0.0059, -0.0355,  0.0396,\n",
       "         -0.0128, -0.0266, -0.0216, -0.0109, -0.0468, -0.0259, -0.0040, -0.0489,\n",
       "         -0.0493,  0.0457,  0.0388,  0.0331, -0.0520,  0.0134, -0.0579, -0.0287,\n",
       "         -0.0058,  0.0429,  0.0187, -0.0542, -0.0129,  0.0111, -0.0607,  0.0240,\n",
       "          0.0039, -0.0065,  0.0598,  0.0606, -0.0383, -0.0247, -0.0610,  0.0444,\n",
       "          0.0096, -0.0286, -0.0286, -0.0502, -0.0170,  0.0406, -0.0435, -0.0240,\n",
       "          0.0323, -0.0318,  0.0346, -0.0254, -0.0581, -0.0541, -0.0468,  0.0575,\n",
       "         -0.0381, -0.0111,  0.0389, -0.0512,  0.0129, -0.0007, -0.0192, -0.0386,\n",
       "          0.0432, -0.0414, -0.0226, -0.0105,  0.0254, -0.0149,  0.0210,  0.0318,\n",
       "          0.0007, -0.0244, -0.0559,  0.0153,  0.0083,  0.0581,  0.0376, -0.0138,\n",
       "         -0.0157,  0.0141,  0.0286, -0.0269,  0.0461,  0.0326,  0.0213,  0.0487],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0065,  0.0117, -0.0258,  ...,  0.0551, -0.0315, -0.0501],\n",
       "         [-0.0477, -0.0265,  0.0667,  ...,  0.0331,  0.0539,  0.0585],\n",
       "         [ 0.0145, -0.0599, -0.0733,  ..., -0.0160,  0.0736, -0.0351],\n",
       "         ...,\n",
       "         [-0.0123, -0.0585, -0.0376,  ..., -0.0209,  0.0345, -0.0269],\n",
       "         [ 0.0534, -0.0277, -0.0302,  ...,  0.0204,  0.0767, -0.0392],\n",
       "         [-0.0570,  0.0174, -0.0835,  ...,  0.0665,  0.0250,  0.0224]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-5.1878e-03, -4.7930e-02,  1.2098e-02,  6.3395e-02,  9.8255e-05,\n",
       "         -7.6540e-02, -3.2764e-02, -9.0914e-03,  4.9133e-02, -1.5271e-02,\n",
       "          8.7204e-03, -9.7166e-03,  4.9813e-02,  1.7389e-02, -5.8412e-02,\n",
       "          1.5409e-02,  4.9646e-02, -4.3686e-02,  3.9392e-02, -7.7122e-02,\n",
       "         -7.8806e-02,  2.8719e-02, -8.8137e-02, -6.6076e-02,  3.7915e-02,\n",
       "          3.7546e-02,  8.7423e-02,  8.6567e-02,  5.3177e-02,  5.3050e-02,\n",
       "         -3.6339e-03,  5.8350e-02, -5.9271e-02, -1.3594e-03,  5.7257e-03,\n",
       "         -7.2897e-02,  7.3517e-02, -6.0034e-02,  2.6017e-02, -4.0578e-02,\n",
       "         -4.0032e-02,  5.2876e-02,  5.9041e-02, -6.1535e-02, -2.9274e-02,\n",
       "          8.1565e-02, -5.0795e-02, -2.8554e-02,  2.1465e-02, -5.4765e-03,\n",
       "          8.1405e-03, -5.5621e-02,  2.1598e-02,  1.9108e-02,  2.5442e-02,\n",
       "         -9.6747e-03, -8.1638e-02, -5.7062e-02,  6.3156e-02,  4.3873e-02,\n",
       "          5.9685e-02, -7.2741e-02,  3.7790e-02, -8.1541e-02],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0856,  0.0179,  0.0825,  ..., -0.0545, -0.0731, -0.0428],\n",
       "         [ 0.0042, -0.0299,  0.0434,  ..., -0.0370, -0.0304, -0.0766],\n",
       "         [-0.0190,  0.0432, -0.0393,  ..., -0.0387, -0.0713,  0.0263],\n",
       "         ...,\n",
       "         [ 0.0090, -0.0168,  0.0294,  ...,  0.0389, -0.0083,  0.0461],\n",
       "         [ 0.0537, -0.0726, -0.0839,  ..., -0.0757,  0.0017, -0.0500],\n",
       "         [ 0.0618, -0.0063,  0.0832,  ...,  0.0226,  0.0704,  0.0194]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0007,  0.0878,  0.0440,  0.0634, -0.0862, -0.0429,  0.0846, -0.0019,\n",
       "          0.0371, -0.0085,  0.0422,  0.0141,  0.0698,  0.0134, -0.0677,  0.0507,\n",
       "         -0.0617,  0.0330, -0.0869, -0.0353,  0.0718,  0.0213, -0.0587, -0.0217,\n",
       "         -0.0418,  0.0639, -0.0797, -0.0362,  0.0661,  0.0827,  0.0163, -0.0106,\n",
       "         -0.0121, -0.0878,  0.0541,  0.0359,  0.0883, -0.0721, -0.0217,  0.0617,\n",
       "         -0.0875,  0.0649,  0.0106, -0.0456, -0.0744,  0.0249, -0.0181,  0.0139,\n",
       "         -0.0647, -0.0120,  0.0572, -0.0581,  0.0103, -0.0216,  0.0725, -0.0659,\n",
       "          0.0576,  0.0654,  0.0316,  0.0242,  0.0648,  0.0244,  0.0607, -0.0232],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1002, -0.0799, -0.0469,  ..., -0.0995, -0.0842, -0.0319],\n",
       "         [-0.0863,  0.1120, -0.0659,  ...,  0.0516, -0.0795,  0.1096],\n",
       "         [ 0.0924,  0.0144, -0.0754,  ..., -0.0437, -0.0779,  0.1131],\n",
       "         ...,\n",
       "         [-0.0525, -0.0536, -0.1041,  ..., -0.0518, -0.0629,  0.1011],\n",
       "         [-0.0798,  0.0549,  0.0042,  ..., -0.0424,  0.1042,  0.1035],\n",
       "         [-0.0323, -0.1182, -0.0457,  ..., -0.0749,  0.0750,  0.0835]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0132, -0.0919,  0.0128, -0.0955, -0.0532,  0.0772, -0.0267,  0.0628,\n",
       "         -0.0013,  0.0142, -0.0829,  0.0025,  0.0187,  0.0132,  0.0212, -0.0431,\n",
       "         -0.0837,  0.0250,  0.0608,  0.0871, -0.0085, -0.1140,  0.0102, -0.0228,\n",
       "         -0.0097, -0.0356,  0.0778, -0.1057, -0.1053,  0.0604, -0.0275, -0.0972,\n",
       "         -0.0822, -0.1013, -0.0940,  0.0255,  0.0493, -0.1163, -0.0446,  0.0205,\n",
       "         -0.1126,  0.1102,  0.0380, -0.1012, -0.0227,  0.0362,  0.1100, -0.0107,\n",
       "         -0.1025,  0.0624, -0.0094, -0.0670,  0.1089,  0.1059,  0.0249, -0.0926,\n",
       "         -0.0665, -0.0675,  0.0620, -0.0216,  0.0606, -0.0073, -0.0309,  0.1076,\n",
       "          0.0055, -0.1028, -0.0665, -0.0357,  0.0331, -0.0845,  0.0059,  0.0037,\n",
       "          0.0545,  0.0730, -0.0897, -0.0423,  0.0352,  0.0585,  0.0603,  0.0500,\n",
       "         -0.0193, -0.0580,  0.0362,  0.0425, -0.0759,  0.0723, -0.0496,  0.0734,\n",
       "          0.0362, -0.0268, -0.1169, -0.0699, -0.0311, -0.0386, -0.0699, -0.0094,\n",
       "          0.1127, -0.0978,  0.0448, -0.0588,  0.0770, -0.0361,  0.1169,  0.0299,\n",
       "         -0.0492, -0.0183, -0.0606, -0.0791, -0.1093,  0.1000, -0.0464, -0.0450,\n",
       "          0.0444,  0.0631,  0.0259,  0.0826, -0.0011, -0.0197, -0.0270,  0.0093,\n",
       "          0.1021,  0.1054,  0.1008,  0.0877,  0.0788, -0.0229, -0.0553,  0.0717],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0655,  0.0757,  0.0535,  ...,  0.0235,  0.0688,  0.0531],\n",
       "         [-0.0526, -0.0093,  0.0175,  ..., -0.0171, -0.0426, -0.0087],\n",
       "         [ 0.0759,  0.0546, -0.0381,  ...,  0.0167, -0.0373, -0.0399],\n",
       "         ...,\n",
       "         [ 0.0353, -0.0227, -0.0009,  ...,  0.0268,  0.0735, -0.0115],\n",
       "         [ 0.0687, -0.0780,  0.0612,  ...,  0.0502,  0.0392, -0.0366],\n",
       "         [ 0.0091,  0.0104, -0.0834,  ...,  0.0278, -0.0497,  0.0320]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0166,  0.0421,  0.0851, -0.0345,  0.0779, -0.0064, -0.0073, -0.0648,\n",
       "          0.0657,  0.0857,  0.0528, -0.0288, -0.0374,  0.0198, -0.0021,  0.0555,\n",
       "         -0.0497,  0.0857,  0.0374, -0.0147,  0.0639,  0.0483,  0.0606,  0.0018,\n",
       "          0.0043,  0.0765,  0.0671, -0.0294,  0.0028, -0.0210,  0.0223,  0.0424,\n",
       "          0.0631,  0.0163, -0.0165,  0.0423,  0.0745,  0.0704, -0.0542, -0.0369,\n",
       "          0.0283, -0.0820, -0.0254,  0.0015,  0.0804,  0.0552,  0.0797,  0.0133,\n",
       "         -0.0336,  0.0442, -0.0845,  0.0202,  0.0678,  0.0189, -0.0403, -0.0162,\n",
       "          0.0610, -0.0624, -0.0137,  0.0044,  0.0703, -0.0318,  0.0349, -0.0390,\n",
       "         -0.0720,  0.0457,  0.0013, -0.0158, -0.0226, -0.0475,  0.0277,  0.0243,\n",
       "         -0.0385,  0.0678,  0.0041, -0.0315, -0.0005, -0.0855,  0.0568, -0.0227,\n",
       "          0.0090, -0.0841,  0.0121,  0.0032, -0.0639, -0.0396, -0.0599, -0.0648,\n",
       "          0.0617, -0.0152,  0.0740, -0.0169, -0.0367,  0.0245,  0.0870,  0.0645,\n",
       "          0.0203,  0.0410,  0.0699, -0.0276,  0.0287, -0.0419, -0.0434,  0.0443,\n",
       "          0.0202,  0.0234,  0.0098,  0.0667, -0.0111, -0.0400, -0.0525, -0.0214,\n",
       "          0.0822, -0.0326,  0.0477, -0.0154, -0.0833,  0.0454,  0.0432,  0.0048,\n",
       "         -0.0835,  0.0015, -0.0111,  0.0416,  0.0399, -0.0678, -0.0236, -0.0688,\n",
       "         -0.0070, -0.0700, -0.0503, -0.0021,  0.0769, -0.0412, -0.0825,  0.0079,\n",
       "         -0.0085,  0.0769,  0.0229,  0.0418,  0.0128,  0.0824,  0.0426, -0.0597,\n",
       "         -0.0297,  0.0023, -0.0846,  0.0109, -0.0806,  0.0478,  0.0833,  0.0412,\n",
       "          0.0311, -0.0216, -0.0799, -0.0213, -0.0168, -0.0122,  0.0833,  0.0204,\n",
       "         -0.0786, -0.0207,  0.0513,  0.0037, -0.0640, -0.0182, -0.0187, -0.0616,\n",
       "         -0.0192,  0.0394,  0.0008,  0.0446, -0.0482,  0.0844,  0.0806,  0.0007,\n",
       "          0.0292, -0.0317,  0.0729, -0.0824, -0.0089,  0.0845,  0.0368, -0.0523,\n",
       "         -0.0584, -0.0320, -0.0338, -0.0489,  0.0787, -0.0638,  0.0342,  0.0838,\n",
       "          0.0722,  0.0614, -0.0840,  0.0251, -0.0839,  0.0273, -0.0305,  0.0325,\n",
       "          0.0504, -0.0606,  0.0176,  0.0290, -0.0043, -0.0517, -0.0031,  0.0605,\n",
       "         -0.0681, -0.0573, -0.0114,  0.0562, -0.0391,  0.0406, -0.0719, -0.0697,\n",
       "         -0.0665,  0.0710,  0.0086,  0.0359,  0.0449, -0.0148,  0.0224,  0.0297,\n",
       "         -0.0160,  0.0251,  0.0334, -0.0653,  0.0093, -0.0205,  0.0136,  0.0340,\n",
       "          0.0489,  0.0694, -0.0530, -0.0677,  0.0072,  0.0263,  0.0685,  0.0783,\n",
       "         -0.0845,  0.0471, -0.0091, -0.0810,  0.0714,  0.0457, -0.0033, -0.0649,\n",
       "         -0.0071,  0.0647, -0.0742,  0.0475,  0.0171, -0.0782,  0.0166,  0.0488],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0258, -0.0542, -0.0103,  ..., -0.0077, -0.0513, -0.0557],\n",
       "         [ 0.0099, -0.0499, -0.0561,  ...,  0.0230, -0.0111,  0.0463],\n",
       "         [ 0.0272,  0.0302, -0.0011,  ...,  0.0276,  0.0495,  0.0203],\n",
       "         ...,\n",
       "         [ 0.0318, -0.0177, -0.0277,  ...,  0.0513, -0.0550, -0.0233],\n",
       "         [ 0.0176, -0.0443, -0.0135,  ...,  0.0141,  0.0390, -0.0502],\n",
       "         [-0.0101,  0.0046,  0.0246,  ...,  0.0385,  0.0590,  0.0390]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0341, -0.0422, -0.0249,  0.0523,  0.0492, -0.0454, -0.0208,  0.0447,\n",
       "          0.0270, -0.0487,  0.0002, -0.0154, -0.0447, -0.0373, -0.0545,  0.0571,\n",
       "          0.0376, -0.0415,  0.0342, -0.0165,  0.0481,  0.0301, -0.0205, -0.0300,\n",
       "         -0.0194,  0.0476,  0.0131, -0.0182, -0.0442, -0.0489,  0.0006, -0.0493,\n",
       "         -0.0519,  0.0402, -0.0195, -0.0003,  0.0389,  0.0364,  0.0459,  0.0058,\n",
       "         -0.0344,  0.0011,  0.0411,  0.0438, -0.0356, -0.0068,  0.0119, -0.0357,\n",
       "         -0.0386,  0.0322, -0.0521,  0.0399, -0.0441,  0.0552,  0.0151,  0.0613,\n",
       "          0.0418,  0.0283, -0.0517, -0.0272,  0.0188, -0.0197,  0.0289, -0.0370,\n",
       "         -0.0624, -0.0032, -0.0450,  0.0116, -0.0157,  0.0361,  0.0624,  0.0129,\n",
       "          0.0124, -0.0461, -0.0155, -0.0266, -0.0470, -0.0110, -0.0544,  0.0409,\n",
       "         -0.0030,  0.0089,  0.0032,  0.0154,  0.0271,  0.0033, -0.0259,  0.0424,\n",
       "          0.0055, -0.0049, -0.0338, -0.0267,  0.0037, -0.0087,  0.0107,  0.0462,\n",
       "         -0.0201,  0.0141, -0.0032,  0.0282, -0.0246,  0.0120, -0.0379, -0.0124,\n",
       "          0.0201, -0.0586, -0.0174, -0.0462,  0.0084,  0.0398, -0.0377,  0.0224,\n",
       "          0.0023, -0.0158,  0.0322, -0.0376,  0.0249, -0.0527, -0.0142, -0.0308,\n",
       "          0.0483,  0.0536,  0.0520, -0.0388, -0.0042, -0.0085, -0.0163,  0.0316,\n",
       "          0.0558, -0.0001, -0.0575,  0.0492,  0.0402, -0.0405, -0.0158,  0.0317,\n",
       "         -0.0078,  0.0322,  0.0198,  0.0513, -0.0261, -0.0601,  0.0596, -0.0487,\n",
       "         -0.0250,  0.0077,  0.0582,  0.0123,  0.0543,  0.0467,  0.0528,  0.0545,\n",
       "         -0.0230,  0.0523,  0.0379,  0.0515, -0.0218,  0.0168, -0.0408,  0.0048,\n",
       "         -0.0125, -0.0102,  0.0506,  0.0367,  0.0584, -0.0070, -0.0007,  0.0374,\n",
       "          0.0588,  0.0575, -0.0064,  0.0339, -0.0389,  0.0399, -0.0274,  0.0273,\n",
       "         -0.0084, -0.0060,  0.0049, -0.0040, -0.0396,  0.0321,  0.0267, -0.0332,\n",
       "          0.0177,  0.0538, -0.0496,  0.0340,  0.0254,  0.0575,  0.0597,  0.0121,\n",
       "          0.0410,  0.0257,  0.0599, -0.0089, -0.0238, -0.0242, -0.0122,  0.0065,\n",
       "         -0.0590,  0.0199,  0.0047, -0.0537, -0.0312,  0.0587,  0.0581,  0.0182,\n",
       "         -0.0378, -0.0438,  0.0015,  0.0304, -0.0023,  0.0398, -0.0561, -0.0254,\n",
       "         -0.0145, -0.0002,  0.0448, -0.0566,  0.0444, -0.0407, -0.0437,  0.0437,\n",
       "         -0.0091, -0.0384, -0.0550, -0.0421, -0.0018, -0.0355,  0.0336, -0.0342,\n",
       "         -0.0602,  0.0297, -0.0219,  0.0025,  0.0418, -0.0368, -0.0173, -0.0223,\n",
       "         -0.0128, -0.0517,  0.0275,  0.0171, -0.0601, -0.0599,  0.0475, -0.0134,\n",
       "         -0.0477, -0.0056, -0.0433, -0.0515,  0.0505,  0.0590, -0.0419,  0.0078,\n",
       "          0.0538,  0.0556, -0.0230, -0.0488, -0.0336,  0.0489, -0.0278,  0.0299,\n",
       "          0.0119,  0.0347, -0.0109, -0.0366, -0.0159,  0.0578,  0.0351,  0.0127,\n",
       "          0.0601, -0.0602,  0.0147,  0.0548, -0.0097,  0.0280,  0.0185,  0.0606,\n",
       "          0.0234, -0.0374, -0.0362, -0.0375, -0.0577, -0.0403,  0.0138, -0.0098,\n",
       "         -0.0082,  0.0594, -0.0412,  0.0193, -0.0069,  0.0220,  0.0329, -0.0489,\n",
       "         -0.0495,  0.0488, -0.0009,  0.0617, -0.0387, -0.0592,  0.0367, -0.0017,\n",
       "          0.0167, -0.0152, -0.0037,  0.0286, -0.0110, -0.0265,  0.0061, -0.0046,\n",
       "          0.0273,  0.0533,  0.0175, -0.0483,  0.0080,  0.0028,  0.0054, -0.0546,\n",
       "         -0.0158,  0.0016, -0.0433,  0.0566,  0.0471, -0.0443,  0.0509, -0.0279,\n",
       "          0.0046, -0.0141,  0.0323, -0.0011,  0.0555,  0.0592,  0.0488,  0.0610,\n",
       "         -0.0518, -0.0601, -0.0444, -0.0044, -0.0158, -0.0561, -0.0622,  0.0143,\n",
       "          0.0162, -0.0344,  0.0388, -0.0356, -0.0209,  0.0471, -0.0460, -0.0241,\n",
       "         -0.0535, -0.0050,  0.0110,  0.0089, -0.0165, -0.0147,  0.0321, -0.0383,\n",
       "         -0.0091,  0.0323,  0.0437,  0.0010, -0.0257,  0.0352,  0.0449, -0.0054,\n",
       "          0.0575, -0.0207, -0.0129, -0.0111, -0.0331, -0.0575,  0.0530,  0.0042,\n",
       "          0.0153, -0.0206,  0.0359, -0.0361, -0.0029,  0.0026, -0.0118,  0.0091,\n",
       "         -0.0021, -0.0115, -0.0432, -0.0023, -0.0134,  0.0011, -0.0387, -0.0045,\n",
       "          0.0484,  0.0348,  0.0420, -0.0428, -0.0050, -0.0281,  0.0513,  0.0203,\n",
       "         -0.0180,  0.0252, -0.0035,  0.0276, -0.0219,  0.0203,  0.0024, -0.0130,\n",
       "          0.0385,  0.0019,  0.0266, -0.0501,  0.0235,  0.0135, -0.0367,  0.0234,\n",
       "         -0.0166, -0.0299, -0.0158, -0.0185,  0.0286,  0.0508, -0.0412, -0.0214,\n",
       "         -0.0287,  0.0192,  0.0426,  0.0125, -0.0128, -0.0526, -0.0611, -0.0108,\n",
       "         -0.0060,  0.0242,  0.0071, -0.0246,  0.0297,  0.0503,  0.0350, -0.0396,\n",
       "         -0.0170,  0.0317,  0.0339,  0.0142, -0.0046, -0.0238, -0.0228, -0.0115,\n",
       "         -0.0067, -0.0210, -0.0343,  0.0527, -0.0295,  0.0491, -0.0514,  0.0366,\n",
       "          0.0430,  0.0182,  0.0241,  0.0573, -0.0049, -0.0416,  0.0511,  0.0432,\n",
       "         -0.0397,  0.0475,  0.0396,  0.0124, -0.0198, -0.0513,  0.0302, -0.0438,\n",
       "          0.0045, -0.0520,  0.0135, -0.0513,  0.0382, -0.0424, -0.0601, -0.0137,\n",
       "          0.0267, -0.0530,  0.0510,  0.0367,  0.0070, -0.0382,  0.0073, -0.0623,\n",
       "          0.0105,  0.0380, -0.0566, -0.0178, -0.0464,  0.0122, -0.0534, -0.0020,\n",
       "         -0.0359,  0.0539,  0.0115,  0.0178,  0.0366, -0.0507,  0.0181,  0.0154,\n",
       "         -0.0473,  0.0582, -0.0417, -0.0021, -0.0207,  0.0428, -0.0337,  0.0061],\n",
       "        requires_grad=True)]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "[p for p in learner.parameters()]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0108,  0.0243,  0.0185,  ..., -0.0164,  0.0236,  0.0374],\n",
       "         [ 0.0068,  0.0064, -0.0116,  ...,  0.0058,  0.0020,  0.0191],\n",
       "         [-0.0327,  0.0254, -0.0249,  ..., -0.0022,  0.0181,  0.0160],\n",
       "         ...,\n",
       "         [ 0.0349, -0.0221,  0.0433,  ...,  0.0178,  0.0242,  0.0199],\n",
       "         [ 0.0255,  0.0358, -0.0036,  ..., -0.0374,  0.0353, -0.0067],\n",
       "         [-0.0255,  0.0315,  0.0118,  ..., -0.0030,  0.0020,  0.0005]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 1.3028e-02, -3.7853e-02, -4.3363e-02,  2.5034e-02,  2.1001e-02,\n",
       "          3.0429e-02, -1.9690e-02, -4.4064e-02,  7.8055e-03,  1.2786e-02,\n",
       "         -4.1244e-02, -4.0994e-02,  1.8539e-02, -3.3859e-03, -5.5976e-03,\n",
       "         -2.7980e-02, -2.4508e-02, -1.3778e-02, -3.1488e-02,  2.7404e-02,\n",
       "          4.2747e-02, -1.2746e-02,  2.0945e-02,  1.1789e-02,  1.0178e-02,\n",
       "          5.0657e-03, -3.2606e-02,  7.6419e-03,  1.0938e-02,  4.3282e-02,\n",
       "         -4.0774e-03, -3.9221e-02,  2.7995e-02,  2.9974e-02, -2.0080e-02,\n",
       "          5.1581e-03,  1.0977e-02, -2.2941e-02, -1.6359e-02,  1.3408e-02,\n",
       "         -3.7971e-02,  4.0835e-03, -3.4791e-02, -1.8681e-02, -1.4372e-02,\n",
       "          4.0276e-02,  3.3049e-03, -3.5235e-02, -4.0212e-02, -3.4582e-02,\n",
       "          6.3961e-03, -2.7739e-02, -1.1579e-02,  1.7510e-02,  5.7920e-03,\n",
       "          1.2337e-02, -2.2277e-02,  1.8925e-02,  1.5877e-02,  2.3946e-02,\n",
       "         -4.2756e-02,  3.6554e-04, -1.6239e-02, -2.6552e-02,  1.2995e-02,\n",
       "          6.6763e-03, -8.7062e-03, -1.4466e-02, -2.4865e-02,  4.3006e-02,\n",
       "         -2.3823e-02,  1.1178e-02, -1.0703e-02,  4.3419e-03, -3.0426e-02,\n",
       "          2.2427e-02,  4.3299e-02, -1.9327e-02,  4.0963e-03,  2.5181e-02,\n",
       "          2.7926e-02,  9.0398e-03, -3.3982e-02, -2.2509e-02, -3.1507e-02,\n",
       "          5.0530e-03,  3.0388e-02,  1.3121e-02,  1.3249e-02, -1.7692e-02,\n",
       "         -7.7672e-03, -1.5035e-02,  3.0769e-02, -2.2105e-02,  2.2630e-02,\n",
       "         -3.5706e-02,  2.8463e-02,  3.5626e-02,  1.2047e-02,  8.2586e-03,\n",
       "         -3.4525e-02, -3.0932e-02,  2.5752e-02,  1.5484e-02, -4.3709e-02,\n",
       "          4.6641e-03, -7.7673e-03,  3.4862e-02, -1.9531e-02,  2.6847e-02,\n",
       "          3.2331e-02,  3.7418e-02, -9.9484e-03,  6.3375e-03, -1.8478e-02,\n",
       "         -3.4241e-02, -3.1248e-02,  3.4759e-02, -4.2040e-02, -1.3658e-02,\n",
       "         -2.1999e-02, -2.4598e-02, -1.2080e-02,  6.6850e-03, -2.9987e-02,\n",
       "          2.1093e-02,  2.5504e-02,  4.2729e-02, -2.2505e-03, -2.1353e-02,\n",
       "          2.5532e-03, -1.5947e-02, -2.5986e-02,  2.8922e-02, -2.2898e-02,\n",
       "         -3.2195e-05, -1.3493e-02, -2.8615e-02,  9.7745e-03, -2.0192e-02,\n",
       "         -2.4184e-02,  2.1117e-02, -1.4131e-02, -1.9057e-02, -1.2340e-02,\n",
       "         -4.0023e-02, -2.3222e-02,  3.1158e-02, -3.0530e-02,  1.4592e-02,\n",
       "         -1.8497e-02, -4.2080e-02, -7.0586e-03, -4.2848e-02, -1.5647e-02,\n",
       "         -5.0136e-03, -2.7459e-02, -1.8861e-02,  3.4418e-02,  1.3902e-02,\n",
       "         -2.8180e-02,  1.3258e-02,  2.6909e-02,  1.3396e-02, -1.7369e-02,\n",
       "         -4.4175e-02,  3.9270e-02,  3.0798e-03,  1.5471e-02, -2.4522e-02,\n",
       "         -1.1816e-04, -2.5890e-02, -3.9448e-02, -1.9325e-02, -8.7388e-03,\n",
       "         -2.0697e-02,  2.1341e-04,  4.0725e-02, -2.6892e-02,  4.2834e-02,\n",
       "         -4.3864e-02, -2.4500e-02, -3.9817e-02, -2.7600e-02, -4.0332e-02,\n",
       "          3.9035e-02, -1.6696e-02,  4.9515e-04,  3.0613e-02,  2.6923e-02,\n",
       "          3.0785e-02,  3.6288e-02,  5.3088e-03, -1.9846e-02,  2.1574e-02,\n",
       "          1.4037e-02, -3.0347e-02,  4.1062e-02, -2.5302e-02, -1.0305e-02,\n",
       "          2.2718e-02,  7.0306e-03, -3.1658e-02,  3.2341e-02, -3.1876e-02,\n",
       "         -1.7374e-02,  2.1883e-02,  4.0304e-02, -2.5916e-02, -3.8560e-03,\n",
       "         -6.9956e-03, -1.9174e-03,  2.9442e-02, -3.7217e-02,  4.3933e-02,\n",
       "          7.3553e-03, -4.6301e-03,  3.7275e-02, -5.7614e-03,  2.2223e-02,\n",
       "          1.0228e-02, -1.2247e-02, -2.6669e-02, -1.4257e-02,  9.1100e-04,\n",
       "         -1.4006e-02,  4.3237e-02, -3.0569e-02, -2.4042e-02,  3.2274e-02,\n",
       "          3.9654e-03, -2.2135e-02,  2.4147e-02,  3.7447e-02, -3.7084e-02,\n",
       "          3.6548e-02, -1.1539e-02, -2.8612e-02, -4.3721e-03,  2.4667e-02,\n",
       "         -1.9582e-02,  2.2585e-04,  2.3154e-02, -5.2551e-04,  9.6619e-03,\n",
       "         -1.6652e-02,  3.8063e-02, -2.1764e-02, -2.7924e-02, -1.2937e-03,\n",
       "          2.5935e-02, -2.6045e-02, -2.2423e-02, -3.4540e-02,  2.1154e-02,\n",
       "          1.9374e-02], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0551, -0.0455,  0.0335,  ...,  0.0199,  0.0176, -0.0604],\n",
       "         [-0.0465,  0.0284,  0.0171,  ...,  0.0206,  0.0069,  0.0217],\n",
       "         [ 0.0117, -0.0424, -0.0460,  ...,  0.0064, -0.0018, -0.0424],\n",
       "         ...,\n",
       "         [-0.0250,  0.0540,  0.0535,  ..., -0.0404, -0.0175,  0.0151],\n",
       "         [-0.0336,  0.0156,  0.0054,  ..., -0.0431,  0.0482, -0.0047],\n",
       "         [ 0.0396,  0.0019,  0.0352,  ..., -0.0598,  0.0129, -0.0013]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0299, -0.0587, -0.0499,  0.0562,  0.0366, -0.0354,  0.0155, -0.0503,\n",
       "         -0.0384,  0.0023,  0.0550, -0.0485,  0.0439, -0.0275,  0.0590, -0.0428,\n",
       "         -0.0342, -0.0289, -0.0498, -0.0295,  0.0114,  0.0237, -0.0513, -0.0613,\n",
       "         -0.0163,  0.0200, -0.0514,  0.0218,  0.0341,  0.0428,  0.0299,  0.0352,\n",
       "          0.0329,  0.0556, -0.0524,  0.0288, -0.0166, -0.0382,  0.0210, -0.0041,\n",
       "          0.0180, -0.0192,  0.0006, -0.0076,  0.0383, -0.0059, -0.0355,  0.0396,\n",
       "         -0.0128, -0.0266, -0.0216, -0.0109, -0.0468, -0.0259, -0.0040, -0.0489,\n",
       "         -0.0493,  0.0457,  0.0388,  0.0331, -0.0520,  0.0134, -0.0579, -0.0287,\n",
       "         -0.0058,  0.0429,  0.0187, -0.0542, -0.0129,  0.0111, -0.0607,  0.0240,\n",
       "          0.0039, -0.0065,  0.0598,  0.0606, -0.0383, -0.0247, -0.0610,  0.0444,\n",
       "          0.0096, -0.0286, -0.0286, -0.0502, -0.0170,  0.0406, -0.0435, -0.0240,\n",
       "          0.0323, -0.0318,  0.0346, -0.0254, -0.0581, -0.0541, -0.0468,  0.0575,\n",
       "         -0.0381, -0.0111,  0.0389, -0.0512,  0.0129, -0.0007, -0.0192, -0.0386,\n",
       "          0.0432, -0.0414, -0.0226, -0.0105,  0.0254, -0.0149,  0.0210,  0.0318,\n",
       "          0.0007, -0.0244, -0.0559,  0.0153,  0.0083,  0.0581,  0.0376, -0.0138,\n",
       "         -0.0157,  0.0141,  0.0286, -0.0269,  0.0461,  0.0326,  0.0213,  0.0487],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0065,  0.0117, -0.0258,  ...,  0.0551, -0.0315, -0.0501],\n",
       "         [-0.0477, -0.0265,  0.0667,  ...,  0.0331,  0.0539,  0.0585],\n",
       "         [ 0.0145, -0.0599, -0.0733,  ..., -0.0160,  0.0736, -0.0351],\n",
       "         ...,\n",
       "         [-0.0123, -0.0585, -0.0376,  ..., -0.0209,  0.0345, -0.0269],\n",
       "         [ 0.0534, -0.0277, -0.0302,  ...,  0.0204,  0.0767, -0.0392],\n",
       "         [-0.0570,  0.0174, -0.0835,  ...,  0.0665,  0.0250,  0.0224]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-5.1878e-03, -4.7930e-02,  1.2098e-02,  6.3395e-02,  9.8255e-05,\n",
       "         -7.6540e-02, -3.2764e-02, -9.0914e-03,  4.9133e-02, -1.5271e-02,\n",
       "          8.7204e-03, -9.7166e-03,  4.9813e-02,  1.7389e-02, -5.8412e-02,\n",
       "          1.5409e-02,  4.9646e-02, -4.3686e-02,  3.9392e-02, -7.7122e-02,\n",
       "         -7.8806e-02,  2.8719e-02, -8.8137e-02, -6.6076e-02,  3.7915e-02,\n",
       "          3.7546e-02,  8.7423e-02,  8.6567e-02,  5.3177e-02,  5.3050e-02,\n",
       "         -3.6339e-03,  5.8350e-02, -5.9271e-02, -1.3594e-03,  5.7257e-03,\n",
       "         -7.2897e-02,  7.3517e-02, -6.0034e-02,  2.6017e-02, -4.0578e-02,\n",
       "         -4.0032e-02,  5.2876e-02,  5.9041e-02, -6.1535e-02, -2.9274e-02,\n",
       "          8.1565e-02, -5.0795e-02, -2.8554e-02,  2.1465e-02, -5.4765e-03,\n",
       "          8.1405e-03, -5.5621e-02,  2.1598e-02,  1.9108e-02,  2.5442e-02,\n",
       "         -9.6747e-03, -8.1638e-02, -5.7062e-02,  6.3156e-02,  4.3873e-02,\n",
       "          5.9685e-02, -7.2741e-02,  3.7790e-02, -8.1541e-02],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0856,  0.0179,  0.0825,  ..., -0.0545, -0.0731, -0.0428],\n",
       "         [ 0.0042, -0.0299,  0.0434,  ..., -0.0370, -0.0304, -0.0766],\n",
       "         [-0.0190,  0.0432, -0.0393,  ..., -0.0387, -0.0713,  0.0263],\n",
       "         ...,\n",
       "         [ 0.0090, -0.0168,  0.0294,  ...,  0.0389, -0.0083,  0.0461],\n",
       "         [ 0.0537, -0.0726, -0.0839,  ..., -0.0757,  0.0017, -0.0500],\n",
       "         [ 0.0618, -0.0063,  0.0832,  ...,  0.0226,  0.0704,  0.0194]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0007,  0.0878,  0.0440,  0.0634, -0.0862, -0.0429,  0.0846, -0.0019,\n",
       "          0.0371, -0.0085,  0.0422,  0.0141,  0.0698,  0.0134, -0.0677,  0.0507,\n",
       "         -0.0617,  0.0330, -0.0869, -0.0353,  0.0718,  0.0213, -0.0587, -0.0217,\n",
       "         -0.0418,  0.0639, -0.0797, -0.0362,  0.0661,  0.0827,  0.0163, -0.0106,\n",
       "         -0.0121, -0.0878,  0.0541,  0.0359,  0.0883, -0.0721, -0.0217,  0.0617,\n",
       "         -0.0875,  0.0649,  0.0106, -0.0456, -0.0744,  0.0249, -0.0181,  0.0139,\n",
       "         -0.0647, -0.0120,  0.0572, -0.0581,  0.0103, -0.0216,  0.0725, -0.0659,\n",
       "          0.0576,  0.0654,  0.0316,  0.0242,  0.0648,  0.0244,  0.0607, -0.0232],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1002, -0.0799, -0.0469,  ..., -0.0995, -0.0842, -0.0319],\n",
       "         [-0.0863,  0.1120, -0.0659,  ...,  0.0516, -0.0795,  0.1096],\n",
       "         [ 0.0924,  0.0144, -0.0754,  ..., -0.0437, -0.0779,  0.1131],\n",
       "         ...,\n",
       "         [-0.0525, -0.0536, -0.1041,  ..., -0.0518, -0.0629,  0.1011],\n",
       "         [-0.0798,  0.0549,  0.0042,  ..., -0.0424,  0.1042,  0.1035],\n",
       "         [-0.0323, -0.1182, -0.0457,  ..., -0.0749,  0.0750,  0.0835]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0132, -0.0919,  0.0128, -0.0955, -0.0532,  0.0772, -0.0267,  0.0628,\n",
       "         -0.0013,  0.0142, -0.0829,  0.0025,  0.0187,  0.0132,  0.0212, -0.0431,\n",
       "         -0.0837,  0.0250,  0.0608,  0.0871, -0.0085, -0.1140,  0.0102, -0.0228,\n",
       "         -0.0097, -0.0356,  0.0778, -0.1057, -0.1053,  0.0604, -0.0275, -0.0972,\n",
       "         -0.0822, -0.1013, -0.0940,  0.0255,  0.0493, -0.1163, -0.0446,  0.0205,\n",
       "         -0.1126,  0.1102,  0.0380, -0.1012, -0.0227,  0.0362,  0.1100, -0.0107,\n",
       "         -0.1025,  0.0624, -0.0094, -0.0670,  0.1089,  0.1059,  0.0249, -0.0926,\n",
       "         -0.0665, -0.0675,  0.0620, -0.0216,  0.0606, -0.0073, -0.0309,  0.1076,\n",
       "          0.0055, -0.1028, -0.0665, -0.0357,  0.0331, -0.0845,  0.0059,  0.0037,\n",
       "          0.0545,  0.0730, -0.0897, -0.0423,  0.0352,  0.0585,  0.0603,  0.0500,\n",
       "         -0.0193, -0.0580,  0.0362,  0.0425, -0.0759,  0.0723, -0.0496,  0.0734,\n",
       "          0.0362, -0.0268, -0.1169, -0.0699, -0.0311, -0.0386, -0.0699, -0.0094,\n",
       "          0.1127, -0.0978,  0.0448, -0.0588,  0.0770, -0.0361,  0.1169,  0.0299,\n",
       "         -0.0492, -0.0183, -0.0606, -0.0791, -0.1093,  0.1000, -0.0464, -0.0450,\n",
       "          0.0444,  0.0631,  0.0259,  0.0826, -0.0011, -0.0197, -0.0270,  0.0093,\n",
       "          0.1021,  0.1054,  0.1008,  0.0877,  0.0788, -0.0229, -0.0553,  0.0717],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0655,  0.0757,  0.0535,  ...,  0.0235,  0.0688,  0.0531],\n",
       "         [-0.0526, -0.0093,  0.0175,  ..., -0.0171, -0.0426, -0.0087],\n",
       "         [ 0.0759,  0.0546, -0.0381,  ...,  0.0167, -0.0373, -0.0399],\n",
       "         ...,\n",
       "         [ 0.0353, -0.0227, -0.0009,  ...,  0.0268,  0.0735, -0.0115],\n",
       "         [ 0.0687, -0.0780,  0.0612,  ...,  0.0502,  0.0392, -0.0366],\n",
       "         [ 0.0091,  0.0104, -0.0834,  ...,  0.0278, -0.0497,  0.0320]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0166,  0.0421,  0.0851, -0.0345,  0.0779, -0.0064, -0.0073, -0.0648,\n",
       "          0.0657,  0.0857,  0.0528, -0.0288, -0.0374,  0.0198, -0.0021,  0.0555,\n",
       "         -0.0497,  0.0857,  0.0374, -0.0147,  0.0639,  0.0483,  0.0606,  0.0018,\n",
       "          0.0043,  0.0765,  0.0671, -0.0294,  0.0028, -0.0210,  0.0223,  0.0424,\n",
       "          0.0631,  0.0163, -0.0165,  0.0423,  0.0745,  0.0704, -0.0542, -0.0369,\n",
       "          0.0283, -0.0820, -0.0254,  0.0015,  0.0804,  0.0552,  0.0797,  0.0133,\n",
       "         -0.0336,  0.0442, -0.0845,  0.0202,  0.0678,  0.0189, -0.0403, -0.0162,\n",
       "          0.0610, -0.0624, -0.0137,  0.0044,  0.0703, -0.0318,  0.0349, -0.0390,\n",
       "         -0.0720,  0.0457,  0.0013, -0.0158, -0.0226, -0.0475,  0.0277,  0.0243,\n",
       "         -0.0385,  0.0678,  0.0041, -0.0315, -0.0005, -0.0855,  0.0568, -0.0227,\n",
       "          0.0090, -0.0841,  0.0121,  0.0032, -0.0639, -0.0396, -0.0599, -0.0648,\n",
       "          0.0617, -0.0152,  0.0740, -0.0169, -0.0367,  0.0245,  0.0870,  0.0645,\n",
       "          0.0203,  0.0410,  0.0699, -0.0276,  0.0287, -0.0419, -0.0434,  0.0443,\n",
       "          0.0202,  0.0234,  0.0098,  0.0667, -0.0111, -0.0400, -0.0525, -0.0214,\n",
       "          0.0822, -0.0326,  0.0477, -0.0154, -0.0833,  0.0454,  0.0432,  0.0048,\n",
       "         -0.0835,  0.0015, -0.0111,  0.0416,  0.0399, -0.0678, -0.0236, -0.0688,\n",
       "         -0.0070, -0.0700, -0.0503, -0.0021,  0.0769, -0.0412, -0.0825,  0.0079,\n",
       "         -0.0085,  0.0769,  0.0229,  0.0418,  0.0128,  0.0824,  0.0426, -0.0597,\n",
       "         -0.0297,  0.0023, -0.0846,  0.0109, -0.0806,  0.0478,  0.0833,  0.0412,\n",
       "          0.0311, -0.0216, -0.0799, -0.0213, -0.0168, -0.0122,  0.0833,  0.0204,\n",
       "         -0.0786, -0.0207,  0.0513,  0.0037, -0.0640, -0.0182, -0.0187, -0.0616,\n",
       "         -0.0192,  0.0394,  0.0008,  0.0446, -0.0482,  0.0844,  0.0806,  0.0007,\n",
       "          0.0292, -0.0317,  0.0729, -0.0824, -0.0089,  0.0845,  0.0368, -0.0523,\n",
       "         -0.0584, -0.0320, -0.0338, -0.0489,  0.0787, -0.0638,  0.0342,  0.0838,\n",
       "          0.0722,  0.0614, -0.0840,  0.0251, -0.0839,  0.0273, -0.0305,  0.0325,\n",
       "          0.0504, -0.0606,  0.0176,  0.0290, -0.0043, -0.0517, -0.0031,  0.0605,\n",
       "         -0.0681, -0.0573, -0.0114,  0.0562, -0.0391,  0.0406, -0.0719, -0.0697,\n",
       "         -0.0665,  0.0710,  0.0086,  0.0359,  0.0449, -0.0148,  0.0224,  0.0297,\n",
       "         -0.0160,  0.0251,  0.0334, -0.0653,  0.0093, -0.0205,  0.0136,  0.0340,\n",
       "          0.0489,  0.0694, -0.0530, -0.0677,  0.0072,  0.0263,  0.0685,  0.0783,\n",
       "         -0.0845,  0.0471, -0.0091, -0.0810,  0.0714,  0.0457, -0.0033, -0.0649,\n",
       "         -0.0071,  0.0647, -0.0742,  0.0475,  0.0171, -0.0782,  0.0166,  0.0488],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0258, -0.0542, -0.0103,  ..., -0.0077, -0.0513, -0.0557],\n",
       "         [ 0.0099, -0.0499, -0.0561,  ...,  0.0230, -0.0111,  0.0463],\n",
       "         [ 0.0272,  0.0302, -0.0011,  ...,  0.0276,  0.0495,  0.0203],\n",
       "         ...,\n",
       "         [ 0.0318, -0.0177, -0.0277,  ...,  0.0513, -0.0550, -0.0233],\n",
       "         [ 0.0176, -0.0443, -0.0135,  ...,  0.0141,  0.0390, -0.0502],\n",
       "         [-0.0101,  0.0046,  0.0246,  ...,  0.0385,  0.0590,  0.0390]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0341, -0.0422, -0.0249,  0.0523,  0.0492, -0.0454, -0.0208,  0.0447,\n",
       "          0.0270, -0.0487,  0.0002, -0.0154, -0.0447, -0.0373, -0.0545,  0.0571,\n",
       "          0.0376, -0.0415,  0.0342, -0.0165,  0.0481,  0.0301, -0.0205, -0.0300,\n",
       "         -0.0194,  0.0476,  0.0131, -0.0182, -0.0442, -0.0489,  0.0006, -0.0493,\n",
       "         -0.0519,  0.0402, -0.0195, -0.0003,  0.0389,  0.0364,  0.0459,  0.0058,\n",
       "         -0.0344,  0.0011,  0.0411,  0.0438, -0.0356, -0.0068,  0.0119, -0.0357,\n",
       "         -0.0386,  0.0322, -0.0521,  0.0399, -0.0441,  0.0552,  0.0151,  0.0613,\n",
       "          0.0418,  0.0283, -0.0517, -0.0272,  0.0188, -0.0197,  0.0289, -0.0370,\n",
       "         -0.0624, -0.0032, -0.0450,  0.0116, -0.0157,  0.0361,  0.0624,  0.0129,\n",
       "          0.0124, -0.0461, -0.0155, -0.0266, -0.0470, -0.0110, -0.0544,  0.0409,\n",
       "         -0.0030,  0.0089,  0.0032,  0.0154,  0.0271,  0.0033, -0.0259,  0.0424,\n",
       "          0.0055, -0.0049, -0.0338, -0.0267,  0.0037, -0.0087,  0.0107,  0.0462,\n",
       "         -0.0201,  0.0141, -0.0032,  0.0282, -0.0246,  0.0120, -0.0379, -0.0124,\n",
       "          0.0201, -0.0586, -0.0174, -0.0462,  0.0084,  0.0398, -0.0377,  0.0224,\n",
       "          0.0023, -0.0158,  0.0322, -0.0376,  0.0249, -0.0527, -0.0142, -0.0308,\n",
       "          0.0483,  0.0536,  0.0520, -0.0388, -0.0042, -0.0085, -0.0163,  0.0316,\n",
       "          0.0558, -0.0001, -0.0575,  0.0492,  0.0402, -0.0405, -0.0158,  0.0317,\n",
       "         -0.0078,  0.0322,  0.0198,  0.0513, -0.0261, -0.0601,  0.0596, -0.0487,\n",
       "         -0.0250,  0.0077,  0.0582,  0.0123,  0.0543,  0.0467,  0.0528,  0.0545,\n",
       "         -0.0230,  0.0523,  0.0379,  0.0515, -0.0218,  0.0168, -0.0408,  0.0048,\n",
       "         -0.0125, -0.0102,  0.0506,  0.0367,  0.0584, -0.0070, -0.0007,  0.0374,\n",
       "          0.0588,  0.0575, -0.0064,  0.0339, -0.0389,  0.0399, -0.0274,  0.0273,\n",
       "         -0.0084, -0.0060,  0.0049, -0.0040, -0.0396,  0.0321,  0.0267, -0.0332,\n",
       "          0.0177,  0.0538, -0.0496,  0.0340,  0.0254,  0.0575,  0.0597,  0.0121,\n",
       "          0.0410,  0.0257,  0.0599, -0.0089, -0.0238, -0.0242, -0.0122,  0.0065,\n",
       "         -0.0590,  0.0199,  0.0047, -0.0537, -0.0312,  0.0587,  0.0581,  0.0182,\n",
       "         -0.0378, -0.0438,  0.0015,  0.0304, -0.0023,  0.0398, -0.0561, -0.0254,\n",
       "         -0.0145, -0.0002,  0.0448, -0.0566,  0.0444, -0.0407, -0.0437,  0.0437,\n",
       "         -0.0091, -0.0384, -0.0550, -0.0421, -0.0018, -0.0355,  0.0336, -0.0342,\n",
       "         -0.0602,  0.0297, -0.0219,  0.0025,  0.0418, -0.0368, -0.0173, -0.0223,\n",
       "         -0.0128, -0.0517,  0.0275,  0.0171, -0.0601, -0.0599,  0.0475, -0.0134,\n",
       "         -0.0477, -0.0056, -0.0433, -0.0515,  0.0505,  0.0590, -0.0419,  0.0078,\n",
       "          0.0538,  0.0556, -0.0230, -0.0488, -0.0336,  0.0489, -0.0278,  0.0299,\n",
       "          0.0119,  0.0347, -0.0109, -0.0366, -0.0159,  0.0578,  0.0351,  0.0127,\n",
       "          0.0601, -0.0602,  0.0147,  0.0548, -0.0097,  0.0280,  0.0185,  0.0606,\n",
       "          0.0234, -0.0374, -0.0362, -0.0375, -0.0577, -0.0403,  0.0138, -0.0098,\n",
       "         -0.0082,  0.0594, -0.0412,  0.0193, -0.0069,  0.0220,  0.0329, -0.0489,\n",
       "         -0.0495,  0.0488, -0.0009,  0.0617, -0.0387, -0.0592,  0.0367, -0.0017,\n",
       "          0.0167, -0.0152, -0.0037,  0.0286, -0.0110, -0.0265,  0.0061, -0.0046,\n",
       "          0.0273,  0.0533,  0.0175, -0.0483,  0.0080,  0.0028,  0.0054, -0.0546,\n",
       "         -0.0158,  0.0016, -0.0433,  0.0566,  0.0471, -0.0443,  0.0509, -0.0279,\n",
       "          0.0046, -0.0141,  0.0323, -0.0011,  0.0555,  0.0592,  0.0488,  0.0610,\n",
       "         -0.0518, -0.0601, -0.0444, -0.0044, -0.0158, -0.0561, -0.0622,  0.0143,\n",
       "          0.0162, -0.0344,  0.0388, -0.0356, -0.0209,  0.0471, -0.0460, -0.0241,\n",
       "         -0.0535, -0.0050,  0.0110,  0.0089, -0.0165, -0.0147,  0.0321, -0.0383,\n",
       "         -0.0091,  0.0323,  0.0437,  0.0010, -0.0257,  0.0352,  0.0449, -0.0054,\n",
       "          0.0575, -0.0207, -0.0129, -0.0111, -0.0331, -0.0575,  0.0530,  0.0042,\n",
       "          0.0153, -0.0206,  0.0359, -0.0361, -0.0029,  0.0026, -0.0118,  0.0091,\n",
       "         -0.0021, -0.0115, -0.0432, -0.0023, -0.0134,  0.0011, -0.0387, -0.0045,\n",
       "          0.0484,  0.0348,  0.0420, -0.0428, -0.0050, -0.0281,  0.0513,  0.0203,\n",
       "         -0.0180,  0.0252, -0.0035,  0.0276, -0.0219,  0.0203,  0.0024, -0.0130,\n",
       "          0.0385,  0.0019,  0.0266, -0.0501,  0.0235,  0.0135, -0.0367,  0.0234,\n",
       "         -0.0166, -0.0299, -0.0158, -0.0185,  0.0286,  0.0508, -0.0412, -0.0214,\n",
       "         -0.0287,  0.0192,  0.0426,  0.0125, -0.0128, -0.0526, -0.0611, -0.0108,\n",
       "         -0.0060,  0.0242,  0.0071, -0.0246,  0.0297,  0.0503,  0.0350, -0.0396,\n",
       "         -0.0170,  0.0317,  0.0339,  0.0142, -0.0046, -0.0238, -0.0228, -0.0115,\n",
       "         -0.0067, -0.0210, -0.0343,  0.0527, -0.0295,  0.0491, -0.0514,  0.0366,\n",
       "          0.0430,  0.0182,  0.0241,  0.0573, -0.0049, -0.0416,  0.0511,  0.0432,\n",
       "         -0.0397,  0.0475,  0.0396,  0.0124, -0.0198, -0.0513,  0.0302, -0.0438,\n",
       "          0.0045, -0.0520,  0.0135, -0.0513,  0.0382, -0.0424, -0.0601, -0.0137,\n",
       "          0.0267, -0.0530,  0.0510,  0.0367,  0.0070, -0.0382,  0.0073, -0.0623,\n",
       "          0.0105,  0.0380, -0.0566, -0.0178, -0.0464,  0.0122, -0.0534, -0.0020,\n",
       "         -0.0359,  0.0539,  0.0115,  0.0178,  0.0366, -0.0507,  0.0181,  0.0154,\n",
       "         -0.0473,  0.0582, -0.0417, -0.0021, -0.0207,  0.0428, -0.0337,  0.0061],\n",
       "        requires_grad=True)]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "ttask = train_tasks.sample()\n",
    "support, y_support, queries, qs, y_queries, queries_labels = set_sets(\n",
    "    ttask, n_ways, k_shots, q_shots, embedder, device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Running inner adaptation loop\n",
    "for i in range(50):\n",
    "    opt.zero_grad()\n",
    "    evaluation_loss, query_preds = inner_adapt_lpo(\n",
    "        support, y_support, qs, y_queries, learner_temp, loss, n_ways, k_shots, q_shots, 3/7, 1)\n",
    "    evaluation_loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "meta_train_loss.append(evaluation_loss.item())\n",
    "evaluation_accuracy = accuracy(query_preds[::n_ways,], queries_labels)\n",
    "meta_train_acc.append(evaluation_accuracy.item())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "meta_train_acc"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.4285714328289032,\n",
       " 0.4285714328289032,\n",
       " 0.4000000059604645,\n",
       " 0.2571428716182709,\n",
       " 0.2857142984867096,\n",
       " 0.22857142984867096,\n",
       " 0.11428571492433548,\n",
       " 0.20000000298023224]"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "for p in learner_temp.parameters():\n",
    "    print(p.grad.data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0018, -0.0018, -0.0015,  ..., -0.0019, -0.0015, -0.0013],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0034,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0065,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0007,  0.0000,  0.0000,  0.0000, -0.0061,  0.0000,  0.0020, -0.0164,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0022,  0.0000,  0.0259,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0057,\n",
      "         0.0000,  0.0000,  0.0188,  0.0000,  0.0000,  0.0017,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0027,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0063,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0084,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.0117,  0.0000,  0.0000,  0.0000, -0.0003,  0.0000,  0.0000,\n",
      "         0.0000,  0.0041,  0.0000,  0.0000,  0.0000,  0.0000, -0.0117,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0013,  0.0000,  0.0018,  0.0000,  0.0042,\n",
      "         0.0000, -0.0066,  0.0000, -0.0025,  0.0000,  0.0000, -0.0005,  0.0000,\n",
      "         0.0000,  0.0000, -0.0096,  0.0000,  0.0000,  0.0083,  0.0000,  0.0000,\n",
      "         0.0000,  0.0043,  0.0000,  0.0000, -0.0067,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0057,  0.0000,  0.0001,\n",
      "         0.0000,  0.0156,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0082, -0.0006,  0.0000,\n",
      "        -0.0074,  0.0000,  0.0000, -0.0054,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0119,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0047, -0.0071,  0.0000,  0.0000,  0.0000,  0.0013,  0.0000,  0.0000,\n",
      "        -0.0074,  0.0246,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0030,  0.0000,  0.0000,\n",
      "         0.0000, -0.0044,  0.0000,  0.0000,  0.0043,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0051,  0.0000,  0.0133,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0055,  0.0000,  0.0146,  0.0000,  0.0000,  0.0125,\n",
      "         0.0002,  0.0000,  0.0000,  0.0000,  0.0000, -0.0019,  0.0000,  0.0000])\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0005, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0175,  0.0000,\n",
      "         0.0000,  0.0032,  0.0000,  0.0000,  0.0000, -0.0113,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0001,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0172,  0.0000, -0.0126,\n",
      "         0.0000,  0.0000,  0.0312, -0.0062,  0.0000,  0.0000, -0.0026,  0.0000,\n",
      "         0.0000, -0.0227, -0.0099, -0.0124,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0065,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0092, -0.0078,\n",
      "        -0.0589,  0.0000,  0.0049,  0.0000,  0.0000,  0.0000,  0.0000,  0.0126,\n",
      "         0.0000, -0.0236,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0260,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0086,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0109,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0366,  0.0379,  0.0000,  0.0003,  0.0000])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0017,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0022,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0008,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0007,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0008,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0009,  0.0000]])\n",
      "tensor([ 0.0109,  0.0151, -0.0077,  0.0112,  0.0168,  0.0115, -0.0024,  0.0093,\n",
      "        -0.0028, -0.0032, -0.0095, -0.0133,  0.0056, -0.0042,  0.0020,  0.0115,\n",
      "         0.0056, -0.0093,  0.0251,  0.0185,  0.0094,  0.0179,  0.0025, -0.0067,\n",
      "        -0.0094, -0.0059,  0.0160,  0.0200, -0.0081, -0.0013,  0.0171,  0.0074,\n",
      "        -0.0138,  0.0041,  0.0111, -0.0107,  0.0022,  0.0082,  0.0107,  0.0057,\n",
      "        -0.0122,  0.0056,  0.0060, -0.0054, -0.0067, -0.0092, -0.0197,  0.0100,\n",
      "         0.0038, -0.0086, -0.0078, -0.0099, -0.0013,  0.0095,  0.0078, -0.0108,\n",
      "        -0.0068, -0.0026,  0.0051,  0.0102,  0.0016, -0.0047,  0.0059,  0.0076])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0002,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0003,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0002,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0001,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0001,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0001,  0.0000]])\n",
      "tensor([ 1.3690e-03, -1.5978e-03, -1.8930e-03, -1.2240e-03,  9.0265e-04,\n",
      "        -4.8669e-04,  3.4246e-05, -6.6190e-05, -1.5189e-03, -2.1673e-04,\n",
      "        -1.3090e-03,  2.9692e-03,  1.9275e-03,  6.3609e-04, -1.1987e-03,\n",
      "        -1.5405e-03, -1.7186e-03, -8.3810e-04, -1.7126e-03, -2.2332e-03,\n",
      "        -3.7580e-05, -3.3576e-05,  1.8377e-03,  1.8236e-03, -1.1220e-03,\n",
      "         6.3933e-04,  2.3903e-03, -1.2483e-03,  1.3983e-03, -6.1481e-04,\n",
      "         1.6709e-03, -7.8195e-04, -1.6658e-03,  1.5524e-03,  3.9362e-04,\n",
      "        -1.9731e-03, -7.3472e-04,  3.8028e-05,  2.1646e-04, -1.3393e-03,\n",
      "        -1.6866e-03, -1.4206e-03, -2.8983e-03, -1.2811e-04, -4.0525e-03,\n",
      "        -1.9929e-03,  4.8064e-05, -7.1422e-04,  5.6825e-05, -6.5696e-04,\n",
      "        -2.3732e-03, -2.0489e-04,  2.9784e-04,  1.0321e-03,  9.7344e-04,\n",
      "         2.7944e-03,  2.6194e-04, -9.5511e-04,  9.4225e-04,  8.1142e-04,\n",
      "         1.0413e-04, -1.0244e-03,  4.2476e-04,  6.5728e-04])\n",
      "tensor([[ 2.3651e-03,  5.7192e-04, -1.8873e-03,  ..., -9.4126e-05,\n",
      "         -5.9098e-04, -7.7564e-04],\n",
      "        [ 5.1155e-04,  3.6935e-04, -9.4343e-04,  ..., -9.9306e-06,\n",
      "         -2.8213e-04, -5.0748e-04],\n",
      "        [ 2.0829e-04, -1.9831e-04, -1.4488e-04,  ..., -2.4794e-04,\n",
      "          6.7333e-06, -2.9092e-04],\n",
      "        ...,\n",
      "        [-2.7073e-04, -7.7921e-05, -3.1166e-04,  ..., -3.6653e-04,\n",
      "          3.5238e-04,  2.4914e-04],\n",
      "        [ 1.7981e-03, -4.8248e-05, -9.2221e-04,  ..., -5.1797e-04,\n",
      "          3.3449e-04, -7.5468e-04],\n",
      "        [ 1.8938e-03,  1.1535e-03, -3.4938e-03,  ...,  1.9773e-04,\n",
      "         -8.2936e-04, -7.9380e-04]])\n",
      "tensor([-1.2731e-03, -1.0615e-03, -6.6319e-04, -1.0569e-03, -6.4748e-04,\n",
      "         5.3404e-05, -2.4274e-03, -8.9655e-04,  7.0375e-04, -1.7750e-04,\n",
      "        -3.2071e-04, -2.1739e-04,  5.8495e-04,  4.9068e-04, -3.1429e-04,\n",
      "        -1.9800e-04, -2.6296e-03, -8.1423e-04, -7.1545e-04, -1.2667e-03,\n",
      "        -2.2747e-03, -3.9127e-04, -1.0105e-03,  1.5259e-03, -3.0787e-04,\n",
      "         1.2608e-03, -1.2469e-04,  1.1045e-05,  3.7652e-04,  5.4525e-05,\n",
      "         2.6834e-04, -2.1089e-03, -2.3021e-03, -2.8581e-04,  6.5612e-04,\n",
      "        -2.1824e-03,  5.1725e-04, -1.1731e-03, -1.2999e-04, -1.8053e-03,\n",
      "        -2.0415e-03,  2.7411e-04,  2.2992e-04, -1.7460e-03, -1.4533e-05,\n",
      "         1.0793e-04, -3.4246e-03, -7.4662e-04, -1.6652e-03, -1.6184e-04,\n",
      "        -1.1027e-03, -7.2537e-04,  5.1999e-05, -2.8035e-03, -8.2253e-04,\n",
      "         7.1428e-04, -1.8258e-04, -5.2765e-04, -8.3006e-04,  7.1885e-04,\n",
      "        -2.3397e-03, -2.3658e-03, -3.1932e-04,  4.8047e-04, -1.6320e-04,\n",
      "         1.7995e-04, -7.1494e-04, -9.2395e-04, -2.1261e-03, -1.0811e-03,\n",
      "        -3.0263e-04, -1.2192e-03,  8.6582e-04, -9.3103e-04, -1.5190e-06,\n",
      "        -1.2335e-04, -1.5838e-03, -4.7702e-04, -9.2709e-05, -3.5671e-04,\n",
      "        -3.3933e-03, -5.8135e-04, -1.0243e-04, -2.7770e-04, -9.8811e-04,\n",
      "         1.0788e-03, -8.5243e-04, -1.2246e-03, -2.1738e-03, -3.3269e-04,\n",
      "        -5.8152e-04, -1.3193e-03, -8.4434e-04, -2.1455e-03,  4.4259e-04,\n",
      "        -1.9040e-04, -1.5158e-03, -8.0536e-04,  1.8179e-04, -3.0238e-03,\n",
      "        -8.8388e-06, -4.3303e-05,  1.5512e-04, -2.0917e-03, -1.0814e-04,\n",
      "        -5.0838e-04, -1.1347e-04,  2.1719e-04, -5.5924e-04,  2.6665e-06,\n",
      "        -7.6564e-04, -6.7066e-04, -5.2268e-04, -1.9615e-03,  6.0983e-04,\n",
      "        -3.2678e-04, -2.4160e-04, -7.7351e-04, -2.7594e-03, -2.0230e-03,\n",
      "        -1.7968e-03, -1.4039e-03, -6.0779e-04, -6.5147e-04, -9.1204e-04,\n",
      "        -8.5015e-04, -8.3849e-04, -2.3083e-03])\n",
      "tensor([[-7.9972e-06, -5.4109e-06, -6.0151e-05,  ..., -1.6091e-05,\n",
      "         -6.2450e-05,  7.1855e-07],\n",
      "        [-5.2959e-04, -5.9436e-04, -6.7256e-05,  ..., -1.5935e-04,\n",
      "          8.7522e-05, -4.4481e-04],\n",
      "        [-3.0815e-05, -6.5121e-06, -2.1421e-05,  ...,  1.1514e-04,\n",
      "         -3.0665e-05, -3.3149e-05],\n",
      "        ...,\n",
      "        [-8.4479e-05, -8.3231e-05, -3.5952e-05,  ...,  2.9481e-05,\n",
      "         -7.0585e-05,  1.3971e-05],\n",
      "        [-1.0434e-06, -7.4087e-05,  4.2609e-06,  ..., -4.2199e-05,\n",
      "          8.0412e-06, -1.1298e-04],\n",
      "        [-5.5162e-04, -5.2635e-04, -1.7419e-04,  ..., -6.2880e-05,\n",
      "         -1.2059e-04, -4.5823e-04]])\n",
      "tensor([-6.6225e-05, -9.5124e-04,  6.2061e-05, -1.4095e-03, -1.8131e-05,\n",
      "        -1.0096e-03, -3.3692e-04, -4.9727e-04, -3.8409e-04, -7.7672e-05,\n",
      "        -7.4844e-04, -7.9982e-04,  2.4846e-04, -1.0664e-03,  4.7959e-06,\n",
      "         2.1940e-04, -7.7507e-04, -1.0146e-03, -2.4221e-04, -1.0648e-03,\n",
      "        -8.7113e-04, -7.4489e-04, -1.7057e-04, -1.0543e-03,  5.4650e-04,\n",
      "        -8.7371e-04, -7.6560e-04, -7.1700e-05, -5.6537e-05, -5.2006e-04,\n",
      "         9.9937e-06, -9.8893e-04, -1.0321e-03, -2.6609e-04, -2.9112e-04,\n",
      "        -5.3780e-04, -5.6539e-05,  1.8272e-06, -8.2931e-04, -4.1084e-04,\n",
      "        -9.8122e-04, -9.0607e-04, -6.4382e-04, -8.4603e-04, -1.1654e-04,\n",
      "        -9.6758e-04,  1.9339e-04,  9.4781e-06, -1.2185e-03,  3.5393e-04,\n",
      "        -1.1978e-03,  2.9215e-04,  1.5741e-06, -1.0376e-03, -1.1149e-03,\n",
      "        -1.0360e-03, -6.5933e-04, -3.4775e-06, -1.7808e-04, -1.1884e-03,\n",
      "        -6.0844e-04, -1.0068e-03, -1.0230e-03,  9.6870e-06, -9.5399e-04,\n",
      "        -1.0581e-03, -1.1193e-03, -5.1471e-04, -6.2249e-05, -2.1030e-04,\n",
      "        -8.3293e-05, -3.5913e-04, -7.2860e-05, -1.0755e-03, -2.1355e-05,\n",
      "        -6.7875e-05, -1.0119e-03, -8.0919e-04, -1.0473e-03, -9.7299e-07,\n",
      "        -7.9007e-04, -1.2514e-03, -5.6974e-04, -6.1195e-05, -1.8346e-04,\n",
      "        -9.0390e-04,  1.7676e-04, -8.4494e-04, -9.4034e-04,  1.2659e-04,\n",
      "        -9.0120e-04,  3.9333e-04, -1.9122e-05, -1.7457e-03, -1.3623e-03,\n",
      "        -1.9757e-04,  5.9581e-05, -9.7643e-05,  2.5624e-05, -5.9719e-04,\n",
      "         3.5260e-04, -1.1812e-03, -6.7071e-04, -8.5002e-04, -2.1274e-04,\n",
      "        -1.1574e-03, -1.9247e-05, -1.2532e-03, -1.0671e-03, -1.2045e-03,\n",
      "         1.6985e-05,  3.0903e-04, -9.8134e-04, -1.1596e-03, -7.1540e-04,\n",
      "        -1.0233e-03,  3.2541e-04, -1.0392e-03, -1.1754e-03, -1.1621e-03,\n",
      "         5.6204e-04, -9.5458e-04, -5.0236e-05, -1.1645e-03, -7.7563e-04,\n",
      "         4.0380e-04, -3.1298e-04, -2.5053e-04, -3.4481e-04, -6.5048e-04,\n",
      "        -1.3922e-04, -8.3317e-04, -7.7538e-04, -2.3987e-04,  7.2351e-07,\n",
      "        -9.0599e-04, -7.4765e-04, -3.1298e-04, -1.0647e-03, -2.8756e-04,\n",
      "        -1.3720e-03,  2.8147e-05,  5.1738e-05, -1.1910e-03, -1.2678e-03,\n",
      "        -3.3263e-05, -6.2121e-04, -1.0483e-03, -8.6208e-04, -4.2209e-04,\n",
      "        -1.2004e-03,  1.1303e-04, -8.7484e-04, -1.3299e-05, -3.3822e-04,\n",
      "        -2.9929e-06, -1.1661e-03,  2.4826e-04, -2.5214e-04, -8.3430e-04,\n",
      "        -1.5003e-03, -1.4428e-06,  1.2187e-04, -6.0163e-04,  9.4203e-04,\n",
      "        -2.6161e-04, -9.1441e-04, -1.7389e-04, -1.2004e-03, -1.0298e-03,\n",
      "        -1.0016e-03,  1.2764e-03, -5.2834e-04, -8.3695e-04, -4.8180e-04,\n",
      "         1.5194e-04, -1.5534e-03,  3.9366e-05, -1.7814e-04, -4.1221e-04,\n",
      "        -5.9308e-04, -6.7013e-04, -1.0715e-03, -7.8642e-04, -1.0559e-03,\n",
      "        -1.3479e-06, -5.8395e-04, -6.9704e-04, -8.4538e-04, -1.0729e-03,\n",
      "        -1.5422e-05, -3.1595e-05,  5.3337e-07, -1.0727e-03, -5.3190e-04,\n",
      "         1.7880e-04, -8.3557e-04, -4.9239e-04, -1.2663e-04, -5.5706e-05,\n",
      "        -8.0324e-04, -2.7785e-04, -5.9964e-04, -9.6624e-04,  1.0210e-04,\n",
      "        -8.0618e-04, -4.9312e-04, -1.2273e-03, -9.0022e-04, -2.5150e-04,\n",
      "         1.4251e-06, -8.7868e-04,  3.2411e-06, -4.7057e-04, -5.9540e-04,\n",
      "        -7.6970e-05, -1.1571e-03, -3.1538e-04,  3.1040e-05, -3.0396e-04,\n",
      "        -6.2595e-04, -1.1108e-03, -9.5067e-05, -9.6855e-04, -1.1434e-03,\n",
      "         7.1775e-04, -1.0045e-03, -7.2477e-04, -2.3766e-04, -7.8379e-04,\n",
      "         6.9090e-07, -9.6410e-04,  2.4311e-04, -9.8225e-05, -1.1514e-03,\n",
      "        -8.3492e-04, -8.7222e-04, -1.0904e-03, -9.3063e-05, -1.0463e-03,\n",
      "        -1.0658e-03, -7.3299e-04,  1.1512e-05, -9.8139e-05,  7.0560e-05,\n",
      "        -8.8203e-04, -1.4892e-05,  7.9129e-06, -1.0078e-03,  9.9396e-04,\n",
      "        -7.7811e-04, -8.7078e-04, -5.9356e-04, -8.0938e-05, -1.6410e-04,\n",
      "        -1.0326e-03])\n",
      "tensor([[ 1.8377e-05, -9.8136e-05,  6.6029e-06,  ...,  2.1393e-05,\n",
      "         -2.5139e-06,  7.2041e-06],\n",
      "        [ 8.4280e-06, -1.2166e-04,  9.0112e-06,  ...,  1.5466e-05,\n",
      "         -4.3245e-06, -3.1556e-05],\n",
      "        [ 4.6492e-06, -5.0406e-05, -1.0287e-06,  ..., -7.4358e-06,\n",
      "         -1.4668e-07, -3.8442e-05],\n",
      "        ...,\n",
      "        [ 1.9749e-05, -1.1202e-04,  1.0055e-05,  ...,  3.6650e-05,\n",
      "         -4.3596e-06,  1.2836e-05],\n",
      "        [ 2.1291e-07, -1.2078e-04,  1.2211e-06,  ...,  2.0845e-06,\n",
      "          4.2237e-07, -8.0247e-05],\n",
      "        [ 4.4250e-06, -7.5509e-05,  1.0452e-06,  ..., -1.8559e-05,\n",
      "          1.1984e-06,  7.0982e-07]])\n",
      "tensor([-8.7325e-05, -1.2458e-04, -2.1391e-04, -1.2249e-04, -1.4236e-04,\n",
      "        -1.6390e-04, -1.7707e-04, -1.1573e-04, -1.5461e-04, -1.2730e-04,\n",
      "        -2.8099e-04, -1.4829e-04, -2.1354e-04, -7.6344e-05, -8.2270e-05,\n",
      "        -7.6758e-05, -6.0336e-05, -1.3575e-04, -1.6316e-04, -2.2817e-04,\n",
      "        -2.2282e-04, -1.2389e-04, -1.9898e-04, -1.7395e-04, -1.2029e-04,\n",
      "        -6.5977e-05, -9.4881e-05, -6.5346e-05, -1.1751e-04, -2.7893e-04,\n",
      "        -2.1600e-04, -1.3308e-04, -2.6260e-04, -2.6653e-04, -1.2091e-04,\n",
      "        -1.8162e-04, -1.7968e-04, -1.1545e-04, -8.0186e-05, -1.0907e-04,\n",
      "        -1.3111e-04, -1.3374e-04, -2.0283e-04,  1.1357e-05, -1.5158e-04,\n",
      "        -1.4146e-04, -1.8972e-04, -6.5021e-05, -9.2627e-05, -1.9656e-04,\n",
      "        -2.3790e-04, -8.9520e-05, -2.1042e-04, -3.1799e-04, -1.1612e-04,\n",
      "        -1.1248e-04, -1.3929e-04, -7.2323e-05, -1.3350e-04, -1.9432e-04,\n",
      "        -1.1398e-04,  2.5442e-05, -1.7621e-04, -1.1096e-04, -2.3853e-04,\n",
      "        -4.7362e-05, -1.4265e-04, -1.9806e-04, -1.4659e-04, -1.6633e-04,\n",
      "        -7.6271e-05, -1.8190e-04, -1.5938e-04, -1.6169e-04, -1.5327e-04,\n",
      "        -1.2178e-04, -1.6013e-04, -2.5317e-04, -1.4392e-04, -2.0370e-04,\n",
      "        -2.0165e-04, -1.6748e-04,  2.0904e-05, -5.2374e-05, -9.0282e-05,\n",
      "        -1.2051e-04, -2.1929e-04, -1.5476e-04, -1.4420e-04, -1.0647e-04,\n",
      "        -1.9817e-04, -2.1640e-04, -2.8822e-04, -1.1554e-04, -1.4921e-04,\n",
      "        -2.7041e-06, -1.1946e-04, -2.1087e-04, -1.3251e-04, -1.5268e-04,\n",
      "        -1.4407e-04, -2.1491e-04, -2.7630e-04, -1.0734e-04, -1.4546e-04,\n",
      "        -1.2585e-04, -2.0085e-04, -1.7753e-04, -2.6769e-05, -1.0358e-04,\n",
      "        -1.3402e-04, -9.5105e-05, -1.2219e-04, -6.0527e-05, -8.7638e-05,\n",
      "        -1.0502e-04, -8.6376e-05, -1.3699e-04, -6.0697e-05, -1.8863e-04,\n",
      "        -1.1465e-04, -1.7090e-04, -1.5264e-04, -1.5366e-04, -1.8656e-04,\n",
      "        -9.6323e-05, -2.0091e-04, -1.3668e-04, -8.3999e-05, -1.6872e-04,\n",
      "        -1.6904e-04, -1.2220e-04, -1.3250e-04, -2.0648e-04, -1.2377e-04,\n",
      "        -9.3845e-06, -1.2508e-04, -2.3302e-04, -1.2915e-04, -1.0356e-04,\n",
      "        -1.8265e-04, -1.3421e-04, -1.6865e-04, -1.7806e-04, -1.7953e-04,\n",
      "        -2.1741e-04, -3.0967e-05, -1.8823e-04, -1.3488e-04, -1.6485e-04,\n",
      "        -1.9668e-04, -1.5599e-04, -1.6825e-04, -1.5529e-04, -4.1211e-05,\n",
      "        -8.9985e-05, -2.1220e-04, -3.0348e-04, -1.7912e-04, -9.8091e-05,\n",
      "        -1.1616e-04, -2.0542e-04, -1.3011e-04,  1.9699e-06, -2.0338e-04,\n",
      "        -1.3142e-04, -1.2184e-04, -1.2337e-04, -9.5072e-05, -8.4824e-05,\n",
      "        -5.6339e-06, -1.3125e-04, -2.5592e-04, -1.8594e-04, -1.8544e-04,\n",
      "        -1.5477e-04, -1.5650e-04, -2.7600e-04, -1.5074e-04, -1.5836e-04,\n",
      "        -1.4466e-04, -1.4154e-07, -8.2490e-05, -5.9578e-05, -1.7751e-04,\n",
      "        -1.2317e-04,  5.9745e-05, -1.0631e-04, -2.0267e-04, -1.9198e-04,\n",
      "        -1.0463e-04, -1.9735e-04, -8.0392e-05, -2.2313e-04, -1.4058e-04,\n",
      "        -1.4744e-04, -7.4156e-05, -6.0709e-05, -1.8944e-04, -1.3876e-04,\n",
      "        -1.4837e-04, -7.1917e-05, -1.5764e-04, -2.2344e-04, -9.2412e-05,\n",
      "        -1.0708e-04, -1.6161e-04, -1.3622e-04, -5.3782e-05, -8.3787e-05,\n",
      "        -1.6567e-04, -1.5299e-04, -1.3987e-04, -1.7415e-04, -1.1300e-04,\n",
      "        -1.5262e-04, -1.6645e-04, -9.2956e-05, -2.4596e-04, -1.9103e-05,\n",
      "        -8.4029e-05, -5.3470e-05, -2.4677e-04, -9.7666e-05, -1.2143e-04,\n",
      "        -8.1544e-05, -2.3578e-04, -1.3747e-04, -2.4450e-05, -1.0942e-04,\n",
      "        -5.4002e-05, -1.9299e-04, -2.0528e-04, -1.0304e-04, -1.5834e-04,\n",
      "        -1.3500e-04, -7.2657e-05, -1.9689e-04, -1.0780e-04, -6.6424e-05,\n",
      "        -1.6796e-04, -1.2877e-04, -9.0769e-05, -1.3561e-04, -2.0432e-04,\n",
      "        -1.4440e-04, -1.1976e-04, -7.6315e-05, -1.3456e-04, -4.3981e-05,\n",
      "        -3.5910e-05, -1.1891e-04, -9.2386e-05, -2.1842e-04, -7.7763e-05,\n",
      "        -7.3182e-05, -1.6601e-04, -3.3810e-05, -1.1238e-04, -7.6189e-05,\n",
      "        -8.2395e-05, -4.2409e-05, -7.9720e-05, -2.2408e-04, -1.9564e-04,\n",
      "        -2.9139e-04, -1.1706e-04, -1.0665e-04, -1.0716e-04, -8.9078e-05,\n",
      "        -2.5932e-04, -7.5607e-05, -2.7196e-04, -2.3104e-04, -2.2215e-04,\n",
      "        -1.4841e-04, -2.6262e-04, -1.0476e-04, -1.2283e-04, -1.5949e-04,\n",
      "        -1.9702e-04, -2.4511e-04, -1.2415e-04, -5.3321e-05, -8.9708e-05,\n",
      "        -7.4896e-05, -1.3532e-04, -1.7055e-04, -1.1163e-04, -2.3566e-04,\n",
      "         1.1597e-06, -2.9382e-04, -6.4143e-05, -1.1321e-04, -1.3888e-04,\n",
      "        -1.1254e-04, -1.6108e-04, -1.6826e-04, -7.6213e-05, -1.0459e-04,\n",
      "        -5.3420e-05, -4.0236e-05, -6.4656e-05, -1.0129e-04, -9.2100e-05,\n",
      "        -1.4136e-04, -9.5168e-05, -1.3507e-04, -1.3068e-04, -1.1498e-04,\n",
      "        -1.0458e-04, -1.7167e-04, -1.5878e-04, -2.4275e-04, -2.3305e-04,\n",
      "         3.9072e-05, -1.2737e-04, -1.1839e-04, -1.4273e-04, -1.0176e-04,\n",
      "        -1.6192e-04, -1.5184e-04, -5.6093e-05, -6.8706e-05, -6.4047e-06,\n",
      "        -2.8324e-05, -1.1814e-04, -1.1029e-04, -8.7845e-05, -1.1763e-04,\n",
      "        -1.1269e-04, -1.0418e-04, -1.9257e-04, -1.3986e-04, -8.4088e-05,\n",
      "        -8.9789e-05,  4.7087e-06, -2.4387e-04, -1.3171e-04, -7.7537e-05,\n",
      "         1.2269e-05, -2.0465e-04, -1.1792e-04, -1.2183e-04, -9.7945e-05,\n",
      "        -1.0316e-04, -1.6768e-04, -2.1270e-04, -1.5221e-04, -1.3077e-04,\n",
      "        -1.4801e-04, -2.2340e-04, -2.5132e-04, -1.5512e-04, -1.5063e-04,\n",
      "        -1.5066e-04, -9.1843e-05, -1.3346e-04, -6.9544e-05, -1.4541e-04,\n",
      "        -7.1232e-05, -1.1186e-04, -3.9756e-05, -1.0429e-05, -1.4583e-04,\n",
      "        -1.6022e-04, -2.0287e-04, -6.7823e-05, -6.5037e-05, -1.0605e-04,\n",
      "        -2.3757e-04, -1.2505e-04, -5.2221e-05, -5.3883e-05, -5.8209e-05,\n",
      "        -1.5692e-04, -1.1735e-04, -1.1495e-04, -7.4046e-05, -1.1344e-04,\n",
      "        -2.3649e-04, -2.0633e-04, -1.1974e-04, -2.4048e-04, -2.9426e-04,\n",
      "        -1.0952e-04, -1.0149e-04, -1.1526e-04, -1.0416e-04, -4.3418e-05,\n",
      "         8.7885e-06, -1.0440e-04, -2.8009e-04, -1.7683e-04, -1.1066e-04,\n",
      "        -5.7114e-05, -1.6148e-05, -1.1259e-04, -1.2548e-04, -1.6698e-04,\n",
      "        -2.1608e-04, -1.5607e-04, -1.9119e-04, -4.6585e-05, -7.8835e-05,\n",
      "        -9.6075e-05, -6.0653e-05, -7.6699e-05, -2.4353e-04, -7.6426e-05,\n",
      "        -1.4433e-04, -1.7088e-04, -1.3873e-04, -5.9608e-06, -8.0958e-05,\n",
      "         5.2130e-05,  1.0191e-04, -1.6269e-04, -1.6610e-05, -1.2935e-04,\n",
      "        -1.9064e-04, -1.4375e-04, -1.8650e-04, -1.2250e-04, -3.3256e-04,\n",
      "        -1.8596e-04, -1.7062e-04, -3.0619e-05, -1.3591e-04, -3.4922e-05,\n",
      "        -3.3470e-05, -1.7669e-04, -2.0021e-04, -1.5396e-04, -8.7494e-05,\n",
      "         4.4332e-05, -1.6251e-04, -1.2674e-04, -1.4432e-04, -2.0311e-04,\n",
      "        -1.7826e-04, -1.9823e-04, -3.3673e-05, -1.6712e-04, -1.1404e-04,\n",
      "        -1.0196e-04, -1.6559e-04,  1.5446e-06, -8.4455e-05, -1.9676e-04,\n",
      "        -5.7480e-05, -1.2312e-04, -1.3061e-04, -8.3658e-05, -9.5360e-05,\n",
      "        -1.1768e-04, -1.2704e-04, -1.5643e-04, -2.6069e-04, -1.2236e-04,\n",
      "        -1.5697e-04, -5.1420e-05, -2.0981e-04, -1.6315e-04, -8.1690e-06,\n",
      "         4.9513e-06, -1.0757e-04, -1.3183e-04, -2.0045e-04, -1.1005e-04,\n",
      "        -1.0058e-04, -1.0008e-04, -1.6597e-04, -6.7317e-05, -4.7609e-05,\n",
      "        -1.3632e-04, -5.7583e-05, -9.2004e-05, -1.6070e-04, -1.2946e-04,\n",
      "        -1.0559e-04,  5.7918e-05, -2.0853e-04, -1.7384e-04, -1.5710e-04,\n",
      "        -1.8536e-04, -6.6835e-05, -3.6323e-05, -7.9949e-05, -1.9634e-04,\n",
      "        -1.5708e-04, -1.9164e-04, -1.3998e-04, -1.5359e-04, -1.4975e-04,\n",
      "        -8.4638e-05, -9.8420e-05, -9.7312e-05, -1.2766e-04, -1.1701e-04,\n",
      "        -1.8376e-04, -9.4000e-05, -1.4566e-04, -2.3077e-05, -2.6348e-05,\n",
      "        -2.1980e-04, -8.2938e-05, -2.3312e-04, -1.2049e-04,  1.5380e-05,\n",
      "        -1.9265e-04, -2.2526e-04])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "- 0.5 * np.log(2 * np.pi)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.9189385332046727"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m71"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('torch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "8d67afa83e86333a367939f878b63191e1d5d5d165e62fc4144602f7751c67e3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}