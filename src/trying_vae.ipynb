{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "classifiers: nn.crossentropyloss = -log-likelihood --- use for logp(y) and -logq(y/x) for support <br>\n",
    "kl-div: <br>\n",
    "reconstr-loss: set reduction to none and then take mean of losses per image in the total batch. This gives reconstr-loss per image for further computation<br> "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import learn2learn as l2l\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from PIL.Image import LANCZOS\n",
    "from config import *\n",
    "\n",
    "import json\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "torch.cuda.is_available()\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "sys.path.append('/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn')\n",
    "sys.path"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/src',\n",
       " '/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/pythonFiles',\n",
       " '/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/pythonFiles/lib/python',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python38.zip',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/datasets-1.2.1-py3.8.egg',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/locket-0.2.1-py3.8.egg',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/home/anuj/.ipython',\n",
       " '/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#from data.loaders import Omniglotmix, MiniImageNet\n",
    "from data.taskers import gen_tasks\n",
    "from src.zoo.archs import CVAE, LVAE\n",
    "from src.zoo.lpo_utils import proto_distr, classify, set_sets, accuracy, inner_adapt_lpo, setup, kl_div\n",
    "\n",
    "#from src.utils import Profiler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_tasks = gen_tasks(dataname='miniimagenet', root='../../mini_imagenet', mode='train', n_ways=5, k_shots=1, q_shots=1, image_transforms=None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "classes = list(range(1623))\n",
    "random.shuffle(classes)\n",
    "image_transforms = transforms.Compose([transforms.Resize(28, interpolation=LANCZOS),\n",
    "                                                    transforms.ToTensor(),\n",
    "                                                    lambda x: 1.0 - x,\n",
    "                                                ])\n",
    "train_tasks = gen_tasks('omniglot', '/home/anuj/Desktop/Work/TU_Delft/research/implement/omniglot', image_transforms=image_transforms, n_ways=5, k_shots=5, q_shots=5, classes=classes[:1100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/torchvision/transforms/transforms.py:257: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_tasks, valid_tasks, test_tasks, learner, learner, embedder = setup('miniimagenet', '../../mini_imagenet', 5, 3, 7, 5, 3, 7, 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "task = train_tasks.sample()\n",
    "device = 'cpu'\n",
    "n_ways = 5\n",
    "k_shots = 3\n",
    "q_shots = 7"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "data, labels = task\n",
    "data, labels = data.to(device), labels.to(device)\n",
    "#data, labels = data.squeeze(0), labels.squeeze(0)\n",
    "sort = torch.sort(labels)\n",
    "data = data.squeeze(0)[sort.indices].squeeze(0)\n",
    "labels = labels.squeeze(0)[sort.indices].squeeze(0)\n",
    "total = n_ways * (k_shots + q_shots)\n",
    "queries_index = np.zeros(total)\n",
    "\n",
    "# Extracting the query datums from the entire task set\n",
    "for offset in range(n_ways):\n",
    "    queries_index[np.random.choice(\n",
    "        k_shots+q_shots, q_shots, replace=False) + ((k_shots + q_shots)*offset)] = True\n",
    "support = data[np.where(queries_index == 0)]\n",
    "support_labels = labels[np.where(queries_index == 0)]\n",
    "queries = data[np.where(queries_index == 1)]\n",
    "queries_labels = labels[np.where(queries_index == 1)]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "queries_labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n",
       "        3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "\n",
    "y_support = F.one_hot(support_labels, num_classes=n_ways)\n",
    "y_queries = torch.tensor(range(n_ways))\n",
    "y_queries = y_queries.repeat(n_ways*q_shots)\n",
    "y_queries = F.one_hot(y_queries, num_classes=n_ways)\n",
    "qs = queries.repeat_interleave(n_ways, dim=0)\n",
    "\n",
    "support, qs = embedder(support), embedder(qs)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "y_support.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([15, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "support_cap, support_mu, support_log_var = learner(support, y_support)\n",
    "support_mu"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-7.5145e-02, -8.9124e-03, -8.2154e-02,  6.1719e-02,  3.6038e-02,\n",
       "         -7.0984e-03,  1.6753e-02, -2.3661e-02,  1.2746e-01, -1.0573e-01,\n",
       "          5.3805e-02, -7.6413e-02, -1.4081e-01,  1.0278e-01,  4.3749e-02,\n",
       "          5.6895e-02,  5.1605e-02, -9.1093e-02, -2.5902e-02,  4.1604e-02,\n",
       "          3.4948e-02,  8.3711e-02, -5.8687e-02,  5.6211e-02,  4.8789e-02,\n",
       "          4.1552e-02,  1.2864e-02, -9.5229e-02, -1.5002e-01,  7.9866e-02,\n",
       "          4.3899e-02,  3.4003e-03, -1.0844e-01,  4.3500e-02, -7.7216e-02,\n",
       "          2.7521e-02,  8.4472e-02, -2.5079e-05,  5.4244e-02,  6.5318e-02,\n",
       "          1.4960e-02,  3.0270e-02, -2.9827e-02, -2.4550e-02, -1.8780e-02,\n",
       "          8.9408e-02, -7.2169e-04, -9.4412e-02,  9.6726e-02, -4.6303e-02,\n",
       "          6.7923e-02, -1.1995e-01, -7.5040e-03,  8.5708e-02, -9.5887e-04,\n",
       "          5.6268e-02,  1.6572e-01, -2.9802e-03, -3.8931e-02,  1.5013e-01,\n",
       "          7.7928e-02, -1.0938e-01, -2.4156e-02, -4.3086e-02],\n",
       "        [-6.5314e-02, -6.3642e-03, -9.7451e-02,  2.3356e-02,  4.0706e-02,\n",
       "         -1.4388e-02, -1.5026e-02, -1.0640e-02,  1.4690e-01, -1.1932e-01,\n",
       "          5.7746e-02, -6.4880e-02, -1.4434e-01,  1.2097e-01,  1.6367e-02,\n",
       "          2.9185e-02,  2.8117e-02, -9.2188e-02, -5.5702e-03,  4.5208e-02,\n",
       "          2.1478e-02,  8.5917e-02, -4.9609e-02,  6.9797e-02,  6.6938e-02,\n",
       "          5.1989e-02,  1.1042e-02, -1.3409e-01, -1.5077e-01,  9.6791e-02,\n",
       "          4.7309e-02,  3.6678e-02, -1.0631e-01,  7.7861e-02, -8.1315e-02,\n",
       "          1.0637e-02,  1.0830e-01,  2.2637e-02,  7.1150e-02,  6.1793e-02,\n",
       "          2.0936e-02,  3.9704e-02, -4.7557e-02, -5.9636e-02, -4.3233e-03,\n",
       "          9.9656e-02,  1.5317e-02, -1.2658e-01,  1.3644e-01, -5.5808e-02,\n",
       "          4.8604e-02, -1.5378e-01,  1.9650e-03,  8.4806e-02, -1.4816e-02,\n",
       "          3.9521e-02,  1.7714e-01,  1.3117e-02, -9.7734e-03,  1.6403e-01,\n",
       "          9.4114e-02, -1.3761e-01, -2.6264e-03, -7.8747e-02],\n",
       "        [-5.9066e-02,  3.3887e-02, -1.1976e-01,  4.7225e-02,  1.0462e-01,\n",
       "         -3.6695e-02, -9.1696e-02,  4.6320e-02,  1.9534e-01, -8.8224e-02,\n",
       "          6.4598e-02,  4.3032e-02, -1.9312e-01,  1.3994e-01,  8.5575e-02,\n",
       "          5.2673e-02, -3.9850e-02, -1.7307e-01, -9.8187e-03,  2.6512e-02,\n",
       "          2.8500e-02,  8.8802e-03,  5.5744e-02,  2.8709e-02,  8.7914e-02,\n",
       "          5.8023e-02,  3.2117e-03, -2.6360e-01, -1.7554e-01,  3.2384e-02,\n",
       "          5.4474e-02,  1.3204e-01, -1.1874e-01,  1.5681e-01, -1.6842e-01,\n",
       "         -7.8350e-02,  1.8266e-01,  6.8420e-02,  1.0990e-01,  1.0473e-01,\n",
       "          4.6474e-02,  1.0825e-01, -1.1874e-01, -5.2907e-02, -1.4206e-01,\n",
       "          1.3544e-01,  3.1665e-02, -1.6705e-01,  2.0828e-01, -1.1077e-01,\n",
       "          1.9360e-04, -2.7436e-01,  2.4912e-02,  1.1914e-01, -2.2491e-02,\n",
       "         -2.0635e-02,  1.9043e-01, -1.8158e-02,  4.2458e-02,  2.2238e-01,\n",
       "          2.1648e-01, -2.2750e-01,  1.3548e-01, -1.7471e-01],\n",
       "        [-7.1618e-02,  1.6099e-02, -1.0111e-01,  3.9369e-02,  3.3515e-02,\n",
       "         -1.4471e-02, -5.0982e-03, -7.1409e-03,  1.4988e-01, -1.1681e-01,\n",
       "          4.3501e-02, -5.6635e-02, -1.4553e-01,  1.1664e-01,  2.2510e-02,\n",
       "          4.4179e-02,  1.1390e-02, -9.3712e-02, -1.2881e-02,  3.5343e-02,\n",
       "          3.1280e-02,  9.7400e-02, -4.4346e-02,  5.8598e-02,  6.4320e-02,\n",
       "          4.6538e-02,  1.1474e-02, -1.4330e-01, -1.1805e-01,  5.5309e-02,\n",
       "          3.2369e-02,  4.4210e-02, -1.1400e-01,  5.5144e-02, -1.0362e-01,\n",
       "          8.2894e-04,  1.1125e-01,  1.7720e-02,  8.2660e-02,  7.0299e-02,\n",
       "          3.0822e-02,  4.8133e-02, -3.3269e-02, -5.9914e-02, -3.8107e-02,\n",
       "          1.1461e-01,  1.9904e-02, -1.1149e-01,  1.2634e-01, -6.8587e-02,\n",
       "          4.2627e-02, -1.6268e-01, -6.2383e-03,  8.1798e-02,  1.2724e-03,\n",
       "          3.4331e-02,  1.8848e-01, -2.1179e-02, -1.8759e-02,  1.8799e-01,\n",
       "          8.0623e-02, -1.2936e-01,  1.3862e-02, -8.1155e-02],\n",
       "        [-7.1519e-02, -2.2265e-03, -8.9679e-02,  4.3565e-02,  3.1799e-02,\n",
       "         -2.6267e-02, -3.7163e-03, -7.6335e-03,  1.3097e-01, -1.1647e-01,\n",
       "          7.0752e-02, -7.6725e-02, -1.3587e-01,  1.0841e-01,  1.8936e-02,\n",
       "          5.2098e-02,  3.7902e-02, -7.5445e-02,  7.3068e-04,  5.7879e-02,\n",
       "          2.4477e-02,  7.5499e-02, -5.0631e-02,  6.9251e-02,  4.8857e-02,\n",
       "          3.2190e-02,  2.7344e-03, -1.1646e-01, -1.4063e-01,  7.2312e-02,\n",
       "          2.8972e-02,  2.7920e-02, -1.0881e-01,  4.9893e-02, -8.3580e-02,\n",
       "          2.0324e-02,  8.8904e-02,  1.8248e-02,  7.0249e-02,  8.0340e-02,\n",
       "          2.3526e-02,  3.8276e-02, -1.2108e-02, -4.8181e-02,  9.5927e-03,\n",
       "          8.3012e-02,  2.4717e-02, -9.2778e-02,  1.0535e-01, -5.1391e-02,\n",
       "          3.8940e-02, -1.3607e-01, -6.5885e-03,  8.2054e-02,  5.6929e-03,\n",
       "          6.1127e-02,  1.7265e-01, -2.0311e-03, -2.2703e-02,  1.4703e-01,\n",
       "          7.7134e-02, -1.1493e-01, -1.3708e-02, -5.6762e-02],\n",
       "        [-7.5434e-02, -8.2178e-03, -8.5178e-02,  4.9224e-02,  3.7759e-02,\n",
       "         -2.2520e-02,  5.9591e-03, -1.8696e-02,  1.3590e-01, -1.0973e-01,\n",
       "          5.7320e-02, -8.4653e-02, -1.6008e-01,  1.0952e-01,  3.1508e-02,\n",
       "          4.1660e-02,  3.5266e-02, -9.2115e-02, -3.1775e-02,  4.6045e-02,\n",
       "          2.6366e-02,  1.0193e-01, -6.6570e-02,  5.5900e-02,  6.0084e-02,\n",
       "          4.1699e-02,  9.6164e-03, -1.1554e-01, -1.3133e-01,  7.7280e-02,\n",
       "          4.4746e-02,  2.5883e-02, -1.0919e-01,  5.0444e-02, -8.4913e-02,\n",
       "          3.6074e-02,  8.9884e-02,  4.7308e-03,  6.2139e-02,  8.6431e-02,\n",
       "          1.3303e-02,  5.1844e-02, -3.8303e-02, -4.3321e-02, -2.9250e-02,\n",
       "          9.7931e-02,  1.5534e-02, -1.0620e-01,  1.0972e-01, -3.9482e-02,\n",
       "          5.5776e-02, -1.4539e-01, -3.7932e-03,  8.9352e-02, -1.5848e-03,\n",
       "          3.5986e-02,  1.7412e-01,  8.8981e-04, -3.5813e-02,  1.4707e-01,\n",
       "          8.2361e-02, -1.3455e-01, -1.0849e-02, -7.2931e-02],\n",
       "        [-6.5027e-02,  3.5146e-03, -9.5613e-02,  3.7953e-02,  6.1452e-02,\n",
       "         -3.7715e-02, -2.0022e-02,  1.9759e-03,  1.4075e-01, -1.0120e-01,\n",
       "          6.9305e-02, -4.5117e-02, -1.8245e-01,  1.3695e-01,  5.7238e-02,\n",
       "          2.4009e-02,  2.0575e-02, -1.2252e-01, -2.3950e-03,  2.8619e-02,\n",
       "         -8.7438e-04,  8.0715e-02, -4.6248e-02,  8.7788e-02,  8.1865e-02,\n",
       "          5.1272e-02,  7.9529e-03, -1.6322e-01, -1.3926e-01,  7.5881e-02,\n",
       "          6.6195e-02,  4.1586e-02, -1.2129e-01,  9.8073e-02, -1.1514e-01,\n",
       "          2.1169e-03,  1.4169e-01,  3.5689e-02,  8.4971e-02,  8.7847e-02,\n",
       "          1.5700e-02,  3.0718e-02, -5.9510e-02, -6.1058e-02, -5.6687e-02,\n",
       "          1.0612e-01,  3.4680e-02, -1.3955e-01,  1.4758e-01, -8.3941e-02,\n",
       "          4.9616e-02, -1.8844e-01,  1.0944e-02,  8.0619e-02, -3.5987e-02,\n",
       "          1.5500e-02,  1.8739e-01,  1.1817e-03,  1.2470e-02,  1.7695e-01,\n",
       "          1.3687e-01, -1.4922e-01,  3.6198e-02, -9.8592e-02],\n",
       "        [-4.6316e-02,  1.2562e-02, -1.0440e-01,  3.2141e-02,  5.2660e-02,\n",
       "         -2.6790e-02, -1.0859e-02,  5.8747e-03,  1.4621e-01, -1.1945e-01,\n",
       "          5.9786e-02, -5.3062e-02, -1.5017e-01,  1.3127e-01,  2.4706e-02,\n",
       "          2.0921e-02,  9.2983e-03, -1.1157e-01,  9.0574e-03,  2.0435e-02,\n",
       "          8.5995e-03,  7.6206e-02, -4.1819e-02,  8.3040e-02,  6.1514e-02,\n",
       "          4.4677e-02,  3.0657e-02, -1.3650e-01, -1.5461e-01,  6.8390e-02,\n",
       "          3.8561e-02,  2.9334e-02, -1.0301e-01,  8.5417e-02, -1.0083e-01,\n",
       "         -5.2087e-04,  1.1949e-01,  4.0191e-02,  7.6551e-02,  7.1552e-02,\n",
       "          5.2547e-03,  3.8430e-02, -4.2499e-02, -6.4889e-02, -3.3622e-02,\n",
       "          9.7135e-02,  2.0645e-02, -1.2669e-01,  1.3576e-01, -7.2526e-02,\n",
       "          5.1499e-02, -1.7683e-01,  8.7697e-03,  7.7781e-02, -1.2574e-02,\n",
       "          3.5205e-02,  1.7694e-01,  1.1383e-02, -8.9132e-03,  1.7013e-01,\n",
       "          1.1275e-01, -1.3994e-01,  1.5318e-02, -8.9817e-02],\n",
       "        [-8.5889e-02,  3.7460e-02, -1.0936e-01,  1.9513e-02,  7.0606e-02,\n",
       "         -3.0727e-02, -4.3822e-02,  1.0679e-02,  1.9009e-01, -1.0526e-01,\n",
       "          9.2283e-02,  2.4152e-02, -1.8408e-01,  1.4888e-01,  6.1423e-02,\n",
       "          2.2010e-02, -4.2514e-02, -1.3445e-01,  1.3875e-02,  4.7025e-02,\n",
       "          3.6547e-02,  5.2122e-02,  2.7116e-02,  3.8524e-02,  8.4295e-02,\n",
       "          8.8662e-02,  4.5031e-03, -2.3267e-01, -1.2127e-01,  5.2190e-02,\n",
       "          4.5049e-02,  8.2935e-02, -1.0673e-01,  1.4010e-01, -1.2999e-01,\n",
       "         -6.7767e-02,  1.7433e-01,  7.8449e-02,  1.0374e-01,  8.2765e-02,\n",
       "          6.7507e-02,  6.4445e-02, -1.0596e-01, -9.3163e-02, -9.4822e-02,\n",
       "          1.3624e-01,  5.2816e-02, -1.7422e-01,  1.8484e-01, -1.1528e-01,\n",
       "          1.7617e-02, -2.4584e-01,  2.6365e-02,  8.8160e-02, -3.9690e-02,\n",
       "         -2.4128e-02,  1.9490e-01, -1.8429e-02,  3.7567e-02,  2.2215e-01,\n",
       "          1.6613e-01, -1.8920e-01,  7.6671e-02, -1.7129e-01],\n",
       "        [-7.3750e-02,  1.4346e-02, -9.2532e-02,  4.6864e-02,  2.6461e-02,\n",
       "         -2.1294e-02, -1.5289e-03,  4.7677e-03,  1.3484e-01, -1.1600e-01,\n",
       "          5.3308e-02, -8.3253e-02, -1.4839e-01,  1.1610e-01,  2.7615e-02,\n",
       "          4.6511e-02,  2.6734e-02, -7.7597e-02, -1.9948e-02,  5.3950e-02,\n",
       "          2.1955e-02,  8.2553e-02, -5.9796e-02,  6.6545e-02,  4.5945e-02,\n",
       "          3.3642e-02, -2.0183e-03, -1.1327e-01, -1.2957e-01,  5.8458e-02,\n",
       "          4.7147e-02,  3.0164e-02, -9.2447e-02,  4.9221e-02, -7.7333e-02,\n",
       "          1.0490e-02,  1.0912e-01,  3.3404e-02,  6.3878e-02,  9.2466e-02,\n",
       "          2.7468e-02,  4.1953e-02, -2.6231e-02, -4.2665e-02, -2.1831e-02,\n",
       "          9.1872e-02,  1.9153e-02, -9.5679e-02,  1.1391e-01, -4.8638e-02,\n",
       "          4.1222e-02, -1.4629e-01,  4.9161e-03,  7.1058e-02,  5.1280e-03,\n",
       "          5.8504e-02,  1.7829e-01, -4.7630e-03, -1.7180e-02,  1.5040e-01,\n",
       "          7.9656e-02, -1.2119e-01, -7.9803e-03, -6.8952e-02],\n",
       "        [-6.8745e-02, -6.5627e-03, -1.0195e-01,  4.1088e-02,  3.2661e-02,\n",
       "         -2.4853e-02, -4.7668e-03, -1.5422e-02,  1.3252e-01, -1.0363e-01,\n",
       "          6.3396e-02, -7.0315e-02, -1.7120e-01,  1.2815e-01,  3.4682e-02,\n",
       "          3.3324e-02,  2.8400e-02, -7.6230e-02, -2.1589e-02,  4.1128e-02,\n",
       "         -5.0601e-05,  9.0774e-02, -4.6575e-02,  7.5449e-02,  5.4407e-02,\n",
       "          3.1372e-02,  9.1730e-03, -1.3909e-01, -1.2449e-01,  6.7614e-02,\n",
       "          5.6340e-02,  2.5640e-02, -9.7541e-02,  7.7936e-02, -9.3039e-02,\n",
       "          2.4910e-02,  1.1865e-01,  2.6989e-02,  6.5117e-02,  9.2845e-02,\n",
       "          3.2547e-02,  4.9591e-02, -4.9813e-02, -4.7505e-02, -2.4162e-02,\n",
       "          7.2137e-02,  3.6677e-02, -1.1810e-01,  1.2303e-01, -6.8651e-02,\n",
       "          5.7780e-02, -1.4607e-01,  1.9318e-02,  9.3850e-02, -1.6386e-02,\n",
       "          4.6185e-02,  1.7159e-01,  1.6138e-03,  1.5077e-03,  1.5989e-01,\n",
       "          8.5077e-02, -1.4925e-01,  1.4054e-02, -8.2717e-02],\n",
       "        [-4.4340e-02,  1.6281e-02, -1.1891e-01,  5.2249e-02,  5.0035e-02,\n",
       "         -2.9686e-02, -1.9471e-02, -1.1816e-02,  1.5083e-01, -9.3680e-02,\n",
       "          4.2293e-02, -5.8443e-02, -1.5400e-01,  1.0488e-01,  3.8995e-02,\n",
       "          4.9129e-02,  3.1343e-02, -1.0948e-01, -1.5527e-02,  9.7218e-03,\n",
       "          1.8476e-02,  5.5711e-02, -4.1066e-02,  8.7415e-02,  6.3748e-02,\n",
       "          2.8070e-02,  2.8832e-02, -1.6937e-01, -1.5800e-01,  7.0073e-02,\n",
       "          5.8566e-02,  3.5711e-02, -1.0385e-01,  9.7655e-02, -1.2998e-01,\n",
       "         -1.0413e-02,  1.0197e-01,  3.2038e-02,  9.1167e-02,  7.8068e-02,\n",
       "          1.4109e-02,  6.2546e-02, -2.5676e-02, -5.5572e-02, -2.6396e-02,\n",
       "          8.5018e-02,  2.1233e-02, -1.1409e-01,  1.6627e-01, -7.2159e-02,\n",
       "          2.6154e-02, -1.6092e-01,  1.5048e-02,  8.6724e-02,  2.9746e-03,\n",
       "          3.4143e-02,  1.9895e-01, -1.6802e-02, -3.9384e-03,  1.7063e-01,\n",
       "          1.0380e-01, -1.6981e-01,  3.0067e-02, -1.1406e-01],\n",
       "        [-7.3854e-02, -1.9035e-02, -6.7625e-02,  4.8140e-02,  3.2230e-02,\n",
       "         -1.5187e-02,  6.1591e-03, -2.4662e-02,  1.3105e-01, -1.1557e-01,\n",
       "          4.1822e-02, -8.8739e-02, -1.4767e-01,  1.0327e-01,  3.4379e-02,\n",
       "          5.8366e-02,  4.7364e-02, -9.2151e-02, -3.3193e-02,  4.1110e-02,\n",
       "          2.9680e-02,  8.9416e-02, -6.2647e-02,  5.3484e-02,  5.1619e-02,\n",
       "          4.7882e-02,  1.9087e-02, -9.0587e-02, -1.2804e-01,  6.6848e-02,\n",
       "          2.6893e-02,  1.8871e-02, -1.0399e-01,  3.9498e-02, -8.6749e-02,\n",
       "          4.0324e-02,  7.8259e-02,  4.5652e-04,  6.9421e-02,  6.8875e-02,\n",
       "          7.0383e-03,  4.3411e-02, -3.2900e-02, -3.6708e-02, -3.6925e-02,\n",
       "          9.3263e-02, -2.2493e-03, -1.0424e-01,  1.0669e-01, -3.4913e-02,\n",
       "          7.2303e-02, -1.2795e-01, -1.3106e-02,  8.5287e-02,  1.1841e-02,\n",
       "          5.3035e-02,  1.5736e-01, -5.1664e-03, -3.8170e-02,  1.4785e-01,\n",
       "          7.2884e-02, -1.1509e-01, -3.3566e-02, -5.6622e-02],\n",
       "        [-8.2487e-02, -1.6996e-03, -9.6570e-02,  3.5347e-02,  3.4837e-02,\n",
       "         -1.0560e-02,  1.0317e-02, -3.9217e-03,  1.3873e-01, -1.0489e-01,\n",
       "          5.1864e-02, -7.3467e-02, -1.4696e-01,  1.0355e-01,  3.6076e-02,\n",
       "          5.7875e-02,  2.8466e-02, -8.3608e-02, -3.3828e-02,  4.1960e-02,\n",
       "          3.8971e-02,  8.0779e-02, -5.5526e-02,  6.6732e-02,  5.2624e-02,\n",
       "          4.5378e-02,  7.9777e-03, -1.1579e-01, -1.3993e-01,  6.7202e-02,\n",
       "          3.6962e-02,  1.7695e-02, -9.7748e-02,  4.6718e-02, -8.0468e-02,\n",
       "          1.6435e-02,  1.0079e-01,  2.1153e-02,  5.9779e-02,  8.2266e-02,\n",
       "          1.9880e-02,  3.7161e-02, -3.9205e-02, -6.2834e-02, -1.5798e-02,\n",
       "          8.7676e-02,  1.2727e-02, -9.2713e-02,  1.1281e-01, -3.6218e-02,\n",
       "          4.4860e-02, -1.2574e-01,  1.4743e-02,  7.2092e-02,  1.2552e-02,\n",
       "          4.5078e-02,  1.7802e-01, -1.0436e-02, -3.0383e-02,  1.4619e-01,\n",
       "          7.1708e-02, -1.1482e-01, -1.9175e-02, -6.6942e-02],\n",
       "        [-8.6287e-02,  2.4120e-02, -1.0965e-01,  2.1414e-02,  4.0828e-02,\n",
       "         -3.2583e-02, -1.5206e-02, -6.9492e-03,  1.5281e-01, -1.1793e-01,\n",
       "          6.1079e-02, -4.0069e-02, -1.4525e-01,  1.0768e-01,  2.9768e-02,\n",
       "          4.9764e-02, -8.2869e-03, -1.1639e-01, -1.8107e-03,  3.5387e-02,\n",
       "          1.6067e-02,  5.2120e-02, -3.7441e-02,  5.9260e-02,  5.5704e-02,\n",
       "          5.1603e-02,  2.1751e-02, -1.6482e-01, -1.2941e-01,  5.2526e-02,\n",
       "          1.7802e-02,  3.1018e-02, -1.1900e-01,  7.0437e-02, -1.0378e-01,\n",
       "         -2.0761e-02,  1.1697e-01,  2.2707e-02,  8.9127e-02,  7.9594e-02,\n",
       "          3.5587e-02,  4.4992e-02, -2.9749e-02, -6.7918e-02, -1.5662e-02,\n",
       "          1.0120e-01,  2.8274e-02, -1.0196e-01,  1.4154e-01, -7.4857e-02,\n",
       "          3.6664e-02, -1.6024e-01,  1.0763e-02,  7.3720e-02,  1.1832e-02,\n",
       "          4.6428e-02,  1.6692e-01, -1.4184e-02,  3.2532e-03,  1.9245e-01,\n",
       "          1.0234e-01, -1.1163e-01,  1.2364e-02, -8.9117e-02]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Building Prototypical distributions\n",
    "proto_mu, proto_var = proto_distr(\n",
    "    support_mu, support_log_var, n_ways, k_shots, 'precision_weighted')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "proto_var.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 64])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "proto_mu.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 64])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "\n",
    "# Forward pass on the Query datums\n",
    "queries_cap, queries_mu, queries_log_var = learner(qs, y_queries)\n",
    "queries_cap"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0428,  0.1504, -0.2027,  ...,  0.0693, -0.1145,  0.0263],\n",
       "        [-0.1058,  0.0255, -0.2681,  ...,  0.0453, -0.1871,  0.0397],\n",
       "        [-0.0311,  0.1314, -0.1639,  ..., -0.1088, -0.2072,  0.0628],\n",
       "        ...,\n",
       "        [ 0.0193,  0.0127, -0.1972,  ...,  0.0714, -0.1562,  0.0559],\n",
       "        [ 0.0277, -0.0531, -0.3132,  ...,  0.0724, -0.1923, -0.0049],\n",
       "        [ 0.0644,  0.0406, -0.1644,  ...,  0.0120, -0.1460,  0.0453]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "\n",
    "support_logits = classify(\n",
    "    mu_p=proto_mu, var_p=proto_var, mu_datums=support_mu)\n",
    "queries_logits = classify(\n",
    "    mu_p=proto_mu, var_p=proto_var, mu_datums=queries_mu)\n",
    "support_logits"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-23.6021, -23.6018, -23.6142, -23.5726, -23.5880],\n",
       "        [-23.5873, -23.5628, -23.4816, -23.4948, -23.4916],\n",
       "        [-23.5813, -23.5522, -23.5197, -23.5076, -23.5279],\n",
       "        [-23.5949, -23.5359, -23.5181, -23.5067, -23.5110],\n",
       "        [-23.5810, -23.5382, -23.5119, -23.5014, -23.5085],\n",
       "        [-23.6005, -23.5409, -23.5303, -23.5203, -23.5227],\n",
       "        [-23.6427, -23.6106, -23.4794, -23.5159, -23.4984],\n",
       "        [-23.6293, -23.5917, -23.4693, -23.5036, -23.4954],\n",
       "        [-23.6215, -23.5772, -23.4727, -23.4979, -23.4884],\n",
       "        [-23.6039, -23.5669, -23.5206, -23.5002, -23.5154],\n",
       "        [-23.5838, -23.5446, -23.4925, -23.4868, -23.4953],\n",
       "        [-23.6467, -23.6168, -23.4848, -23.5051, -23.4993],\n",
       "        [-23.6246, -23.5816, -23.5140, -23.5177, -23.4837],\n",
       "        [-23.6001, -23.5622, -23.4982, -23.4963, -23.4792],\n",
       "        [-23.6877, -23.6445, -23.4968, -23.5423, -23.5072]],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "\n",
    "# adding up the losses\n",
    "ce_loss = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "reconstruction_loss = nn.MSELoss(reduction='none')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "\n",
    "L_support = -reconstruction_loss(support_cap, support).view(support.shape[0], -1).mean(dim=1) - ce_loss(\n",
    "    F.softmax(torch.ones_like(y_support).float(), dim=1), torch.argmax(y_support, dim=1)) - kl_div(support_mu, support_log_var)  # = -L(x_s, y_s)\n",
    "L_support"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-2.5833, -3.0038, -2.8290, -2.5975, -2.6868, -2.6668, -3.2976, -3.0719,\n",
       "        -2.9612, -2.6229, -2.8146, -3.3088, -2.8344, -2.8077, -3.4454],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "\n",
    "L_queries = -reconstruction_loss(queries_cap, qs).view(qs.shape[0], -1).mean(dim=1) - ce_loss(\n",
    "    F.softmax(torch.ones_like(y_queries).float(), dim=1), torch.argmax(y_queries, dim=1)) - kl_div(queries_mu, queries_log_var)  # = -L(x_q, y_q)\n",
    "L_queries"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-2.7519, -2.7516, -2.7609, -2.7493, -2.7607, -2.6219, -2.6133, -2.6251,\n",
       "        -2.6283, -2.6194, -2.7640, -2.7708, -2.7782, -2.7780, -2.7817, -2.7049,\n",
       "        -2.6945, -2.7047, -2.7047, -2.7028, -2.6130, -2.6090, -2.6101, -2.6148,\n",
       "        -2.6060, -2.7029, -2.7020, -2.7052, -2.7152, -2.7026, -2.6540, -2.6356,\n",
       "        -2.6403, -2.6457, -2.6380, -2.5660, -2.5774, -2.5702, -2.5704, -2.5642,\n",
       "        -2.8104, -2.8126, -2.8134, -2.8128, -2.8140, -2.8794, -2.8642, -2.8698,\n",
       "        -2.8728, -2.8693, -2.9672, -2.9540, -2.9480, -2.9431, -2.9446, -2.9832,\n",
       "        -2.9816, -2.9821, -2.9812, -2.9750, -2.5828, -2.5861, -2.5875, -2.5781,\n",
       "        -2.5856, -2.8765, -2.8712, -2.8730, -2.8725, -2.8709, -2.7327, -2.7147,\n",
       "        -2.7157, -2.7129, -2.7193, -3.5113, -3.4952, -3.4876, -3.4819, -3.4779,\n",
       "        -2.5509, -2.5536, -2.5512, -2.5452, -2.5477, -2.7118, -2.7136, -2.7242,\n",
       "        -2.7072, -2.7143, -3.3958, -3.3839, -3.3937, -3.3829, -3.3937, -2.7552,\n",
       "        -2.7553, -2.7500, -2.7622, -2.7625, -3.6034, -3.5930, -3.5946, -3.6086,\n",
       "        -3.6056, -2.9572, -2.9554, -2.9530, -2.9648, -2.9650, -3.3585, -3.3411,\n",
       "        -3.3566, -3.3504, -3.3559, -2.6287, -2.6234, -2.6217, -2.6261, -2.6187,\n",
       "        -3.3443, -3.3340, -3.3453, -3.3456, -3.3366, -2.9700, -2.9656, -2.9668,\n",
       "        -2.9682, -2.9700, -2.9267, -2.9321, -2.9386, -2.9281, -2.9303, -2.7379,\n",
       "        -2.7326, -2.7403, -2.7353, -2.7363, -2.7281, -2.7239, -2.7386, -2.7275,\n",
       "        -2.7288, -2.8979, -2.8854, -2.8927, -2.8873, -2.8823, -2.6569, -2.6576,\n",
       "        -2.6539, -2.6719, -2.6602, -3.2795, -3.2551, -3.2695, -3.2739, -3.2655,\n",
       "        -3.3101, -3.3312, -3.3227, -3.3098, -3.3249, -2.6668, -2.6968, -2.6893,\n",
       "        -2.6744, -2.6790, -3.2009, -3.2041, -3.1976, -3.1984, -3.1929],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "yq = torch.argmax(y_queries, dim=1)\n",
    "yq.view(n_ways*q_shots, n_ways).t()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "        [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "         4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]])"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "L_queries.view(n_ways*q_shots, n_ways).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([35, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "U_queries = torch.mul(F.softmax(queries_logits, dim=1)[\n",
    "                        ::5, ], L_queries.view(n_ways*q_shots, n_ways)).sum(dim=1) - 0.1*torch.sum(torch.mul(F.softmax(queries_logits, dim=1)[\n",
    "                            ::5, ], torch.log(F.softmax(queries_logits, dim=1)[\n",
    "                                ::5, ])), dim=1)\n",
    "U_queries"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-2.5940, -2.4607, -2.6137, -2.5415, -2.4497, -2.5448, -2.4817, -2.4088,\n",
       "        -2.6518, -2.7102, -2.7902, -2.8197, -2.4231, -2.7119, -2.5580, -3.3294,\n",
       "        -2.3888, -2.5534, -3.2292, -2.5962, -3.4405, -2.7984, -3.1919, -2.4627,\n",
       "        -3.1805, -2.8073, -2.7704, -2.5756, -2.5687, -2.7281, -2.4993, -3.1080,\n",
       "        -3.1591, -2.5205, -3.0378], grad_fn=<SubBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "alpha = 0.1*(q_shots/k_shots)\n",
    "J_alpha = -L_support.mean() - U_queries.mean() + alpha * \\\n",
    "    ce_loss(support_logits, torch.argmax(y_support, dim=1)).mean()\n",
    "J_alpha"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(6.0066, grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "\n",
    "torch.Tensor([1,2,3,4])**-1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.5000, 0.3333, 0.2500])"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m71"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('torch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "8d67afa83e86333a367939f878b63191e1d5d5d165e62fc4144602f7751c67e3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}