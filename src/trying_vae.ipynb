{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "classifiers: nn.crossentropyloss = -log-likelihood --- use for logp(y) and -logq(y/x) for support <br>\n",
    "kl-div: <br>\n",
    "reconstr-loss: set reduction to none and then take mean of losses per image in the total batch. This gives reconstr-loss per image for further computation<br> "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import learn2learn as l2l\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from PIL.Image import LANCZOS\n",
    "from config import *\n",
    "\n",
    "import json\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "torch.cuda.is_available()\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "sys.path.append('/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn')\n",
    "sys.path"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn/src',\n",
       " '/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/pythonFiles',\n",
       " '/home/anuj/.vscode/extensions/ms-toolsai.jupyter-2021.8.2041215044/pythonFiles/lib/python',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python38.zip',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/datasets-1.2.1-py3.8.egg',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/locket-0.2.1-py3.8.egg',\n",
       " '/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/home/anuj/.ipython',\n",
       " '/home/anuj/Desktop/Work/TU_Delft/research/implement/learning_to_meta-learn']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#from data.loaders import Omniglotmix, MiniImageNet\n",
    "from data.taskers import gen_tasks\n",
    "from src.zoo.archs import CCVAE\n",
    "from src.zoo.delpo_utils import setup, inner_adapt_delpo, loss\n",
    "\n",
    "#from src.utils import Profiler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_tasks = gen_tasks(dataname='miniimagenet', root='../../mini_imagenet', mode='train', n_ways=5, k_shots=1, q_shots=1, image_transforms=None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "classes = list(range(1623))\n",
    "random.shuffle(classes)\n",
    "image_transforms = transforms.Compose([transforms.Resize(28, interpolation=LANCZOS),\n",
    "                                                    transforms.ToTensor(),\n",
    "                                                    lambda x: 1.0 - x,\n",
    "                                                ])\n",
    "train_tasks = gen_tasks('omniglot', '/home/anuj/Desktop/Work/TU_Delft/research/implement/omniglot', image_transforms=image_transforms, n_ways=5, k_shots=5, q_shots=5, classes=classes[:1100])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "device = 'cpu'\n",
    "n_ways = 5\n",
    "k_shots = 5\n",
    "q_shots = 15\n",
    "dataset = 'miniimagenet'\n",
    "root = '../../dataset/mini_imagenet'\n",
    "order = False\n",
    "inner_lr = 0.01\n",
    "meta_lr = 0.001\n",
    "reconst_loss = nn.MSELoss(reduction='mean')\n",
    "inner_adapt_steps_train = 5"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train_tasks, valid_tasks, test_tasks, learner = setup(\n",
    "    dataset, root, n_ways, k_shots, q_shots, order, inner_lr, device, download='False')\n",
    "opt = optim.Adam(learner.parameters(), meta_lr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "opt.zero_grad()\n",
    "meta_train_loss = []\n",
    "meta_valid_loss = []\n",
    "meta_train_acc = []\n",
    "meta_valid_acc = []\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "ttask = train_tasks.sample()\n",
    "model = learner.clone()\n",
    "evaluation_loss, evaluation_accuracy = inner_adapt_delpo(\n",
    "    ttask, reconst_loss, model, n_ways, k_shots, q_shots, inner_adapt_steps_train, device)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/anuj/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "evaluation_loss"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor(6.3777, grad_fn=<AddBackward0>),\n",
       " tensor(1.6141, grad_fn=<NllLossBackward>),\n",
       " tensor(0.1253, grad_fn=<MseLossBackward>),\n",
       " tensor(2.1628, grad_fn=<MeanBackward0>),\n",
       " tensor(2.4754, grad_fn=<MeanBackward0>))"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "evaluation_loss[0].backward()\n",
    "meta_train_loss.append(evaluation_loss[0])\n",
    "meta_train_acc.append(evaluation_accuracy)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "evaluation_loss[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(16.9887, grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for p in learner.parameters():\n",
    "    p.grad.data.mul_(1.0 / meta_batch_size)\n",
    "opt.step()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data, labels = ttask\n",
    "data, labels = data.to(device), labels.to(device)\n",
    "total = n_ways * (k_shots + q_shots)\n",
    "queries_index = np.zeros(total)\n",
    "\n",
    "# Extracting the evaluation datums from the entire task set, for the meta gradient calculation\n",
    "for offset in range(n_ways):\n",
    "    queries_index[np.random.choice(\n",
    "        k_shots+q_shots, q_shots, replace=False) + ((k_shots + q_shots)*offset)] = True\n",
    "support = data[np.where(queries_index == 0)]\n",
    "support_labels = labels[np.where(queries_index == 0)]\n",
    "queries = data[np.where(queries_index == 1)]\n",
    "queries_labels = labels[np.where(queries_index == 1)]\n",
    "\n",
    "# Inner adapt step\n",
    "for _ in range(1):\n",
    "    reconst_image, logits, mu_l, log_var_l, mu_s, log_var_s = learner(support)\n",
    "    adapt_loss = loss(reconst_loss, reconst_image, support/256, logits, support_labels, mu_s, log_var_s, mu_l, log_var_l)\n",
    "    learner.adapt(adapt_loss[0])\n",
    "\n",
    "reconst_image, logits, mu_l, log_var_l, mu_s, log_var_s = learner(queries)\n",
    "eval_loss = loss(reconst_loss, reconst_image, queries/256, logits, queries_labels, mu_s, log_var_s, mu_l, log_var_l)\n",
    "eval_acc = accuracy(F.softmax(logits, dim=1), queries_labels)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m71"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('torch': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "8d67afa83e86333a367939f878b63191e1d5d5d165e62fc4144602f7751c67e3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}